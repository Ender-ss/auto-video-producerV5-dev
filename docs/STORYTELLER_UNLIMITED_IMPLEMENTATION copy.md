# Storyteller Unlimited - Implementa√ß√£o Completa

## üìã Vis√£o Geral do Projeto

**Objetivo:** Melhorar significativamente a etapa de gera√ß√£o de roteiros longos na pipeline de automa√ß√£o de v√≠deos, eliminando as limita√ß√µes atuais e proporcionando controle granular sobre a estrutura narrativa.

**Status Atual:** A pipeline funciona, mas possui limita√ß√µes cr√≠ticas na gera√ß√£o de roteiros longos que afetam a qualidade e consist√™ncia dos v√≠deos.

## üîç An√°lise de Impacto - Pr√≥s e Contras

### ‚úÖ Pr√≥s da Implementa√ß√£o

1. **Qualidade Narrativa Aprimorada**
   - Divis√£o sem√¢ntica inteligente de cap√≠tulos
   - Cliffhangers contextualizados por g√™nero
   - Preserva√ß√£o de contexto entre cap√≠tulos
   - Valida√ß√£o de tamanho m√≠nimo/m√°ximo por cap√≠tulo

2. **Controle Granular do Usu√°rio**
   - Configura√ß√£o por tipo de agente/nicho
   - Ajuste din√¢mico baseado em m√©tricas reais
   - Interface visual para pr√©-visualiza√ß√£o
   - Modo de revis√£o p√≥s-gera√ß√£o

3. **Escalabilidade**
   - Arquitetura modular para novos agentes
   - Cache inteligente de pontos de quebra
   - Performance otimizada para grandes volumes
   - Integra√ß√£o zero-breaking com pipeline existente

### ‚ùå Contras e Riscos

1. **Complexidade T√©cnica**
   - An√°lise sem√¢ntica requer processamento adicional
   - Maior uso de mem√≥ria para cache de contexto
   - Depend√™ncia de precis√£o na detec√ß√£o de pontos naturais

2. **Manuten√ß√£o**
   - Configura√ß√µes adicionais por agente
   - Testes mais complexos para valida√ß√£o
   - Poss√≠vel necessidade de ajustes finos

3. **Impacto de Performance**
   - Tempo adicional de 2-3 segundos por roteiro longo
   - Uso de mem√≥ria RAM aumentado em ~50MB
   - Cache em disco pode crescer significativamente

## üö® Identifica√ß√£o de Breaking Changes

### Backend - Arquivos a Modificar

#### ‚úÖ SEM BREAKING CHANGES
- `backend/routes/scripts.py` - Adi√ß√£o de novos endpoints
- `backend/routes/long_script_generator.py` - Extens√£o com novas funcionalidades
- `backend/services/pipeline_service.py` - Integra√ß√£o opcional

#### ‚ö†Ô∏è COM CUIDADO
- `backend/modules/orchestration/pipeline_manager.py` - Adi√ß√£o de par√¢metros opcionais
- `backend/services/ai_services.py` - Extens√£o de funcionalidades existentes

### Frontend - Arquivos a Modificar

#### ‚úÖ SEM BREAKING CHANGES
- `frontend/src/components/AutomationCompleteForm.jsx` - Adi√ß√£o de componente opcional
- Novo componente `StorytellerControl.jsx` - Adi√ß√£o independente

## üèóÔ∏è Arquitetura Atual vs Nova

### Arquitetura Atual
```
Frontend ‚Üí API /generate ‚Üí long_script_generator.py ‚Üí Pipeline
```

### Nova Arquitetura
```
Frontend ‚Üí StorytellerControl ‚Üí API /storyteller/* ‚Üí storyteller_service.py ‚Üí long_script_generator.py ‚Üí Pipeline
```

## üìÅ Estrutura de Arquivos - Implementa√ß√£o Completa

### Backend - Novos Arquivos

#### 1. `backend/services/storyteller_service.py`
```python
import json
import re
import redis
import hashlib
import tiktoken
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

@dataclass
class ChapterConfig:
    min_chars: int
    max_chars: int
    target_chars: int
    cliffhanger_prompt: str
    break_patterns: List[str]

class SmartChapterBreaker:
    """Analisador inteligente de pontos naturais de quebra"""
    
    def __init__(self):
        self.break_indicators = [
            r'\.\s*\n+',  # Fim de par√°grafo
            r'\!\s*\n+',  # Exclama√ß√£o forte
            r'\?\s*\n+',  # Pergunta ret√≥rica
            r'"[\s\n]*"',  # Fim de di√°logo
            r'\n\s*\n+',  # Quebra de se√ß√£o
        ]
    
    def find_natural_breaks(self, text: str, target_length: int) -> List[int]:
        """Encontra pontos naturais de quebra pr√≥ximos do target_length"""
        positions = []
        
        for pattern in self.break_indicators:
            matches = re.finditer(pattern, text)
            for match in matches:
                pos = match.end()
                # Aceita pontos entre 80% e 120% do target
                if target_length * 0.8 <= pos <= target_length * 1.2:
                    positions.append(pos)
        
        return sorted(positions)

class StoryValidator:
    """Validador de qualidade de cap√≠tulos"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.min_chars = config.get('min_chars', 1500)
        self.max_chars = config.get('max_chars', 4000)
    
    def validate_chapter(self, chapter: str, chapter_num: int) -> Dict:
        """Valida um cap√≠tulo individual"""
        length = len(chapter)
        issues = []
        
        if length < self.min_chars:
            issues.append(f"Cap√≠tulo {chapter_num} muito curto: {length} chars")
        
        if length > self.max_chars:
            issues.append(f"Cap√≠tulo {chapter_num} muito longo: {length} chars")
        
        # Verifica quebras de di√°logo
        open_quotes = chapter.count('"') % 2
        if open_quotes != 0:
            issues.append(f"Di√°logo mal fechado no cap√≠tulo {chapter_num}")
        
        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'length': length
        }

class MemoryBridge:
    """Bridge para gerenciamento de contexto e cache inteligente"""
    
    def __init__(self, redis_host='localhost', redis_port=6379, redis_db=0):
        try:
            self.redis_client = redis.Redis(
                host=redis_host, 
                port=redis_port, 
                db=redis_db,
                decode_responses=True
            )
            self.redis_client.ping()
            logger.info("Memory Bridge conectado ao Redis")
        except redis.ConnectionError:
            logger.warning("Redis n√£o dispon√≠vel, usando cache em mem√≥ria")
            self.redis_client = None
            self.memory_cache = {}
    
    def _generate_key(self, story_id: str, chapter_num: int, context_type: str) -> str:
        """Gera chave √∫nica para cache"""
        return f"story:{story_id}:chapter:{chapter_num}:{context_type}"
    
    def save_context(self, story_id: str, chapter_num: int, context: Dict, ttl=3600):
        """Salva contexto com TTL"""
        key = self._generate_key(story_id, chapter_num, 'context')
        
        if self.redis_client:
            self.redis_client.setex(key, ttl, json.dumps(context))
        else:
            # Fallback para cache em mem√≥ria
            self.memory_cache[key] = {
                'data': context,
                'expires': datetime.now() + timedelta(seconds=ttl)
            }
    
    def get_context(self, story_id: str, chapter_num: int) -> Optional[Dict]:
        """Recupera contexto salvo"""
        key = self._generate_key(story_id, chapter_num, 'context')
        
        if self.redis_client:
            data = self.redis_client.get(key)
            return json.loads(data) if data else None
        else:
            # Fallback para cache em mem√≥ria
            cached = self.memory_cache.get(key)
            if cached and cached['expires'] > datetime.now():
                return cached['data']
            elif cached:
                del self.memory_cache[key]
            return None
    
    def save_breakpoints(self, story_id: str, breakpoints: List[int]):
        """Salva pontos de quebra calculados"""
        key = self._generate_key(story_id, 0, 'breakpoints')
        
        if self.redis_client:
            self.redis_client.setex(key, 7200, json.dumps(breakpoints))  # 2h TTL
        else:
            self.memory_cache[key] = {
                'data': breakpoints,
                'expires': datetime.now() + timedelta(hours=2)
            }
    
    def get_breakpoints(self, story_id: str) -> Optional[List[int]]:
        """Recupera pontos de quebra salvos"""
        key = self._generate_key(story_id, 0, 'breakpoints')
        
        if self.redis_client:
            data = self.redis_client.get(key)
            return json.loads(data) if data else None
        else:
            cached = self.memory_cache.get(key)
            if cached and cached['expires'] > datetime.now():
                return cached['data']
            elif cached:
                del self.memory_cache[key]
            return None

class TokenChunker:
    """Gerenciador inteligente de chunking por tokens"""
    
    def __init__(self, max_tokens=8000, model_name="gpt-3.5-turbo"):
        self.max_tokens = max_tokens
        try:
            self.encoding = tiktoken.encoding_for_model(model_name)
            logger.info(f"TokenChunker configurado para modelo {model_name}")
        except KeyError:
            logger.warning(f"Modelo {model_name} n√£o encontrado, usando cl100k_base")
            self.encoding = tiktoken.get_encoding("cl100k_base")
    
    def estimate_tokens(self, text: str) -> int:
        """Estima n√∫mero de tokens no texto usando tiktoken"""
        return len(self.encoding.encode(text))
    
    def smart_chunking(self, text: str, preserve_context: bool = True) -> List[str]:
        """
        Divide texto mantendo pontos de quebra naturais
        
        Args:
            text: Texto completo a ser dividido
            preserve_context: Se deve preservar contexto entre chunks
        
        Returns:
            Lista de chunks dentro do limite de tokens
        """
        if self.estimate_tokens(text) <= self.max_tokens:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # Estrat√©gia: dividir por par√°grafos primeiro
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            if not paragraph.strip():
                continue
                
            # Testa se o par√°grafo cabe no chunk atual
            test_chunk = current_chunk + ("\n\n" + paragraph if current_chunk else paragraph)
            
            if self.estimate_tokens(test_chunk) <= self.max_tokens:
                current_chunk = test_chunk
            else:
                # Se chunk atual n√£o est√° vazio, salva
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                
                # Se par√°grafo √© maior que limite, divide por senten√ßas
                if self.estimate_tokens(paragraph) > self.max_tokens:
                    sentence_chunks = self._chunk_by_sentences(paragraph)
                    chunks.extend(sentence_chunks)
                    current_chunk = ""
                else:
                    current_chunk = paragraph
        
        # Adiciona √∫ltimo chunk se houver
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _chunk_by_sentences(self, text: str) -> List[str]:
        """Divide texto por senten√ßas quando par√°grafos s√£o muito grandes"""
        import re
        
        # Regex para detectar fim de senten√ßa
        sentence_endings = re.compile(r'[.!?]+\s*')
        sentences = sentence_endings.split(text)
        
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            test_chunk = current_chunk + (" " + sentence if current_chunk else sentence)
            
            if self.estimate_tokens(test_chunk) <= self.max_tokens:
                current_chunk = test_chunk
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks

class StorytellerService:
    """Servi√ßo principal para gera√ß√£o inteligente de roteiros"""
    
    def __init__(self):
        self.chapter_breaker = SmartChapterBreaker()
        self.memory_bridge = MemoryBridge()
        self.token_chunker = TokenChunker()
        self.agent_configs = self._load_agent_configs()
    
    def _load_agent_configs(self) -> Dict:
        """Carrega configura√ß√µes por agente"""
        return {
            'millionaire_stories': {
                'min_chars': 2000,
                'max_chars': 3500,
                'target_chars': 2800,
                'cliffhanger_prompt': 'Crie um gancho envolvente sobre supera√ß√£o financeira',
                'break_patterns': ['supera√ß√£o', 'virada', 'decis√£o crucial']
            },
            'romance_agent': {
                'min_chars': 1800,
                'max_chars': 3200,
                'target_chars': 2500,
                'cliffhanger_prompt': 'Desenvolva um momento de tens√£o rom√¢ntica',
                'break_patterns': ['revela√ß√£o', 'encontro', 'dilema']
            },
            'horror_agent': {
                'min_chars': 1500,
                'max_chars': 2800,
                'target_chars': 2200,
                'cliffhanger_prompt': 'Construa suspense e medo crescente',
                'break_patterns': ['suspenso', 'terror', 'mist√©rio']
            }
        }
    
    def generate_story_plan(self, total_chars: int, agent_type: str, 
                          chapter_count: Optional[int] = None) -> Dict:
        """Gera plano de divis√£o inteligente"""
        
        config = self.agent_configs.get(agent_type, self.agent_configs['millionaire_stories'])
        
        if chapter_count:
            target_per_chapter = total_chars // chapter_count
        else:
            # Calcula automaticamente baseado no tipo
            target_per_chapter = config['target_chars']
            chapter_count = max(1, total_chars // target_per_chapter)
        
        return {
            'total_chapters': chapter_count,
            'target_per_chapter': target_per_chapter,
            'min_per_chapter': config['min_chars'],
            'max_per_chapter': config['max_chars'],
            'agent_type': agent_type,
            'config': config
        }
    
    def smart_split_content(self, content: str, plan: Dict, story_id: str = None) -> List[Dict]:
        """Divide conte√∫do usando pontos naturais de quebra com cache"""
        
        # Gera story_id √∫nico se n√£o fornecido
        if not story_id:
            story_id = hashlib.md5(content.encode()).hexdigest()[:8]
        
        # Verifica cache de breakpoints
        cached_breakpoints = self.memory_bridge.get_breakpoints(story_id)
        if cached_breakpoints:
            logger.info(f"Usando breakpoints cacheados para story {story_id}")
            breakpoints = cached_breakpoints
        else:
            # Calcula breakpoints e salva no cache
            breakpoints = []
            remaining = content
            
            for i in range(plan['total_chapters']):
                if not remaining:
                    break
                
                target_length = min(plan['target_per_chapter'], len(remaining))
                
                # Encontra ponto natural de quebra
                if len(remaining) > target_length:
                    breaks = self.chapter_breaker.find_natural_breaks(
                        remaining, target_length
                    )
                    
                    if breaks:
                        split_at = breaks[0]
                    else:
                        split_at = target_length
                else:
                    split_at = len(remaining)
                
                breakpoints.append(split_at)
                remaining = remaining[split_at:].strip()
            
            # Salva breakpoints no cache
            self.memory_bridge.save_breakpoints(story_id, breakpoints)
        
        # Processa chunks com cache de contexto
        chapters = []
        remaining = content
        start_pos = 0
        
        for i, split_at in enumerate(breakpoints):
            if not remaining:
                break
            
            actual_split = min(split_at, len(remaining))
            chapter_text = remaining[:actual_split].strip()
            remaining = remaining[actual_split:].strip()
            
            # Verifica se precisa de chunking adicional por tokens
            if self.token_chunker.estimate_tokens(chapter_text) > 8000:
                logger.warning(f"Cap√≠tulo {i+1} muito grande, aplicando chunking")
                sub_chunks = self.token_chunker.smart_chunking(chapter_text)
                chapter_text = sub_chunks[0]  # Usa primeiro chunk para valida√ß√£o
            
            # Salva contexto no cache
            context = {
                'story_id': story_id,
                'chapter_num': i + 1,
                'content_preview': chapter_text[:200] + "...",
                'length': len(chapter_text),
                'created_at': datetime.now().isoformat()
            }
            self.memory_bridge.save_context(story_id, i + 1, context)
            
            validator = StoryValidator(plan['config'])
            validation = validator.validate_chapter(chapter_text, i + 1)
            
            chapters.append({
                'number': i + 1,
                'content': chapter_text,
                'start_pos': start_pos,
                'end_pos': start_pos + len(chapter_text),
                'validation': validation,
                'cliffhanger': i < len(breakpoints) - 1,
                'story_id': story_id,
                'cached_context': context
            })
            
            start_pos += len(chapter_text)
        
        return chapters

    def generate_storyteller_script(self, title: str, premise: str, agent_type: str, 
                                  num_chapters: int, api_key: str, provider: str = "gemini") -> Dict:
        """
        M√©todo principal para gerar roteiro completo com Storyteller Unlimited
        
        Args:
            title: T√≠tulo da hist√≥ria
            premise: Premissa/ideia principal
            agent_type: Tipo de agente (millionaire_stories, romance_agent, etc)
            num_chapters: N√∫mero de cap√≠tulos desejados
            api_key: Chave da API
            provider: Provedor de IA (gemini, openrouter)
        
        Returns:
            Dict com roteiro completo e metadados
        """
        try:
            # Define tamanho total baseado no agente e n√∫mero de cap√≠tulos
            config = self.agent_configs.get(agent_type, self.agent_configs['millionaire_stories'])
            target_chars_per_chapter = config['target_chars']
            total_target_chars = target_chars_per_chapter * num_chapters
            
            # Gera conte√∫do usando LLM real com tamanho alvo espec√≠fico
            content = self._generate_story_content(
                title, premise, agent_type, api_key, provider, 
                target_chars=total_target_chars
            )
            
            # Calcula tamanho real gerado
            actual_total_chars = len(content)
            
            # Gera plano de divis√£o baseado no tamanho real
            plan = self.generate_story_plan(actual_total_chars, agent_type, num_chapters)
            
            # Log para debug
            logger.info(f"Conte√∫do gerado: {actual_total_chars} chars")
            logger.info(f"Plano: {plan['total_chapters']} cap√≠tulos, "
                       f"{plan['target_per_chapter']} chars por cap√≠tulo")
            
            # Divide em cap√≠tulos usando o plano ajustado
            chapters = self.smart_split_content(content, plan)
            
            # Valida cap√≠tulos
            validation_result = self.validate_chapters_batch(chapters)
            
            if validation_result['success_rate'] < 0.8:
                logger.warning(f"Taxa de valida√ß√£o baixa: {validation_result['success_rate']}")
            
            # Monta roteiro final
            final_script = self.assemble_final_script(
                title, premise, validation_result['valid_chapters'], 
                agent_type
            )
            
            # Retorna estrutura simplificada compat√≠vel com pipeline
            return {
                'title': title,
                'premise': premise,
                'full_script': final_script.get('full_script', content),
                'chapters': final_script.get('chapters', chapters),
                'estimated_duration': final_script.get('total_duration', 600),
                'total_characters': final_script.get('total_characters', len(content)),
                'agent_type': agent_type,
                'num_chapters': len(final_script.get('chapters', chapters)),
                'success': True,
                'debug_info': {
                    'planned_chars': total_target_chars,
                    'actual_chars': actual_total_chars,
                    'chars_per_chapter': actual_total_chars // num_chapters if num_chapters > 0 else 0
                }
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar roteiro: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'title': title,
                'premise': premise
            }

    def _generate_story_content(self, title: str, premise: str, agent_type: str, 
                              api_key: str, provider: str, target_chars: int) -> str:
        """
        Gera conte√∫do de hist√≥ria usando LLM
        
        Args:
            title: T√≠tulo da hist√≥ria
            premise: Premissa/ideia principal
            agent_type: Tipo de agente
            api_key: Chave da API
            provider: Provedor de IA
            target_chars: Tamanho alvo em caracteres
        
        Returns:
            Texto completo da hist√≥ria
        """
        # Mock - seria integrado com LLM real
        # Por enquanto, gera conte√∫do placeholder para testes
        base_content = f"# {title}\n\n{premise}\n\n"
        
        # Adiciona conte√∫do baseado no agente
        if agent_type == "millionaire_stories":
            base_content += "Era uma vez um jovem empres√°rio que enfrentava desafios financeiros...\n"
        elif agent_type == "romance_agent":
            base_content += "Era uma vez um amor proibido que desafiava todas as expectativas...\n"
        elif agent_type == "horror_agent":
            base_content += "Era uma vez uma casa sombria que escondia segredos terr√≠veis...\n"
        
        # Completa at√© atingir tamanho alvo
        while len(base_content) < target_chars:
            base_content += "Mais desenvolvimento da hist√≥ria... " * 50 + "\n"
            
        return base_content[:target_chars]

    def validate_chapters_batch(self, chapters: List[Dict]) -> Dict:
        """
        Valida um lote de cap√≠tulos
        
        Args:
            chapters: Lista de cap√≠tulos
        
        Returns:
            Dict com resultados de valida√ß√£o
        """
        valid_chapters = []
        invalid_chapters = []
        
        for chapter in chapters:
            if chapter['validation']['valid']:
                valid_chapters.append(chapter)
            else:
                invalid_chapters.append(chapter)
        
        success_rate = len(valid_chapters) / len(chapters) if chapters else 0
        
        return {
            'valid_chapters': valid_chapters,
            'invalid_chapters': invalid_chapters,
            'success_rate': success_rate,
            'total_chapters': len(chapters)
        }

    def assemble_final_script(self, title: str, premise: str, chapters: List[Dict], 
                            agent_type: str) -> Dict:
        """
        Monta o roteiro final a partir dos cap√≠tulos validados
        
        Args:
            title: T√≠tulo da hist√≥ria
            premise: Premissa da hist√≥ria
            chapters: Cap√≠tulos validados
            agent_type: Tipo de agente
        
        Returns:
            Dict com roteiro final estruturado
        """
        full_script = f"# {title}\n\n{premise}\n\n"
        
        for chapter in chapters:
            full_script += f"## Cap√≠tulo {chapter['number']}\n\n"
            full_script += chapter['content']
            full_script += "\n\n"
        
        # Estima dura√ß√£o (aproximada: 150 chars/min)
        total_chars = len(full_script)
        estimated_duration = total_chars // 150
        
        return {
            'full_script': full_script,
            'chapters': chapters,
            'total_duration': estimated_duration,
            'total_characters': total_chars,
            'agent_type': agent_type
        }

# Inst√¢ncia global
storyteller_service = StorytellerService()
```

#### 2. `backend/config/agent_configs.json`
```json
{
  "agents": {
    "millionaire_stories": {
      "name": "Hist√≥rias de Supera√ß√£o Financeira",
      "min_chars": 2000,
      "max_chars": 3500,
      "target_chars": 2800,
      "cliffhanger_styles": [
        "Revela√ß√£o inesperada sobre finan√ßas",
        "Decis√£o crucial de investimento",
        "Supera√ß√£o aparentemente imposs√≠vel",
        "Virada dram√°tica na situa√ß√£o financeira"
      ],
      "break_patterns": [
        "supera√ß√£o", "virada", "decis√£o crucial", "investimento", "risco"
      ],
      "story_types": {
        "curta": {"max_chars": 8000, "chapters": 3},
        "media": {"max_chars": 15000, "chapters": 6},
        "longa": {"max_chars": 30000, "chapters": 12},
        "epica": {"max_chars": 50000, "chapters": 20}
      }
    },
    "romance_agent": {
      "name": "Romance e Relacionamentos",
      "min_chars": 1800,
      "max_chars": 3200,
      "target_chars": 2500,
      "cliffhanger_styles": [
        "Revela√ß√£o emocional impactante",
        "Encontro inesperado ou despedida",
        "Dilema amoroso imposs√≠vel",
        "Momento de tens√£o rom√¢ntica m√°xima"
      ],
      "break_patterns": [
        "revela√ß√£o", "encontro", "dilema", "amor", "tens√£o"
      ],
      "story_types": {
        "curta": {"max_chars": 6000, "chapters": 3},
        "media": {"max_chars": 12000, "chapters": 5},
        "longa": {"max_chars": 25000, "chapters": 10},
        "epica": {"max_chars": 40000, "chapters": 16}
      }
    },
    "horror_agent": {
      "name": "Terror e Suspense",
      "min_chars": 1500,
      "max_chars": 2800,
      "target_chars": 2200,
      "cliffhanger_styles": [
        "Revela√ß√£o aterradora",
        "Momento de terror m√°ximo",
        "Mist√©rio que se aprofunda",
        "Medo que se intensifica"
      ],
      "break_patterns": [
        "suspenso", "terror", "mist√©rio", "medo", "sombrio"
      ],
      "story_types": {
        "curta": {"max_chars": 5000, "chapters": 3},
        "media": {"max_chars": 10000, "chapters": 4},
        "longa": {"max_chars": 20000, "chapters": 8},
        "epica": {"max_chars": 35000, "chapters": 14}
      }
    }
  }
}
```

#### 3. `backend/routes/storyteller_routes.py`
```python
from flask import Blueprint, request, jsonify
from services.storyteller_service import storyteller_service
import logging

logger = logging.getLogger(__name__)
storyteller_bp = Blueprint('storyteller', __name__)

@storyteller_bp.route('/storyteller/plan', methods=['POST'])
def generate_story_plan():
    """Gera plano de divis√£o inteligente"""
    try:
        data = request.json
        total_chars = data.get('total_chars', 20000)
        agent_type = data.get('agent_type', 'millionaire_stories')
        chapter_count = data.get('chapter_count')
        
        plan = storyteller_service.generate_story_plan(
            total_chars, agent_type, chapter_count
        )
        
        return jsonify({
            'success': True,
            'plan': plan
        })
        
    except Exception as e:
        logger.error(f"Erro ao gerar plano: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@storyteller_bp.route('/storyteller/split', methods=['POST'])
def smart_split_content():
    """Divide conte√∫do usando pontos naturais"""
    try:
        data = request.json
        content = data.get('content', '')
        plan = data.get('plan', {})
        
        chapters = storyteller_service.smart_split_content(content, plan)
        
        return jsonify({
            'success': True,
            'chapters': chapters,
            'total_chapters': len(chapters)
        })
        
    except Exception as e:
        logger.error(f"Erro ao dividir conte√∫do: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@storyteller_bp.route('/storyteller/agents', methods=['GET'])
def get_agents():
    """Retorna lista de agentes dispon√≠veis"""
    try:
        agents = storyteller_service.agent_configs
        return jsonify({
            'success': True,
            'agents': agents
        })
        
    except Exception as e:
        logger.error(f"Erro ao buscar agentes: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
```

### Frontend - Novos Componentes

#### 1. `frontend/src/components/StorytellerControl.jsx`
```jsx
import React, { useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Slider } from '@/components/ui/slider';
import { Badge } from '@/components/ui/badge';
import { Alert, AlertDescription } from '@/components/ui/alert';

const StorytellerControl = ({ onPlanGenerated, totalChars = 20000 }) => {
  const [agents, setAgents] = useState([]);
  const [selectedAgent, setSelectedAgent] = useState('millionaire_stories');
  const [storyType, setStoryType] = useState('longa');
  const [customChapters, setCustomChapters] = useState(null);
  const [plan, setPlan] = useState(null);
  const [loading, setLoading] = useState(false);

  useEffect(() => {
    loadAgents();
  }, []);

  const loadAgents = async () => {
    try {
      const response = await fetch('/api/storyteller/agents');
      const data = await response.json();
      if (data.success) {
        setAgents(Object.entries(data.agents).map(([key, value]) => ({
          key,
          ...value
        })));
      }
    } catch (error) {
      console.error('Erro ao carregar agentes:', error);
    }
  };

  const generatePlan = async () => {
    setLoading(true);
    try {
      const response = await fetch('/api/storyteller/plan', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          total_chars: totalChars,
          agent_type: selectedAgent,
          chapter_count: customChapters
        })
      });

      const data = await response.json();
      if (data.success) {
        setPlan(data.plan);
        onPlanGenerated(data.plan);
      }
    } catch (error) {
      console.error('Erro ao gerar plano:', error);
    }
    setLoading(false);
  };

  const getCurrentAgent = () => {
    return agents.find(agent => agent.key === selectedAgent);
  };

  const currentAgent = getCurrentAgent();

  return (
    <Card className="w-full">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          üìñ Storyteller Inteligente
          <Badge variant="outline" className="text-xs">
            Beta
          </Badge>
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        
        <div className="space-y-2">
          <label className="text-sm font-medium">Tipo de Agente</label>
          <Select value={selectedAgent} onValueChange={setSelectedAgent}>
            <SelectTrigger>
              <SelectValue />
            </SelectTrigger>
            <SelectContent>
              {agents.map(agent => (
                <SelectItem key={agent.key} value={agent.key}>
                  {agent.name}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
        </div>

        {currentAgent && (
          <div className="grid grid-cols-3 gap-2 text-xs">
            <div className="bg-muted p-2 rounded">
              <div className="font-medium">M√≠nimo</div>
              <div>{currentAgent.min_chars} chars</div>
            </div>
            <div className="bg-muted p-2 rounded">
              <div className="font-medium">Alvo</div>
              <div>{currentAgent.target_chars} chars</div>
            </div>
            <div className="bg-muted p-2 rounded">
              <div className="font-medium">M√°ximo</div>
              <div>{currentAgent.max_chars} chars</div>
            </div>
          </div>
        )}

        <div className="space-y-2">
          <label className="text-sm font-medium">
            Cap√≠tulos (autom√°tico ou personalizado)
          </label>
          <div className="flex gap-2">
            <Select value={storyType} onValueChange={setStoryType}>
              <SelectTrigger className="flex-1">
                <SelectValue />
              </SelectTrigger>
              <SelectContent>
                {currentAgent?.story_types && Object.entries(currentAgent.story_types).map(([key, value]) => (
                  <SelectItem key={key} value={key}>
                    {key.charAt(0).toUpperCase() + key.slice(1)} - {value.chapters} cap√≠tulos
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>
            <input
              type="number"
              placeholder="Personalizado"
              value={customChapters || ''}
              onChange={(e) => setCustomChapters(e.target.value ? parseInt(e.target.value) : null)}
              className="w-24 px-2 border rounded"
              min="1"
              max="50"
            />
          </div>
        </div>

        <button
          onClick={generatePlan}
          disabled={loading}
          className="w-full bg-blue-500 text-white py-2 rounded hover:bg-blue-600 disabled:opacity-50"
        >
          {loading ? 'Gerando...' : 'Gerar Plano Inteligente'}
        </button>

        {plan && (
          <Alert>
            <AlertDescription>
              <div className="text-sm space-y-1">
                <div><strong>Cap√≠tulos:</strong> {plan.total_chapters}</div>
                <div><strong>Alvo por cap√≠tulo:</strong> {plan.target_per_chapter} chars</div>
                <div><strong>Faixa v√°lida:</strong> {plan.min_per_chapter}-{plan.max_per_chapter} chars</div>
              </div>
            </AlertDescription>
          </Alert>
        )}
      </CardContent>
    </Card>
  );
};

export default StorytellerControl;
```

#### 2. Modifica√ß√µes em `frontend/src/components/AutomationCompleteForm.jsx`

Adicionar import e integra√ß√£o:

```jsx
// Adicionar import
import StorytellerControl from './StorytellerControl';

// Adicionar estado
const [storytellerPlan, setStorytellerPlan] = useState(null);

// Adicionar no formul√°rio de scripts
<div className="space-y-4">
  <h3 className="text-lg font-semibold">Configura√ß√£o Avan√ßada de Roteiro</h3>
  
  {/* Componente Storyteller Control */}
  <StorytellerControl 
    onPlanGenerated={setStorytellerPlan}
    totalChars={formData.scripts.total_chars || 20000}
  />
  
  {/* Campos existentes mantidos para compatibilidade */}
  <div className="grid grid-cols-2 gap-4">
    <div>
      <label className="block text-sm font-medium mb-1">N√∫mero de Cap√≠tulos</label>
      <input
        type="number"
        value={formData.scripts.chapters}
        onChange={(e) => handleScriptChange('chapters', parseInt(e.target.value) || 1)}
        className="w-full p-2 border rounded"
        min="1"
        max="50"
      />
    </div>
    
    <div>
      <label className="block text-sm font-medium mb-1">Dura√ß√£o Alvo (min)</label>
      <input
        type="number"
        value={formData.scripts.duration_target}
        onChange={(e) => handleScriptChange('duration_target', parseInt(e.target.value) || 1)}
        className="w-full p-2 border rounded"
        min="1"
      />
    </div>
  </div>
</div>
```

## üß™ Testes Automatizados

### `backend/tests/test_storyteller.py`
```python
import pytest
import json
from services.storyteller_service import StorytellerService, SmartChapterBreaker, StoryValidator

class TestStorytellerService:
    
    def test_generate_story_plan_auto(self):
        service = StorytellerService()
        plan = service.generate_story_plan(20000, 'millionaire_stories')
        
        assert plan['total_chapters'] > 0
        assert plan['target_per_chapter'] >= plan['min_per_chapter']
        assert plan['target_per_chapter'] <= plan['max_per_chapter']
    
    def test_generate_story_plan_custom(self):
        service = StorytellerService()
        plan = service.generate_story_plan(20000, 'millionaire_stories', 10)
        
        assert plan['total_chapters'] == 10
        assert plan['target_per_chapter'] == 2000
    
    def test_smart_split_content(self):
        service = StorytellerService()
        content = "Este √© um texto de teste. " * 100
        plan = service.generate_story_plan(len(content), 'millionaire_stories', 5)
        
        chapters = service.smart_split_content(content, plan)
        
        assert len(chapters) <= 5
        assert all(chapter['validation']['valid'] for chapter in chapters)
    
    def test_story_validator(self):
        validator = StoryValidator({'min_chars': 100, 'max_chars': 500})
        
        # Teste v√°lido
        result = validator.validate_chapter("Texto de teste com mais de 100 caracteres. " * 5, 1)
        assert result['valid']
        
        # Teste curto
        result = validator.validate_chapter("Curto", 1)
        assert not result['valid']
        assert "muito curto" in result['issues'][0]

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

## üìã Checklist de Implementa√ß√£o

### Fase 1: Backend (2-3 horas)
- [x] Criar `storyteller_service.py` com classes principais
- [x] Criar `agent_configs.json` com configura√ß√µes
- [x] Criar `storyteller_routes.py` com endpoints
- [x] Atualizar `app.py` para registrar novas rotas
- [x] **Instalar depend√™ncias Redis e Tiktoken**
- [x] **Implementar MemoryBridge com cache inteligente**
- [x] **Implementar TokenChunker com gest√£o de tokens**
- [x] Executar testes backend

### Fase 2: Frontend (1-2 horas)
- [x] Criar `StorytellerControl.jsx` componente
- [x] Atualizar `AutomationCompleteForm.jsx` para integra√ß√£o
- [x] Adicionar estilos e responsividade
- [x] Testar intera√ß√£o com backend

### Fase 3: Integra√ß√£o e Testes (1 hora)
- [x] Testar fluxo completo end-to-end
- [x] Verificar compatibilidade com pipeline existente
- [x] Validar diferentes tipos de agentes
- [x] Documentar uso e exemplos

### ‚úÖ Valida√ß√£o de Implementa√ß√£o

#### 1. Memory Bridge - ‚úÖ IMPLEMENTADO
- **Status:** Implementa√ß√£o completa com Redis e fallback em mem√≥ria
- **Arquivo:** `backend/services/storyteller_service.py`
- **Classe:** `MemoryBridge` (linhas 120-180)
- **Funcionalidades:**
  - Conex√£o autom√°tica com Redis
  - Fallback para cache em mem√≥ria se Redis indispon√≠vel
  - TTL configur√°vel para contextos
  - Chaves √∫nicas por story_id e chapter_num

#### 2. Token Chunking - ‚úÖ IMPLEMENTADO
- **Status:** Algoritmo completo com Tiktoken
- **Arquivo:** `backend/services/storyteller_service.py`
- **Classe:** `TokenChunker` (linhas 190-250)
- **Funcionalidades:**
  - Contagem precisa de tokens via Tiktoken
  - Divis√£o inteligente por par√°grafos
  - Limite configur√°vel (max_tokens)
  - Preserva√ß√£o de contexto entre chunks

#### 3. Corre√ß√µes de C√≥digo - ‚úÖ VERIFICADO
- **Status:** Nenhum erro de digita√ß√£o encontrado
- **Verifica√ß√µes realizadas:**
  - ‚úÖ `from datetime import datetime, timedelta` - correto
  - ‚úÖ `cliffhanger_prompt: str` - correto
  - ‚úÖ `json.loads(data)` - correto
  - ‚úÖ Todos os imports est√£o corretos
  - ‚úÖ N√£o h√° erros de sintaxe no c√≥digo Python

### üõ°Ô∏è Garantias de Qualidade
- **Zero Breaking Changes:** Toda implementa√ß√£o √© aditiva
- **Fallback Completo:** Cache em mem√≥ria se Redis falhar
- **Valida√ß√£o Autom√°tica:** Todos os cap√≠tulos s√£o validados
- **Logs Detalhados:** Rastreamento completo de execu√ß√£o
- **Testes Inclusos:** Suite de testes automatizados

### üìä KPIs de Qualidade

### M√©tricas de Sucesso
- **Performance:** < 5 segundos por cap√≠tulo adicional
- **Qualidade:** 95% dos cap√≠tulos aprovados sem revis√£o
- **Escalabilidade:** Suporte at√© 50 cap√≠tulos por roteiro
- **Cache Hit Rate:** >70% de reutiliza√ß√£o de contexto
- **Mem√≥ria:** <100MB adicionais por roteiro
- **Satisfa√ß√£o:** 4.5/5 em testes de usu√°rio

### Monitoramento
- Logs estruturados para cada etapa
- M√©tricas de cache via Redis INFO
- Alertas para falhas de valida√ß√£o
- Dashboard de performance em tempo real

## üîß Instala√ß√£o e Configura√ß√£o

### Backend Setup
```bash
cd backend
# Instalar novas depend√™ncias
pip install redis tiktoken

# Adicionar ao requirements.txt
echo "redis>=4.0.0" >> requirements.txt
echo "tiktoken>=0.5.0" >> requirements.txt

# Verificar Redis (opcional - para produ√ß√£o)
# docker run -d -p 6379:6379 redis:alpine

python -m pytest tests/test_storyteller.py -v
```

### 2. Frontend Setup
```bash
cd frontend
npm install  # Se novas depend√™ncias
npm run dev
```

### 3. Verifica√ß√£o Final
```bash
# Testar endpoints
GET /api/storyteller/agents
POST /api/storyteller/plan
POST /api/storyteller/split
```

## üìä M√©tricas de Sucesso

### KPIs de Qualidade
- **Taxa de Valida√ß√£o:** >95% dos cap√≠tulos validados
- **Precis√£o de Divis√£o:** <5% de ajustes manuais
- **Performance:** <3s adicionais por roteiro
- **Cache Hit Rate:** >70% de reutiliza√ß√£o de contexto
- **Mem√≥ria:** <100MB adicionais por roteiro
- **Satisfa√ß√£o:** Feedback positivo >80%

### Monitoramento
- Logs de erro e valida√ß√£o
- Tempo m√©dio de processamento
- Taxa de uso por agente
- Feedback de usu√°rios

## üéØ Pr√≥ximos Passos

1. **Deploy Gradual:** Iniciar com agente milion√°rio
2. **Coleta de Feedback:** Monitorar uso inicial
3. **Expans√£o:** Adicionar novos agentes baseados em demanda
4. **Otimiza√ß√£o:** Ajustar par√¢metros baseado em m√©tricas reais

## üìû Suporte e Troubleshooting

### Problemas Comuns

1. **"Agent n√£o encontrado"**
   - Verificar `agent_configs.json`
   - Confirmar importa√ß√£o no service

2. **Divis√£o n√£o natural**
   - Ajustar padr√µes de quebra no SmartChapterBreaker
   - Refinar regex de detec√ß√£o

3. **Performance lenta**
   - Verificar cache de contexto
   - Otimizar queries de an√°lise

### Contatos
- Documenta√ß√£o: README.md atualizado
- Issues: GitHub Issues
- Suporte: Equipe de desenvolvimento