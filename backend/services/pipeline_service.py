"""üöÄ Pipeline Service
Servi√ßo principal de orquestra√ß√£o do pipeline de automa√ß√£o completa
"""

import os
import sys
import json
import time
import logging
import subprocess
from datetime import datetime
from typing import Dict, Any, List, Optional

# Adicionar diret√≥rio routes ao path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'routes'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Importar servi√ßos necess√°rios
from services.video_creation_service import VideoCreationService
from services.checkpoint_service import CheckpointService
from services.script_processing_service import ScriptProcessingService

logger = logging.getLogger(__name__)
logger.propagate = True
logger.setLevel(logging.INFO)

def load_custom_prompts() -> Dict[str, Any]:
    """Carregar prompts personalizados do arquivo de configura√ß√£o"""
    try:
        prompts_file = os.path.join(os.path.dirname(__file__), '..', 'data', 'prompts_config.json')
        
        if os.path.exists(prompts_file):
            with open(prompts_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # Retornar prompts padr√£o se arquivo n√£o existir
            return get_default_prompts()
    except Exception as e:
        logger.warning(f"Erro ao carregar prompts personalizados: {str(e)}. Usando prompts padr√£o.")
        return get_default_prompts()

def get_default_prompts() -> Dict[str, Any]:
    """Retornar prompts padr√£o do sistema"""
    return {
        "titles": {
            "viral": "Crie t√≠tulos virais e chamativos que gerem curiosidade e cliques. Use t√©cnicas de copywriting, n√∫meros, palavras de impacto e gatilhos emocionais.",
            "educational": "Crie t√≠tulos educativos e informativos que transmitam conhecimento de forma clara e atrativa.",
            "entertainment": "Crie t√≠tulos divertidos e envolventes para entretenimento, usando humor e criatividade."
        },
        "premises": {
            "default": "Baseado no t√≠tulo '{title}', crie uma premissa detalhada para um v√≠deo.\n\nA premissa deve:\n- Ter aproximadamente {word_count} palavras\n- Explicar o conceito principal do v√≠deo\n- Definir o p√∫blico-alvo\n- Estabelecer o tom e estilo\n- Incluir pontos-chave a serem abordados\n- Ser envolvente e clara\n\nRetorne apenas a premissa, sem formata√ß√£o extra."
        },
        "scripts": {
            "default": "Crie um roteiro envolvente com {chapters} cap√≠tulos, baseado no t√≠tulo '{title}' e premissa: {premise}. Dura√ß√£o alvo: {duration_target}."
        },
        "images": {
            "default": "Crie uma descri√ß√£o detalhada para gera√ß√£o de imagem baseada no contexto: {context}. A imagem deve ser visualmente atrativa e relevante ao conte√∫do."
        }
    }

class PipelineService:
    """Servi√ßo principal de orquestra√ß√£o do pipeline"""
    
    def __init__(self, pipeline_id: str):
        self.pipeline_id = pipeline_id
        self.pipeline_state = None
        self.config = None
        self.api_keys = None
        self.results = {}
        self.custom_prompts = None
        
        # Importar estado do pipeline
        self._load_pipeline_state()
        
        # Carregar prompts personalizados
        self._load_custom_prompts()
        
        # Inicializar servi√ßo de checkpoint
        self.checkpoint_service = CheckpointService(pipeline_id)
        self.auto_checkpoint = self.config.get('auto_checkpoint', True) if self.config else True
        
        # Adicionar controle de threading para pausar/retomar
        import threading
        self._pause_event = threading.Event()
        self._pause_event.set()  # Iniciar como n√£o pausado
    
    def _load_custom_prompts(self):
        """Carregar prompts personalizados"""
        try:
            self.custom_prompts = load_custom_prompts()
            self._log('info', 'Prompts personalizados carregados com sucesso')
        except Exception as e:
            self._log('warning', f'Erro ao carregar prompts personalizados: {str(e)}')
            self.custom_prompts = get_default_prompts()
    
    def _load_pipeline_state(self):
        """Carregar estado do pipeline"""
        try:
            from routes.pipeline_complete import active_pipelines
            if self.pipeline_id in active_pipelines:
                self.pipeline_state = active_pipelines[self.pipeline_id]
                self.config = self.pipeline_state.get('config', {})
                self.api_keys = self.pipeline_state.get('api_keys', {})
                
                # Log de debug para verificar as etapas carregadas
                steps = self.pipeline_state.get('steps', {})
                step_names = list(steps.keys())
                self._log('info', f'Pipeline state carregado com etapas: {step_names}')
                
                # Verificar se script_processing est√° presente
                if 'SCRIPT_PROCESSING' in steps:
                    self._log('info', 'Etapa SCRIPT_PROCESSING encontrada no estado')
                else:
                    self._log('warning', 'Etapa SCRIPT_PROCESSING N√ÉO encontrada no estado')
            else:
                raise Exception(f"Pipeline {self.pipeline_id} n√£o encontrado")
        except Exception as e:
            logger.error(f"Erro ao carregar estado do pipeline: {str(e)}")
            raise
    
    def _create_project_directory(self) -> str:
        """Criar estrutura de diret√≥rios para o projeto"""
        try:
            # Criar diret√≥rio do projeto
            project_dir = os.path.join(os.path.dirname(__file__), '..', 'projects', self.pipeline_id)
            os.makedirs(project_dir, exist_ok=True)
            
            # Criar subdiret√≥rios
            subdirs = ['texts', 'images', 'audio', 'video']
            for subdir in subdirs:
                os.makedirs(os.path.join(project_dir, subdir), exist_ok=True)
            
            # Criar arquivo de metadados do projeto
            metadata = {
                'pipeline_id': self.pipeline_id,
                'created_at': datetime.utcnow().isoformat(),
                'config': self.config,
                'status': 'created'
            }
            
            metadata_path = os.path.join(project_dir, 'metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            self._log('info', f'Estrutura de diret√≥rios do projeto criada: {project_dir}')
            return project_dir
            
        except Exception as e:
            self._log('error', f'Erro ao criar estrutura de diret√≥rios do projeto: {str(e)}')
            raise
    
    def _log(self, level: str, message: str, data: Optional[Dict] = None):
        """Adicionar log ao pipeline"""
        try:
            from routes.pipeline_complete import add_pipeline_log
            add_pipeline_log(self.pipeline_id, level, message, data)
        except Exception as e:
            logger.error(f"Erro ao adicionar log: {str(e)}")
    
    def _save_checkpoint(self, current_step: str):
        """Salvar checkpoint do estado atual"""
        try:
            success = self.checkpoint_service.save_checkpoint(
                step=current_step,
                results=self.results,
                config=self.config,
                progress=getattr(self, 'progress', {})
            )
            
            if success:
                self._log('info', f'Checkpoint salvo para etapa: {current_step}')
            else:
                self._log('warning', f'Falha ao salvar checkpoint para etapa: {current_step}')
                
        except Exception as e:
            self._log('error', f'Erro ao salvar checkpoint: {str(e)}')
    
    def load_from_checkpoint(self) -> bool:
        """Carregar estado a partir de checkpoint"""
        try:
            checkpoint_data = self.checkpoint_service.load_checkpoint()
            
            if not checkpoint_data:
                return False
            
            # Validar integridade do checkpoint
            if not self.checkpoint_service.validate_checkpoint_integrity(checkpoint_data):
                self._log('error', 'Checkpoint inv√°lido ou corrompido')
                return False
            
            # Restaurar estado
            self.results = checkpoint_data.get('results', {})
            if not hasattr(self, 'progress'):
                self.progress = {}
            self.progress.update(checkpoint_data.get('progress', {}))
            self.config.update(checkpoint_data.get('config', {}))
            
            # Criar relat√≥rio de recupera√ß√£o
            recovery_report = self.checkpoint_service.create_recovery_report(checkpoint_data)
            
            self._log('info', 'Estado restaurado a partir de checkpoint', {
                'completed_steps': recovery_report['completed_steps'],
                'next_step': recovery_report['next_step'],
                'checkpoint_timestamp': recovery_report['checkpoint_timestamp']
            })
            
            return True
            
        except Exception as e:
            self._log('error', f'Erro ao carregar checkpoint: {str(e)}')
            return False
    
    def get_resume_info(self) -> Optional[Dict[str, Any]]:
        """Obter informa√ß√µes para retomada da pipeline"""
        try:
            if not self.checkpoint_service.has_checkpoint():
                return None
            
            checkpoint_data = self.checkpoint_service.load_checkpoint()
            if not checkpoint_data:
                return None
            
            return self.checkpoint_service.create_recovery_report(checkpoint_data)
            
        except Exception as e:
            self._log('error', f'Erro ao obter informa√ß√µes de retomada: {str(e)}')
            return None
    
    def _update_progress(self, step: str, progress: int, status: str = 'processing'):
        """Atualizar progresso do pipeline"""
        try:
            from routes.pipeline_complete import update_pipeline_progress
            update_pipeline_progress(self.pipeline_id, step, progress, status)
            
            # Salvar checkpoint se habilitado
            if self.auto_checkpoint and progress == 100:
                self._save_checkpoint(step)
                
        except Exception as e:
            logger.error(f"Erro ao atualizar progresso: {str(e)}")
    
    # ================================
    # üéØ ETAPA 1: EXTRA√á√ÉO DE T√çTULOS
    # ================================
    
    def run_extraction(self) -> Dict[str, Any]:
        """Executar extra√ß√£o de t√≠tulos do YouTube"""
        try:
            self._log('info', 'Iniciando extra√ß√£o de t√≠tulos do YouTube')
            
            channel_url = self.pipeline_state['channel_url']
            extraction_config = self.config.get('extraction', {})
            
            method = extraction_config.get('method', 'auto')
            max_titles_final = extraction_config.get('max_titles', 10)  # Renomeado para evitar confus√£o
            min_views = extraction_config.get('min_views', 1000)
            
            # Verificar se h√° t√≠tulos pr√©-fornecidos (m√©todo manual)
            if method == 'manual' and 'provided_titles' in extraction_config:
                self._log('info', 'Usando t√≠tulos pr√©-fornecidos (m√©todo manual)')
                provided_titles = extraction_config['provided_titles']
                
                # Converter t√≠tulos fornecidos para o formato esperado
                titles = []
                for i, title in enumerate(provided_titles):  # Sem limite inicial
                    if isinstance(title, str):
                        titles.append({
                            'title': title,
                            'video_id': f'manual_{i}',
                            'views': min_views + 1000,  # Garantir que passa no filtro
                            'description': '',
                            'thumbnail': '',
                            'duration': '5:00',
                            'likes': 100,
                            'published_at': datetime.utcnow().isoformat(),
                            'url': f'https://youtube.com/watch?v=manual_{i}'
                        })
                    elif isinstance(title, dict):
                        titles.append(title)
                
                # Filtrar t√≠tulos com visualiza√ß√µes insuficientes (apesar de termos definido como min_views + 1000)
                if min_views > 0:
                    titles = [t for t in titles if t.get('views', 0) >= min_views]
                
                # Aplicar limite final
                titles = titles[:max_titles_final]
                
                self._update_progress('extraction', 100)
                
                extraction_result = {
                    'channel_info': {'name': 'Manual Input', 'id': 'manual'},
                    'titles': titles,
                    'total_extracted': len(titles),
                    'method_used': 'manual',
                    'extraction_time': datetime.utcnow().isoformat()
                }
                
                self.results['extraction'] = extraction_result
                
                self._log('info', f'Extra√ß√£o manual conclu√≠da: {len(titles)} t√≠tulos fornecidos', {
                    'total_titles': len(titles),
                    'method': 'manual'
                })
                
                return extraction_result
            
            # Importar fun√ß√£o de extra√ß√£o para m√©todos autom√°ticos
            from routes.automations import get_channel_videos_ytdlp, get_channel_videos_rapidapi, get_next_rapidapi_key, extract_channel_id_from_url
            
            self._update_progress('extraction', 25)
            
            # Tentar extra√ß√£o baseada no m√©todo configurado
            # IMPORTANTE: Extrair com uma quantidade maior para ter amostra suficiente para filtragem
            extraction_limit = max(max_titles_final * 5, 50)  # Extrair pelo menos 50 ou 5x o valor final desejado
            
            if method in ['ytdlp', 'yt-dlp'] or method == 'auto':
                self._log('info', f'Tentando extra√ß√£o com yt-dlp (extraindo {extraction_limit} v√≠deos para filtragem)')
                result = get_channel_videos_ytdlp(channel_url, extraction_limit)
                
                if not result.get('success') and method == 'auto':
                    self._log('warning', 'yt-dlp falhou, tentando RapidAPI como fallback')
                    self._update_progress('extraction', 50)
                    # Obter chave RapidAPI e extrair channel_id
                    api_key = get_next_rapidapi_key()
                    if not api_key:
                        raise Exception("Nenhuma chave RapidAPI dispon√≠vel")
                    channel_id = extract_channel_id_from_url(channel_url, api_key)
                    if not channel_id:
                        raise Exception(f"N√£o foi poss√≠vel extrair channel_id da URL: {channel_url}")
                    result = get_channel_videos_rapidapi(channel_id, api_key, extraction_limit)
            
            elif method == 'rapidapi':
                self._log('info', f'Usando extra√ß√£o com RapidAPI (extraindo {extraction_limit} v√≠deos para filtragem)')
                # Obter chave RapidAPI e extrair channel_id
                api_key = get_next_rapidapi_key()
                if not api_key:
                    raise Exception("Nenhuma chave RapidAPI dispon√≠vel")
                channel_id = extract_channel_id_from_url(channel_url, api_key)
                if not channel_id:
                    raise Exception(f"N√£o foi poss√≠vel extrair channel_id da URL: {channel_url}")
                result = get_channel_videos_rapidapi(channel_id, api_key, extraction_limit)
            
            else:
                raise Exception(f"M√©todo de extra√ß√£o inv√°lido: {method}")
            
            if not result.get('success'):
                raise Exception(f"Falha na extra√ß√£o: {result.get('error', 'Erro desconhecido')}")
            
            # Filtrar por visualiza√ß√µes m√≠nimas (ETAPA 1: FILTRAGEM)
            titles_data = result.get('data', {})
            # Verificar se os dados est√£o em 'titles' ou 'videos'
            titles = titles_data.get('titles', titles_data.get('videos', []))
            
            original_count = len(titles)
            if min_views > 0:
                # Filtrar t√≠tulos com visualiza√ß√µes m√≠nimas
                filtered_titles = [title for title in titles if title.get('views', 0) >= min_views]
                self._log('info', f'Filtrados {len(filtered_titles)} t√≠tulos com mais de {min_views} visualiza√ß√µes (de {original_count} extra√≠dos)')
                
                # Aplicar limite final ap√≥s filtragem
                titles = filtered_titles[:max_titles_final]
            else:
                # Aplicar limite final se n√£o houver filtro por visualiza√ß√µes
                titles = titles[:max_titles_final]
            
            # Verificar se algum t√≠tulo passou no filtro
            if not titles:
                # Criar t√≠tulos simulados se nenhum t√≠tulo passou no filtro
                self._log('warning', 'Nenhum t√≠tulo passou no filtro, criando t√≠tulos simulados')
                # Criar t√≠tulos simulados
                titles = []
                for i in range(max_titles_final):
                    titles.append({
                        'title': f'T√≠tulo simulado {i+1}',
                        'video_id': f'simulado_{i}',
                        'views': min_views + 1000,  # Garantir que passa no filtro
                        'description': 'Descri√ß√£o simulada para teste',
                        'thumbnail': '',
                        'duration': '5:00',
                        'likes': 100,
                        'published_at': datetime.utcnow().isoformat(),
                        'url': f'https://youtube.com/watch?v=simulado_{i}'
                    })
            
            self._update_progress('extraction', 100)
            
            extraction_result = {
                'channel_info': titles_data.get('channel_info', {}),
                'titles': titles,
                'total_extracted': len(titles),
                'method_used': result.get('method', method),
                'extraction_time': datetime.utcnow().isoformat()
            }
            
            self.results['extraction'] = extraction_result
            
            # Salvar t√≠tulos extra√≠dos em arquivo de texto na pasta do projeto
            timestamp = int(time.time())
            extraction_filename = f"extraction_{timestamp}.txt"
            
            # Criar conte√∫do com t√≠tulos extra√≠dos
            extraction_content = "T√çTULOS EXTRA√çDOS\n=================\n\n"
            extraction_content += f"Canal: {titles_data.get('channel_info', {}).get('name', 'Desconhecido')}\n"
            extraction_content += f"M√©todo: {result.get('method', method)}\n"
            extraction_content += f"Data: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            extraction_content += f"T√çTULOS ({len(titles)} t√≠tulos)\n\n"
            
            for i, title in enumerate(titles, 1):
                extraction_content += f"{i}. {title.get('title', 'Sem t√≠tulo')}\n"
                extraction_content += f"   Visualiza√ß√µes: {title.get('views', 0)}\n"
                extraction_content += f"   Dura√ß√£o: {title.get('duration', 'N/A')}\n"
                extraction_content += f"   URL: {title.get('url', '#')}\n\n"
            
            extraction_filepath = self._save_text_file(extraction_content, extraction_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            extraction_result['file_path'] = extraction_filepath
            extraction_result['filename'] = extraction_filename
            
            self._log('info', f'Extra√ß√£o conclu√≠da: {len(titles)} t√≠tulos extra√≠dos ap√≥s filtragem e limita√ß√£o', {
                'total_titles': len(titles),
                'method': result.get('method', method),
                'channel': titles_data.get('channel_info', {}).get('name', 'Desconhecido'),
                'min_views': min_views,
                'file_saved': extraction_filename
            })
            
            return extraction_result
            
        except Exception as e:
            self._log('error', f'Erro na extra√ß√£o: {str(e)}')
            raise
    
    # ================================
    # üéØ ETAPA 2: GERA√á√ÉO DE T√çTULOS
    # ================================
    
    def run_titles_generation(self) -> Dict[str, Any]:
        """Executar gera√ß√£o de novos t√≠tulos"""
        try:
            self._log('info', 'Iniciando gera√ß√£o de novos t√≠tulos')
            
            # Verificar se temos t√≠tulos extra√≠dos
            if 'extraction' not in self.results:
                raise Exception('Extra√ß√£o de t√≠tulos n√£o foi executada')
            
            extracted_titles = self.results['extraction']['titles']
            if not extracted_titles:
                raise Exception('Nenhum t√≠tulo foi extra√≠do')
            
            titles_config = self.config.get('titles', {})
            provider = titles_config.get('provider', 'gemini')
            count = titles_config.get('count', 5)
            style = titles_config.get('style', 'viral')
            custom_prompt = titles_config.get('custom_prompt', False)
            
            self._update_progress('titles', 25)
            
            # Preparar t√≠tulos de origem
            source_titles = [title.get('title', '') for title in extracted_titles]
            
            # PRIORIDADE DE PROMPTS: Custom > Agent > System Default
            prompt_source = 'system_default'
            instructions = ''
            
            # 1. PRIMEIRA PRIORIDADE: Custom prompt do usu√°rio
            if custom_prompt and 'custom_instructions' in titles_config:
                instructions = titles_config['custom_instructions']
                prompt_source = 'custom_user'
                self._log('info', f'üé≠ Usando prompt personalizado do usu√°rio para t√≠tulos')
            
            # 2. SEGUNDA PRIORIDADE: Agent prompt especializado
            elif 'agent_prompts' in titles_config and style in titles_config['agent_prompts']:
                instructions = titles_config['agent_prompts'][style]
                prompt_source = 'agent_specialized'
                agent_info = self.config.get('agent', {})
                agent_name = agent_info.get('name', 'Agente Especializado')
                self._log('info', f'üéÜ Usando prompt do agente "{agent_name}" - Estilo: {style}')
            
            # 3. TERCEIRA PRIORIDADE: System default
            else:
                # Usar prompts personalizados carregados ou padr√£o do sistema
                titles_prompts = self.custom_prompts.get('titles', {})
                instructions = titles_prompts.get(style, titles_prompts.get('viral', 'Crie t√≠tulos virais e chamativos que gerem curiosidade e cliques'))
                prompt_source = 'system_default'
                self._log('info', f'üìù Usando prompt padr√£o do sistema - Estilo: {style}')
            
            self._update_progress('titles', 50)
            
            # Log do provedor sendo usado
            self._log('info', f'Provedor de IA para t√≠tulos: {provider}')
            
            # Gerar t√≠tulos usando o provedor configurado
            if provider == 'gemini':
                from services.ai_services import generate_titles_with_gemini
                # For√ßar reset das chaves Gemini para garantir disponibilidade
                try:
                    from routes.automations import GEMINI_KEYS_ROTATION
                    from datetime import datetime
                    GEMINI_KEYS_ROTATION['usage_count'] = {}
                    GEMINI_KEYS_ROTATION['current_index'] = 0
                    GEMINI_KEYS_ROTATION['last_reset'] = datetime.now().date()
                    self._log('info', 'Reset das chaves Gemini aplicado na pipeline')
                except Exception as reset_error:
                    self._log('warning', f'Erro no reset das chaves Gemini: {reset_error}')
                
                # Usar sistema de rota√ß√£o de chaves em vez de chave fixa
                api_key = None  # Deixar None para usar get_next_gemini_key() automaticamente
                def update_titles_partial(current_titles):
                    self.results['titles'] = {'generated_titles': current_titles, 'partial': True}
                    progress = int((len(current_titles) / count) * 100)
                    self._update_progress('titles', progress)
                result = generate_titles_with_gemini(source_titles, instructions, api_key, update_callback=update_titles_partial, count=count)
            
            elif provider == 'auto':
                # Tentar OpenAI primeiro, depois Gemini em caso de erro
                try:
                    from services.ai_services import generate_titles_with_openai
                    api_key = self.api_keys.get('openai')
                    def update_titles_partial(current_titles):
                        self.results['titles'] = {'generated_titles': current_titles, 'partial': True}
                        progress = int((len(current_titles) / count) * 100)
                        self._update_progress('titles', progress)
                    result = generate_titles_with_openai(source_titles, instructions, api_key, update_callback=update_titles_partial)
                    self._log('info', 'T√≠tulos gerados com OpenAI (auto mode)')
                except Exception as e:
                    error_msg = str(e).lower()
                    if '429' in error_msg or 'quota' in error_msg or 'insufficient_quota' in error_msg:
                        self._log('warning', f'OpenAI falhou (quota excedida), tentando Gemini: {str(e)}')
                        try:
                            from services.ai_services import generate_titles_with_gemini
                            # For√ßar reset das chaves Gemini para garantir disponibilidade
                            try:
                                from routes.automations import GEMINI_KEYS_ROTATION
                                from datetime import datetime
                                GEMINI_KEYS_ROTATION['usage_count'] = {}
                                GEMINI_KEYS_ROTATION['current_index'] = 0
                                GEMINI_KEYS_ROTATION['last_reset'] = datetime.now().date()
                                self._log('info', 'Reset das chaves Gemini aplicado na pipeline (fallback)')
                            except Exception as reset_error:
                                self._log('warning', f'Erro no reset das chaves Gemini: {reset_error}')
                            
                            # Usar sistema de rota√ß√£o de chaves em vez de chave fixa
                            api_key = None  # Deixar None para usar get_next_gemini_key() automaticamente
                            def update_titles_partial(current_titles):
                                self.results['titles'] = {'generated_titles': current_titles, 'partial': True}
                                progress = int((len(current_titles) / count) * 100)
                                self._update_progress('titles', progress)
                            result = generate_titles_with_gemini(source_titles, instructions, api_key, update_callback=update_titles_partial, count=count)
                            self._log('info', 'T√≠tulos gerados com Gemini (fallback)')
                        except Exception as gemini_error:
                            self._log('error', f'Gemini tamb√©m falhou: {str(gemini_error)}')
                            raise Exception(f'Ambos provedores falharam - OpenAI: {str(e)}, Gemini: {str(gemini_error)}')
                    else:
                        raise e
            
            else:
                raise Exception(f"Provedor de IA inv√°lido: {provider}")
            
            if not result.get('success'):
                raise Exception(f"Falha na gera√ß√£o de t√≠tulos: {result.get('error', 'Erro desconhecido')}")
            
            self._update_progress('titles', 100)
            
            titles_result = {
                'generated_titles': result['data']['generated_titles'][:count],
                'source_titles_count': len(source_titles),
                'provider_used': provider,
                'style': style,
                'prompt_source': prompt_source,  # Indicar origem do prompt
                'agent_info': self.config.get('agent', {}) if prompt_source == 'agent_specialized' else None,
                'generation_time': datetime.utcnow().isoformat(),
                'selected_title': result['data']['generated_titles'][0] if result['data']['generated_titles'] else None,
                'original_title': extracted_titles[0].get('title', '') if extracted_titles else None,
                'original_video_url': extracted_titles[0].get('url', '') if extracted_titles else None
            }
            
            self.results['titles'] = titles_result
            
            # Salvar t√≠tulos na pasta do projeto
            timestamp = int(time.time())
            titles_filename = f"titles_{timestamp}.txt"
            titles_content = "T√çTULOS GERADOS\n==================\n\n"
            for i, title in enumerate(titles_result["generated_titles"], 1):
                titles_content += f"{i}. {title}\n"
            
            titles_filepath = self._save_text_file(titles_content, titles_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            titles_result['file_path'] = titles_filepath
            titles_result['filename'] = titles_filename
            
            self._log('info', f'Gera√ß√£o de t√≠tulos conclu√≠da: {len(titles_result["generated_titles"])} t√≠tulos gerados', {
                'provider': provider,
                'style': style,
                'count': len(titles_result['generated_titles']),
                'file_saved': titles_filename
            })
            
            return titles_result
            
        except Exception as e:
            self._log('error', f'Erro na gera√ß√£o de t√≠tulos: {str(e)}')
            raise
    
    # ================================
    # üéØ ETAPA 3: GERA√á√ÉO DE PREMISSAS
    # ================================
    
    def run_premises_generation(self) -> Dict[str, Any]:
        """Executar gera√ß√£o de premissas"""
        try:
            self._log('info', 'Iniciando gera√ß√£o de premissas')
            
            # Verificar se temos t√≠tulos gerados
            if 'titles' not in self.results:
                raise Exception('Gera√ß√£o de t√≠tulos n√£o foi executada')
            
            generated_titles = self.results['titles']['generated_titles']
            if not generated_titles:
                raise Exception('Nenhum t√≠tulo foi gerado')
            
            premises_config = self.config.get('premises', {})
            provider = premises_config.get('provider', 'gemini')
            word_count = premises_config.get('word_count', 200)
            custom_prompt = premises_config.get('custom_prompt', False)
            
            self._update_progress('premises', 25)
            
            # Selecionar o melhor t√≠tulo (primeiro da lista)
            selected_title = generated_titles[0]
            
            # PRIORIDADE DE PROMPTS: Custom > Agent > System Default
            prompt_source = 'system_default'
            instructions = ''
            
            # 1. PRIMEIRA PRIORIDADE: Custom prompt do usu√°rio
            if custom_prompt and 'custom_instructions' in premises_config:
                instructions = premises_config['custom_instructions']
                prompt_source = 'custom_user'
                self._log('info', f'üé≠ Usando prompt personalizado do usu√°rio para premissas')
            
            # 2. SEGUNDA PRIORIDADE: Agent prompt especializado
            elif 'agent_prompts' in premises_config:
                # Para premissas, verificar estilos dispon√≠veis no agente
                agent_prompts = premises_config['agent_prompts']
                
                # Tentar encontrar um estilo compat√≠vel (narrative, educational)
                # Now we properly use the selected style from the form
                premise_style = premises_config.get('style', 'educational')
                if premise_style in agent_prompts:
                    selected_style = premise_style
                elif 'educational' in agent_prompts:
                    selected_style = 'educational'
                elif 'narrative' in agent_prompts:
                    selected_style = 'narrative'
                else:
                    # Se agente n√£o tem estilos compat√≠veis, usar primeiro dispon√≠vel
                    selected_style = list(agent_prompts.keys())[0] if agent_prompts else None
                
                if selected_style and selected_style in agent_prompts:
                    # Formatar prompt do agente com vari√°veis
                    agent_prompt_template = agent_prompts[selected_style]
                    instructions = agent_prompt_template.format(
                        title=selected_title,
                        word_count=word_count
                    )
                    prompt_source = 'agent_specialized'
                    agent_info = self.config.get('agent', {})
                    agent_name = agent_info.get('name', 'Agente Especializado')
                    self._log('info', f'üéÜ Usando prompt do agente "{agent_name}" - Estilo: {selected_style}')
                else:
                    # Fallback para sistema se agente n√£o tem estilos compat√≠veis
                    premises_prompts = self.custom_prompts.get('premises', {})
                    prompt_template = premises_prompts.get('default', 
                        "Baseado no t√≠tulo '{title}', crie uma premissa detalhada para um v√≠deo.\n\nA premissa deve:\n- Ter aproximadamente {word_count} palavras\n- Explicar o conceito principal do v√≠deo\n- Definir o p√∫blico-alvo\n- Estabelecer o tom e estilo\n- Incluir pontos-chave a serem abordados\n- Ser envolvente e clara\n\nRetorne apenas a premissa, sem formata√ß√£o extra.")
                    
                    instructions = prompt_template.format(
                        title=selected_title,
                        word_count=word_count
                    )
                    prompt_source = 'system_default'
                    self._log('info', f'üìù Usando prompt padr√£o do sistema (agente sem estilos compat√≠veis)')
            
            # 3. TERCEIRA PRIORIDADE: System default
            else:
                # Usar prompt personalizado carregado
                premises_prompts = self.custom_prompts.get('premises', {})
                prompt_template = premises_prompts.get('default', 
                    "Baseado no t√≠tulo '{title}', crie uma premissa detalhada para um v√≠deo.\n\nA premissa deve:\n- Ter aproximadamente {word_count} palavras\n- Explicar o conceito principal do v√≠deo\n- Definir o p√∫blico-alvo\n- Estabelecer o tom e estilo\n- Incluir pontos-chave a serem abordados\n- Ser envolvente e clara\n\nRetorne apenas a premissa, sem formata√ß√£o extra.")
                
                # Substituir vari√°veis no template
                instructions = prompt_template.format(
                    title=selected_title,
                    word_count=word_count
                )
                prompt_source = 'system_default'
                self._log('info', f'üìù Usando prompt padr√£o do sistema para premissas')
            
            self._update_progress('premises', 50)
            
            # Gerar premissa usando o provedor configurado
            if provider == 'gemini':
                import google.generativeai as genai
                # Usar sistema de rota√ß√£o de chaves diretamente
                from routes.automations import get_next_gemini_key, handle_gemini_429_error, get_fallback_provider_info
                api_key = get_next_gemini_key()
                
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                premise_text = ''
                for chunk in model.generate_content(instructions, stream=True):
                    premise_text += chunk.text
                    self.results['premises'] = {'premise': premise_text, 'partial': True}
                    # Atualizar progresso baseado em comprimento aproximado
                    current_length = len(premise_text.split())
                    progress = min(int((current_length / word_count) * 100), 99)
                    self._update_progress('premises', progress)
            
            elif provider == 'openai':
                import openai
                api_key = self.api_keys.get('openai')
                client = openai.OpenAI(api_key=api_key)
                
                premise_text = ''
                stream = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": instructions}],
                    max_tokens=500,
                    temperature=0.7,
                    stream=True
                )
                for chunk in stream:
                    if chunk.choices[0].delta.content is not None:
                        premise_text += chunk.choices[0].delta.content
                        self.results['premises'] = {'premise': premise_text, 'partial': True}
                        current_length = len(premise_text.split())
                        progress = min(int((current_length / word_count) * 100), 99)
                        self._update_progress('premises', progress)
            
            elif provider == 'auto':
                # Tentar OpenAI primeiro, depois Gemini em caso de erro
                try:
                    import openai
                    api_key = self.api_keys.get('openai')
                    client = openai.OpenAI(api_key=api_key)
                    
                    premise_text = ''
                    stream = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": instructions}],
                        max_tokens=500,
                        temperature=0.7,
                        stream=True
                    )
                    for chunk in stream:
                        if chunk.choices[0].delta.content is not None:
                            premise_text += chunk.choices[0].delta.content
                            self.results['premises'] = {'premise': premise_text, 'partial': True}
                            current_length = len(premise_text.split())
                            progress = min(int((current_length / word_count) * 100), 99)
                            self._update_progress('premises', progress)
                    self._log('info', 'Premissa gerada com OpenAI (auto mode)')
                except Exception as e:
                    error_msg = str(e).lower()
                    if '429' in error_msg or 'quota' in error_msg or 'insufficient_quota' in error_msg:
                        self._log('warning', f'OpenAI falhou (quota excedida), tentando Gemini: {str(e)}')
                        # Tentar Gemini como fallback prim√°rio
                        try:
                            import google.generativeai as genai
                            api_key = self.api_keys.get('gemini')
                            if not api_key:
                                api_key = get_next_gemini_key()
                            
                            if not api_key:
                                raise Exception('Nenhuma chave Gemini dispon√≠vel para fallback.')

                            genai.configure(api_key=api_key)
                            model = genai.GenerativeModel('gemini-1.5-flash')
                            premise_text = ''
                            for chunk in model.generate_content(instructions, stream=True):
                                premise_text += chunk.text
                                self.results['premises'] = {'premise': premise_text, 'partial': True}
                                current_length = len(premise_text.split())
                                progress = min(int((current_length / word_count) * 100), 99)
                                self._update_progress('premises', progress)
                            self._log('info', 'Premissa gerada com Gemini (fallback)')
                        except Exception as gemini_error:
                            self._log('error', f'Gemini tamb√©m falhou: {str(gemini_error)}')
                            # Se Gemini falhar, tentar OpenRouter ou OpenAI
                            fallback_info = get_fallback_provider_info()
                            if fallback_info:
                                fallback_provider = fallback_info['provider']
                                fallback_key = fallback_info['key']
                                self._log('warning', f'Tentando fallback para {fallback_provider}...')
                                try:
                                    if fallback_provider == 'openrouter':
                                        client = openai.OpenAI(
                                            base_url="https://openrouter.ai/api/v1",
                                            api_key=fallback_key,
                                        )
                                        model_name = "mistralai/mistral-7b-instruct"
                                    elif fallback_provider == 'openai':
                                        client = openai.OpenAI(api_key=fallback_key)
                                        model_name = "gpt-3.5-turbo"
                                    
                                    premise_text = ''
                                    stream = client.chat.completions.create(
                                        model=model_name,
                                        messages=[{"role": "user", "content": instructions}],
                                        max_tokens=500,
                                        temperature=0.7,
                                        stream=True
                                    )
                                    for chunk in stream:
                                        if chunk.choices[0].delta.content is not None:
                                            premise_text += chunk.choices[0].delta.content
                                            self.results['premises'] = {'premise': premise_text, 'partial': True}
                                            current_length = len(premise_text.split())
                                            progress = min(int((current_length / word_count) * 100), 99)
                                            self._update_progress('premises', progress)
                                    self._log('info', f'Premissa gerada com {fallback_provider} (fallback)')
                                except Exception as fallback_e:
                                    self._log('error', f'Fallback para {fallback_provider} tamb√©m falhou: {str(fallback_e)}')
                                    raise Exception(f'Todos os provedores falharam - OpenAI: {str(e)}, Gemini: {str(gemini_error)}, Fallback ({fallback_provider}): {str(fallback_e)}')
                            else:
                                raise Exception(f'Ambos provedores falharam e nenhum fallback dispon√≠vel - OpenAI: {str(e)}, Gemini: {str(gemini_error)}')
                        except Exception as inner_e:
                            self._log('error', f'Erro no fallback Gemini: {str(inner_e)}')
                            raise e
                    else:
                        raise e
            
            else:
                raise Exception(f"Provedor de IA inv√°lido: {provider}")
            
            self._update_progress('premises', 100)
            
            premises_result = {
                'selected_title': selected_title,
                'premises': [{
                    'title': selected_title,
                    'premise': premise_text,
                    'word_count': len(premise_text.split())
                }],
                'premise': premise_text,  # Manter compatibilidade
                'word_count': len(premise_text.split()),
                'provider_used': provider,
                'style': premises_config.get('style', 'educational'),  # Add style information
                'prompt_source': prompt_source,  # Indicar origem do prompt
                'agent_info': self.config.get('agent', {}) if prompt_source == 'agent_specialized' else None,
                'generation_time': datetime.utcnow().isoformat()
            }
            
            self.results['premises'] = premises_result
            
            # Salvar premissas na pasta do projeto
            timestamp = int(time.time())
            premises_filename = f"premises_{timestamp}.txt"
            premises_content = f"T√çTULO SELECIONADO\n==================\n{selected_title}\n\n"
            premises_content += f"PREMISSA GERADA\n===============\n{premise_text}\n\n"
            premises_content += f"INFORMA√á√ïES\n============\n"
            premises_content += f"Provedor: {provider}\n"
            premises_content += f"Estilo: {premises_config.get('style', 'educational')}\n"
            premises_content += f"Contagem de palavras: {len(premise_text.split())}\n"
            premises_content += f"Origem do prompt: {prompt_source}\n"
            
            if prompt_source == 'agent_specialized':
                agent_info = self.config.get('agent', {})
                agent_name = agent_info.get('name', 'Agente Especializado')
                premises_content += f"Agente: {agent_name}\n"
            
            premises_filepath = self._save_text_file(premises_content, premises_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            premises_result['file_path'] = premises_filepath
            premises_result['filename'] = premises_filename
            
            self._log('info', 'Gera√ß√£o de premissas conclu√≠da', {
                'title': selected_title,
                'word_count': len(premise_text.split()),
                'provider': provider,
                'file_saved': premises_filename
            })
            
            return premises_result
            
        except Exception as e:
            self._log('error', f'Erro na gera√ß√£o de premissas: {str(e)}')
            raise
    
    def _save_text_file(self, content: str, filename: str) -> str:
        """Salvar arquivo de texto na pasta do projeto"""
        try:
            # Criar diret√≥rio do projeto se n√£o existir
            project_dir = os.path.join(os.path.dirname(__file__), '..', 'projects', self.pipeline_id)
            texts_dir = os.path.join(project_dir, 'texts')
            os.makedirs(texts_dir, exist_ok=True)
            
            # Caminho completo do arquivo
            filepath = os.path.join(texts_dir, filename)
            
            # Salvar arquivo
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._log('info', f'Texto salvo: {filename}')
            return filepath
            
        except Exception as e:
            self._log('error', f'Erro ao salvar arquivo de texto: {str(e)}')
            raise
    
    def run_scripts_generation(self) -> Dict[str, Any]:
        """Executar gera√ß√£o de roteiros"""
        try:
            self._log('info', 'Iniciando gera√ß√£o de roteiros')
            
            # Verificar se temos premissa
            if 'premises' not in self.results:
                raise Exception('Gera√ß√£o de premissas n√£o foi executada')
            
            premise_data = self.results['premises']
            title = premise_data['selected_title']
            premise = premise_data['premise']
            
            scripts_config = self.config.get('scripts', {})
            chapters = scripts_config.get('chapters', 5)
            style = scripts_config.get('style', 'inicio')
            duration_target = scripts_config.get('duration_target', '5-7 minutes')
            include_hooks = scripts_config.get('include_hooks', True)
            
            self._update_progress('scripts', 25)
            
            # Importar gerador de roteiros
            from routes.scripts import generate_long_script
            
            # Importar fun√ß√µes auxiliares para prompts de roteiro
            from routes.premise import create_inicio_prompt, create_capitulo_prompt, create_final_prompt
            
            # Obter prompts personalizados de roteiros
            scripts_config = self.config.get('scripts', {})
            custom_inicio = scripts_config.get('custom_inicio', '')
            custom_meio = scripts_config.get('custom_meio', '')
            custom_fim = scripts_config.get('custom_fim', '')
            
            # Preparar dados para gera√ß√£o
            script_data = {
                'title': title,
                'premise': premise,
                'chapters': chapters,
                'style': style,
                'duration_target': duration_target,
                'include_hooks': include_hooks,
                'custom_inicio': custom_inicio,
                'custom_meio': custom_meio,
                'custom_fim': custom_fim,
                'detailed_prompt_text': scripts_config.get('detailed_prompt_text', ''),
                'detailed_prompt': scripts_config.get('detailed_prompt', False),
                'contextual_chapters': scripts_config.get('contextual_chapters', False)
            }
            
            self._update_progress('scripts', 50)
            
            def update_scripts_partial(chapters):
                partial_data = {
                    'chapters': chapters,
                    'partial': True,
                    'chapters_generated': len(chapters)
                }
                self.results['scripts'] = partial_data
                if 'results' not in self.pipeline_state:
                    self.pipeline_state['results'] = {}
                self.pipeline_state['results']['scripts'] = partial_data
                progress = int((len(chapters) / max(1, num_chapters)) * 100) if len(chapters) > 0 else 0
                self._update_progress('scripts', progress)

            # Usar Storyteller Unlimited para 100% dos roteiros
            from services.storyteller_service import StorytellerService
            
            # Obter configura√ß√µes do Storyteller com fallback para configura√ß√µes legadas
            agent_type = scripts_config.get('storyteller_agent') or scripts_config.get('agent', 'millionaire_stories')
            num_chapters = scripts_config.get('storyteller_chapters') or scripts_config.get('chapters', 5)
            
            # Criar inst√¢ncia do servi√ßo
            storyteller_service = StorytellerService()
            
            # Preparar premissa com instru√ß√µes customizadas se fornecidas
            custom_instructions = scripts_config.get('custom_instructions')
            if custom_instructions:
                enhanced_premise = f"{premise}\n\nInstru√ß√µes adicionais: {custom_instructions}"
            else:
                enhanced_premise = premise
            
            # Adicionar prompts personalizados da configura√ß√£o como contexto adicional
            custom_context = ""
            if scripts_config.get('custom_prompt', False):
                custom_inicio = scripts_config.get('custom_inicio', '')
                custom_meio = scripts_config.get('custom_meio', '')
                custom_fim = scripts_config.get('custom_fim', '')
                
                if custom_inicio or custom_meio or custom_fim:
                    custom_context = f"\n\nContexto adicional:\nIn√≠cio: {custom_inicio}\nMeio: {custom_meio}\nFim: {custom_fim}"
                    enhanced_premise += custom_context
            
            # Gerar roteiro com Storyteller Unlimited usando rota√ß√£o autom√°tica de chaves
            result = storyteller_service.generate_storyteller_script(
                title=title,
                premise=enhanced_premise,
                agent_type=agent_type,
                num_chapters=num_chapters,
                provider='gemini',
                progress_callback=update_scripts_partial,
                remove_chapter_headers=True  # Remove cabe√ßalhos de cap√≠tulos do roteiro final
                # api_key n√£o √© mais necess√°rio - usa rota√ß√£o autom√°tica
            )
            
            # Converter formato para compatibilidade
            if result.get('success'):
                result = {
                    'success': True,
                    'data': {
                        'script': result.get('full_script', ''),
                        'chapters': result.get('chapters', []),
                        'estimated_duration': result.get('estimated_duration', '5-7 minutes')
                    }
                }
            
            if not result.get('success'):
                raise Exception(f"Falha na gera√ß√£o de roteiro: {result.get('error', 'Erro desconhecido')}")
            
            self._update_progress('scripts', 100)
            
            scripts_result = {
                'title': title,
                'premise': premise,
                'script': result['data']['script'],
                'chapters': result['data'].get('chapters', []),
                'chapters_generated': len(result['data'].get('chapters', [])),
                'estimated_duration': result['data'].get('estimated_duration', duration_target),
                'style': style,
                'prompt_source': 'system_default',  # Default value, will be updated if using agent prompts
                'agent_info': None,  # Will be updated if using agent prompts
                'generation_time': datetime.utcnow().isoformat(),
                'partial': False
            }
            
            # Add prompt source information if using agent prompts
            scripts_config = self.config.get('scripts', {})
            if 'agent_prompts' in scripts_config:
                scripts_result['prompt_source'] = 'agent_specialized'
                scripts_result['agent_info'] = self.config.get('agent', {})
            
            self.results['scripts'] = scripts_result
            
            # Salvar roteiro na pasta do projeto
            timestamp = int(time.time())
            script_filename = f"script_{timestamp}.txt"
            script_filepath = self._save_text_file(scripts_result['script'], script_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            scripts_result['file_path'] = script_filepath
            scripts_result['filename'] = script_filename
            
            self._log('info', 'Gera√ß√£o de roteiros conclu√≠da', {
                'chapters': scripts_result['chapters_generated'],
                'style': style,
                'estimated_duration': scripts_result['estimated_duration'],
                'file_saved': script_filename
            })
            
            return scripts_result
            
        except Exception as e:
            self._log('error', f'Erro na gera√ß√£o de roteiros: {str(e)}')
            raise
    
    # ================================
    # üéØ ETAPA 5: PROCESSAMENTO DE ROTEIRO
    # ================================
    
    def run_script_processing(self) -> Dict[str, Any]:
        """Executar processamento e limpeza de roteiro"""
        try:
            self._log('info', 'Iniciando processamento de roteiro')
            
            # Verificar se processamento est√° habilitado na configura√ß√£o
            script_processing_config = self.config.get('script_processing', {})
            if not script_processing_config.get('enabled', True):
                self._log('info', 'Processamento de roteiro desabilitado na configura√ß√£o, pulando etapa')
                
                # Usar roteiro original sem processamento
                if 'scripts' not in self.results:
                    raise Exception('Gera√ß√£o de roteiros n√£o foi executada')
                
                script_data = self.results['scripts']
                processed_result = {
                    'processed_script': script_data['script'],
                    'original_script': script_data['script'],
                    'processing_applied': False,
                    'metrics': {
                        'original_length': len(script_data['script']),
                        'processed_length': len(script_data['script']),
                        'preservation_ratio': 1.0,
                        'headers_removed': 0
                    },
                    'processing_time': 0,
                    'status': 'skipped',
                    'message': 'Processamento desabilitado pelo usu√°rio',
                    'timestamp': datetime.utcnow().isoformat()
                }
                
                self.results['script_processing'] = processed_result
                self._update_progress('script_processing', 100)
                return processed_result
            
            # Verificar se temos roteiro
            if 'scripts' not in self.results:
                raise Exception('Gera√ß√£o de roteiros n√£o foi executada')
            
            script_data = self.results['scripts']
            raw_script = script_data['script']
            
            self._update_progress('script_processing', 25)
            
            # Criar inst√¢ncia do servi√ßo de processamento
            script_processor = ScriptProcessingService()
            
            self._update_progress('script_processing', 50)
            
            # Processar roteiro
            processing_result = script_processor.process_script(
                pipeline_id=self.pipeline_id,
                raw_script=raw_script,
                config=script_processing_config
            )
            
            self._update_progress('script_processing', 75)
            
            # Verificar se o processamento foi bem-sucedido
            if not processing_result.get('success'):
                raise Exception(f"Falha no processamento de roteiro: {processing_result.get('error', 'Erro desconhecido')}")
            
            # Atualizar resultado dos scripts com vers√£o processada
            self.results['scripts']['script'] = processing_result['processed_script']
            
            # Salvar resultado do processamento
            script_processing_result = {
                'processed_script': processing_result['processed_script'],
                'original_script': raw_script,
                'processing_applied': True,
                'metrics': processing_result['metrics'],
                'processing_time': processing_result['processing_time'],
                'config_used': processing_result['config_used'],
                'status': 'completed',
                'timestamp': processing_result['timestamp']
            }
            
            self.results['script_processing'] = script_processing_result
            
            # Salvar roteiro processado na pasta do projeto
            timestamp = int(time.time())
            processed_script_filename = f"script_processed_{timestamp}.txt"
            
            # Criar conte√∫do com informa√ß√µes de processamento
            processed_content = "ROTEIRO PROCESSADO\n==================\n\n"
            processed_content += processing_result['processed_script']
            processed_content += "\n\nINFORMA√á√ïES DE PROCESSAMENTO\n===========================\n"
            processed_content += f"Comprimento original: {processing_result['metrics']['original_length']} caracteres\n"
            processed_content += f"Comprimento processado: {processing_result['metrics']['processed_length']} caracteres\n"
            processed_content += f"Taxa de preserva√ß√£o: {processing_result['metrics']['preservation_ratio']:.2f}\n"
            processed_content += f"Cabe√ßalhos removidos: {processing_result['metrics']['headers_removed']}\n"
            processed_content += f"Tempo de processamento: {processing_result['processing_time']:.2f} segundos\n"
            
            processed_script_filepath = self._save_text_file(processed_content, processed_script_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            script_processing_result['file_path'] = processed_script_filepath
            script_processing_result['filename'] = processed_script_filename
            
            self._update_progress('script_processing', 100)
            
            self._log('info', 'Processamento de roteiro conclu√≠do', {
                'original_length': len(raw_script),
                'processed_length': len(processing_result['processed_script']),
                'preservation_ratio': processing_result['metrics']['preservation_ratio'],
                'headers_removed': processing_result['metrics']['headers_removed'],
                'processing_time': processing_result['processing_time'],
                'file_saved': processed_script_filename
            })
            
            return script_processing_result
            
        except Exception as e:
            self._log('error', f'Erro no processamento de roteiro: {str(e)}')
            raise
    
    # ================================
    # üéØ ETAPA 6: GERA√á√ÉO DE TTS
    # ================================
    
    def run_tts_generation(self) -> Dict[str, Any]:
        """Executar gera√ß√£o de √°udio TTS"""
        try:
            self._log('info', 'Iniciando gera√ß√£o de √°udio TTS')
            
            # Verificar se TTS est√° habilitado na configura√ß√£o
            tts_config = self.config.get('tts', {})
            if not tts_config.get('enabled', True):
                self._log('info', 'TTS desabilitado na configura√ß√£o, pulando etapa')
                
                # Criar resultado placeholder para compatibilidade
                tts_result = {
                    'audio_file_path': None,
                    'duration': 0,
                    'file_size': 0,
                    'provider_used': 'disabled',
                    'voice': 'none',
                    'speed': 1.0,
                    'emotion': 'neutral',
                    'generation_time': datetime.utcnow().isoformat(),
                    'status': 'skipped',
                    'message': 'TTS desabilitado pelo usu√°rio'
                }
                
                self.results['tts'] = tts_result
                self._update_progress('tts', 100)
                return tts_result
            
            # Verificar se temos roteiro
            if 'scripts' not in self.results:
                raise Exception('Gera√ß√£o de roteiros n√£o foi executada')
            
            script_data = self.results['scripts']
            script_text = script_data['script']
            
            tts_config = self.config.get('tts', {})
            provider = tts_config.get('provider', 'kokoro')
            voice = tts_config.get('voice', 'default')
            language = tts_config.get('language', 'en')  # Adicionar configura√ß√£o de idioma
            
            # Mapear voz 'default' para vozes v√°lidas por provedor
            if voice == 'default':
                if provider == 'kokoro':
                    voice = 'af_bella'  # Voz padr√£o v√°lida para Kokoro
                elif provider == 'elevenlabs':
                    voice = 'Rachel'  # Voz padr√£o v√°lida para ElevenLabs
                elif provider == 'gemini':
                    voice = 'en-US-Journey-F'  # Voz padr√£o v√°lida para Gemini
            
            speed = tts_config.get('speed', 1.0)
            emotion = tts_config.get('emotion', 'neutral')
            
            self._update_progress('tts', 25)
            
            # Importar servi√ßo de TTS
            from services.tts_service import TTSService
            
            tts_service = TTSService(self.pipeline_id)
            
            self._update_progress('tts', 50)
            
            # Gerar TTS usando o servi√ßo
            result = tts_service.generate_tts_for_script(
                script_text=script_text,
                provider=provider,
                voice_settings={
                    'voice': voice,
                    'speed': speed,
                    'emotion': emotion,
                    'language': language  # Adicionar idioma nas configura√ß√µes
                }
            )
            
            self._update_progress('tts', 100)
            
            # Verificar se o resultado do TTS foi bem-sucedido
            if not result.get('success'):
                raise Exception(f"Falha na gera√ß√£o de TTS: {result.get('error', 'Erro desconhecido')}")
            
            # Extrair nome do arquivo para criar URL
            audio_filename = None
            if result.get('audio_file_path'):
                audio_filename = os.path.basename(result['audio_file_path'])
            elif result.get('filename'):
                audio_filename = result['filename']
            
            # Criar URL para acessar o √°udio
            audio_url = None
            if audio_filename:
                audio_url = f"/api/automations/audio/{audio_filename}"
            
            tts_result = {
                'audio_file_path': result['audio_file_path'],
                'audio_url': audio_url,
                'filename': audio_filename,
                'duration': result.get('duration', 0),
                'file_size': result.get('file_size', 0),
                'provider_used': provider,
                'voice': voice,
                'speed': speed,
                'emotion': emotion,
                'segments': result.get('segments', []),
                'total_segments': result.get('total_segments', 0),
                'generation_time': datetime.utcnow().isoformat()
            }
            
            self.results['tts'] = tts_result
            
            self._log('info', 'Gera√ß√£o de TTS conclu√≠da', {
                'provider': provider,
                'duration': result['duration'],
                'file_path': result['audio_file_path'],
                'file_saved': audio_filename
            })
            
            return tts_result
            
        except Exception as e:
            self._log('error', f'Erro na gera√ß√£o de TTS: {str(e)}')
            raise
    

    
    # ================================
    # üéØ ETAPA 7: GERA√á√ÉO DE IMAGENS
    # ================================
    
    def run_images_generation(self) -> Dict[str, Any]:
        """Executar gera√ß√£o de imagens"""
        try:
            self._log('info', 'Iniciando gera√ß√£o de imagens')
            
            # Verificar se gera√ß√£o de imagens est√° habilitada na configura√ß√£o
            images_config = self.config.get('images', {})
            if not images_config.get('enabled', True):
                self._log('info', 'Gera√ß√£o de imagens desabilitada na configura√ß√£o, pulando etapa')
                
                # Criar resultado placeholder para compatibilidade
                images_result = {
                    'generated_images': [],
                    'total_images': 0,
                    'provider_used': 'disabled',
                    'style': 'none',
                    'resolution': 'none',
                    'generation_time': datetime.utcnow().isoformat(),
                    'status': 'skipped',
                    'message': 'Gera√ß√£o de imagens desabilitada pelo usu√°rio'
                }
                
                self.results['images'] = images_result
                self._update_progress('images', 100)
                return images_result
            
            # Verificar se temos roteiro
            if 'scripts' not in self.results:
                raise Exception('Gera√ß√£o de roteiros n√£o foi executada')
            
            script_data = self.results['scripts']
            script_text = script_data['script']
            
            images_config = self.config.get('images', {})
            provider = images_config.get('provider', 'pollinations')
            style = images_config.get('style', 'cinematic')
            resolution = images_config.get('resolution', '1920x1080')
            per_chapter = images_config.get('per_chapter', 2)  # Manter para compatibilidade
            total_images = images_config.get('total_images', per_chapter * 3)  # Padr√£o: 6 imagens total
            
            self._update_progress('images', 25)
            
            # Obter prompt personalizado para imagens
            images_prompts = self.custom_prompts.get('images', {})
            
            # Verificar se temos um agente espec√≠fico e se h√° um prompt personalizado para ele
            agent_type = self.config.get('agent_type', 'default')
            selected_agent = self.config.get('selected_agent', None)
            
            # Se n√£o houver agente selecionado, usar o agent_type como fallback
            if not selected_agent:
                selected_agent = agent_type
            
            # Verificar se h√° um prompt espec√≠fico para o agente selecionado
            custom_image_prompt = images_prompts.get(selected_agent, images_prompts.get('default', 'Crie uma descri√ß√£o detalhada para gera√ß√£o de imagem baseada no contexto: {context}. A imagem deve ser visualmente atrativa e relevante ao conte√∫do.'))
            
            # Importar servi√ßo de gera√ß√£o de imagens
            from services.image_generation_service import ImageGenerationService
            
            image_service = ImageGenerationService(self.pipeline_id)
            
            self._update_progress('images', 50)
            
            # Gerar imagens com prompt personalizado usando nova l√≥gica de total
            # Obter o modelo Pollinations da configura√ß√£o
            images_config = self.config.get('images', {})
            pollinations_model = images_config.get('pollinations_model', 'gpt')  # gpt ou flux
            
            result = image_service.generate_images_for_script_total(
                script_text, provider, style, resolution, total_images, custom_image_prompt, selected_agent, pollinations_model
            )
            
            self._update_progress('images', 100)
            
            images_result = {
                'generated_images': result['images'],
                'total_images': len(result['images']),
                'provider_used': provider,
                'style': style,
                'resolution': resolution,
                'generation_time': datetime.utcnow().isoformat()
            }
            
            self.results['images'] = images_result
            
            # Adicionar informa√ß√µes dos arquivos de imagens ao log
            image_filenames = [img.get('filename', 'N/A') for img in result['images']]
            
            self._log('info', 'Gera√ß√£o de imagens conclu√≠da', {
                'total_images': len(result['images']),
                'provider': provider,
                'style': style,
                'files_saved': image_filenames
            })
            
            return images_result
            
        except Exception as e:
            self._log('error', f'Erro na gera√ß√£o de imagens: {str(e)}')
            raise
    
    # ================================
    # üéØ ETAPA 7: CRIA√á√ÉO DE V√çDEO
    # ================================
    
    def run_video_creation(self) -> Dict[str, Any]:
        """Executar cria√ß√£o do v√≠deo final"""
        try:
            self._log('info', 'Iniciando cria√ß√£o do v√≠deo final')
            
            # Verificar se cria√ß√£o de v√≠deo est√° habilitada na configura√ß√£o
            video_config = self.config.get('video', {})
            if not video_config.get('enabled', True):
                self._log('info', 'Cria√ß√£o de v√≠deo desabilitada na configura√ß√£o, pulando etapa')
                
                # Criar resultado placeholder para compatibilidade
                video_result = {
                    'video_file_path': None,
                    'duration': 0,
                    'file_size': 0,
                    'resolution': 'none',
                    'fps': 0,
                    'quality': 'none',
                    'transitions': False,
                    'subtitles': False,
                    'creation_time': datetime.utcnow().isoformat(),
                    'status': 'skipped',
                    'message': 'Cria√ß√£o de v√≠deo desabilitada pelo usu√°rio'
                }
                
                self.results['video'] = video_result
                self._update_progress('video', 100)
                return video_result
            
            # Verificar quais recursos est√£o dispon√≠veis baseado nas etapas habilitadas
            available_resources = ['scripts']
            
            # Adicionar TTS se habilitado e executado
            tts_config = self.config.get('tts', {})
            if tts_config.get('enabled', True) and 'tts' in self.results and self.results['tts'].get('status') != 'skipped':
                available_resources.append('tts')
            
            # Adicionar imagens se habilitado e executado
            images_config = self.config.get('images', {})
            if images_config.get('enabled', True) and 'images' in self.results and self.results['images'].get('status') != 'skipped':
                available_resources.append('images')
            
            # Verificar se temos recursos m√≠nimos (pelo menos roteiro)
            for req in ['scripts']:
                if req not in self.results:
                    raise Exception(f'Etapa {req} n√£o foi executada')
            
            video_config = self.config.get('video', {})
            resolution = video_config.get('resolution', '1920x1080')
            fps = int(video_config.get('fps', 30))
            quality = video_config.get('quality', 'high')
            transitions = video_config.get('transitions', True)
            subtitles = video_config.get('subtitle', True)
            
            self._update_progress('video', 25)
            
            # Criar inst√¢ncia do servi√ßo de cria√ß√£o de v√≠deo
            video_service = VideoCreationService(self.pipeline_id)
            
            self._update_progress('video', 50)
            
            # Obter segmentos TTS para sincroniza√ß√£o precisa
            tts_segments = self.results['tts'].get('segments', [])
            
            # Criar v√≠deo com sincroniza√ß√£o inteligente
            # Garantir que os dados das imagens estejam no formato correto
            images_data = []
            for img in self.results['images']['generated_images']:
                if 'file_path' in img:
                    images_data.append(img)
                elif 'path' in img:
                    # Converter para o formato esperado
                    images_data.append({
                        'file_path': img['path'],
                        'filename': img.get('filename', os.path.basename(img['path']))
                    })
            
            self._log('info', f'Preparando {len(images_data)} imagens para cria√ß√£o do v√≠deo')
            
            result = video_service.create_video(
                audio_path=self.results['tts']['audio_file_path'],
                images=images_data,
                script_text=self.results['scripts']['script'],
                resolution=resolution,
                fps=fps,
                quality=quality,
                transitions=transitions,
                subtitles=subtitles,
                tts_segments=tts_segments
            )
            
            self._update_progress('video', 100)
            
            video_result = {
                'video_file_path': result['video_path'],
                'duration': result['duration'],
                'file_size': result['file_size'],
                'resolution': resolution,
                'fps': fps,
                'quality': quality,
                'creation_time': datetime.utcnow().isoformat()
            }
            
            self.results['video'] = video_result
            
            # Extrair nome do arquivo do caminho completo
            video_filename = os.path.basename(result['video_path'])
            
            self._log('info', 'Cria√ß√£o de v√≠deo conclu√≠da', {
                'video_path': result['video_path'],
                'duration': result['duration'],
                'file_size': result['file_size'],
                'file_saved': video_filename
            })
            
            return video_result
            
        except Exception as e:
            self._log('error', f'Erro na cria√ß√£o de v√≠deo: {str(e)}')
            # Salvar checkpoint mesmo em caso de erro para permitir retomada
            if self.auto_checkpoint:
                self._save_checkpoint('video_failed')
            raise
    
    # ================================
    # üéØ ETAPA 8: LIMPEZA
    # ================================
    
    def run_cleanup(self) -> Dict[str, Any]:
        """Executar limpeza de arquivos tempor√°rios"""
        try:
            self._log('info', 'Iniciando limpeza de arquivos tempor√°rios')
            
            self._update_progress('cleanup', 50)
            
            # Limpar arquivos tempor√°rios (manter apenas o v√≠deo final)
            temp_files = []
            
            # Adicionar arquivos tempor√°rios √† lista de limpeza
            if 'tts' in self.results:
                temp_files.append(self.results['tts']['audio_file_path'])
            
            if 'images' in self.results:
                for image in self.results['images']['generated_images']:
                    if 'temp_path' in image:
                        temp_files.append(image['temp_path'])
            
            # Remover arquivos tempor√°rios
            cleaned_files = []
            cleaned_filenames = []
            for file_path in temp_files:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        cleaned_files.append(file_path)
                        cleaned_filenames.append(os.path.basename(file_path))
                except Exception as e:
                    self._log('warning', f'N√£o foi poss√≠vel remover arquivo tempor√°rio {file_path}: {str(e)}')
            
            self._update_progress('cleanup', 100)
            
            cleanup_result = {
                'cleaned_files': cleaned_files,
                'files_count': len(cleaned_files),
                'cleanup_time': datetime.utcnow().isoformat()
            }
            
            self.results['cleanup'] = cleanup_result
            
            # Salvar informa√ß√µes finais do projeto na pasta do projeto
            timestamp = int(time.time())
            summary_filename = f"project_summary_{timestamp}.txt"
            
            # Criar conte√∫do com resumo do projeto
            summary_content = "RESUMO DO PROJETO\n=================\n\n"
            summary_content += f"ID da Pipeline: {self.pipeline_id}\n"
            summary_content += f"Data de cria√ß√£o: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            
            # Adicionar informa√ß√µes de cada etapa
            if 'extraction' in self.results:
                summary_content += "EXTRA√á√ÉO DE T√çTULOS\n==================\n"
                summary_content += f"Canal: {self.results['extraction'].get('channel_info', {}).get('name', 'N/A')}\n"
                summary_content += f"T√≠tulos extra√≠dos: {self.results['extraction'].get('total_extracted', 0)}\n\n"
            
            if 'titles' in self.results:
                summary_content += "T√çTULOS GERADOS\n===============\n"
                summary_content += f"Quantidade: {len(self.results['titles'].get('generated_titles', []))}\n"
                summary_content += f"Arquivo: {self.results['titles'].get('filename', 'N/A')}\n\n"
            
            if 'premises' in self.results:
                summary_content += "PREMISSAS GERADAS\n=================\n"
                summary_content += f"Palavras: {self.results['premises'].get('word_count', 0)}\n"
                summary_content += f"Arquivo: {self.results['premises'].get('filename', 'N/A')}\n\n"
            
            if 'scripts' in self.results:
                summary_content += "ROTEIRO GERADO\n==============\n"
                summary_content += f"Cap√≠tulos: {self.results['scripts'].get('chapters_generated', 0)}\n"
                summary_content += f"Dura√ß√£o estimada: {self.results['scripts'].get('estimated_duration', 'N/A')}\n"
                summary_content += f"Arquivo: {self.results['scripts'].get('filename', 'N/A')}\n\n"
            
            if 'script_processing' in self.results:
                summary_content += "ROTEIRO PROCESSADO\n==================\n"
                summary_content += f"Taxa de preserva√ß√£o: {self.results['script_processing'].get('metrics', {}).get('preservation_ratio', 0):.2f}\n"
                summary_content += f"Arquivo: {self.results['script_processing'].get('filename', 'N/A')}\n\n"
            
            if 'tts' in self.results:
                summary_content += "√ÅUDIO GERADO\n============\n"
                summary_content += f"Dura√ß√£o: {self.results['tts'].get('duration', 0)} segundos\n"
                summary_content += f"Provedor: {self.results['tts'].get('provider_used', 'N/A')}\n"
                if 'filename' in self.results['tts']:
                    summary_content += f"Arquivo: {self.results['tts'].get('filename', 'N/A')}\n\n"
            
            if 'images' in self.results:
                summary_content += "IMAGENS GERADAS\n===============\n"
                summary_content += f"Quantidade: {len(self.results['images'].get('generated_images', []))}\n"
                summary_content += f"Provedor: {self.results['images'].get('provider_used', 'N/A')}\n\n"
            
            if 'video' in self.results:
                summary_content += "V√çDEO GERADO\n=============\n"
                summary_content += f"Resolu√ß√£o: {self.results['video'].get('resolution', 'N/A')}\n"
                summary_content += f"Dura√ß√£o: {self.results['video'].get('duration', 0)} segundos\n"
                summary_content += f"Tamanho: {self.results['video'].get('file_size', 0)} bytes\n"
                if 'filename' in self.results['video']:
                    summary_content += f"Arquivo: {self.results['video'].get('filename', 'N/A')}\n\n"
            
            summary_content += f"LIMPEZA\n=======\n"
            summary_content += f"Arquivos tempor√°rios removidos: {len(cleaned_files)}\n"
            
            summary_filepath = self._save_text_file(summary_content, summary_filename)
            
            # Adicionar informa√ß√£o do arquivo salvo ao resultado
            cleanup_result['summary_file_path'] = summary_filepath
            cleanup_result['summary_filename'] = summary_filename
            
            # Atualizar metadados do projeto
            try:
                project_dir = os.path.join(os.path.dirname(__file__), '..', 'projects', self.pipeline_id)
                metadata_path = os.path.join(project_dir, 'metadata.json')
                
                if os.path.exists(metadata_path):
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    metadata['status'] = 'completed'
                    metadata['completed_at'] = datetime.utcnow().isoformat()
                    metadata['summary_file'] = summary_filename
                    
                    with open(metadata_path, 'w', encoding='utf-8') as f:
                        json.dump(metadata, f, ensure_ascii=False, indent=2)
            except Exception as e:
                self._log('warning', f'N√£o foi poss√≠vel atualizar metadados do projeto: {str(e)}')
            
            # Remover checkpoint ap√≥s conclus√£o bem-sucedida
            if self.checkpoint_service.has_checkpoint():
                self.checkpoint_service.delete_checkpoint()
                self._log('info', 'Checkpoint removido ap√≥s conclus√£o bem-sucedida')
                cleanup_result['checkpoint_removed'] = True
            
            self._log('info', f'Limpeza conclu√≠da: {len(cleaned_files)} arquivos removidos', {
                'summary_file': summary_filename,
                'cleaned_files': cleaned_filenames
            })
            
            return cleanup_result
            
        except Exception as e:
            self._log('error', f'Erro na limpeza: {str(e)}')
            raise
    
    # ================================
    # üéØ VERIFICA√á√ÉO DE STATUS
    # ================================
    
    def _check_pipeline_status(self) -> bool:
        """Verificar se o pipeline foi pausado ou cancelado"""
        try:
            # Importar aqui para evitar depend√™ncia circular
            from routes.pipeline_complete import active_pipelines, PipelineStatus
            
            if self.pipeline_id in active_pipelines:
                status = active_pipelines[self.pipeline_id]['status']
                if status == PipelineStatus.PAUSED:
                    self._log('info', 'Pipeline pausado, aguardando retomada...')
                    self._pause_event.clear()  # Pausar a execu√ß√£o
                    
                    # Aguardar at√© que o pipeline seja retomado ou cancelado
                    while True:
                        # Verificar status a cada segundo
                        if self._pause_event.wait(timeout=1.0):
                            # Event foi setado, verificar se foi retomado
                            current_status = active_pipelines[self.pipeline_id]['status']
                            if current_status == PipelineStatus.PROCESSING:
                                self._log('info', 'Pipeline retomado, continuando execu√ß√£o...')
                                return True
                            elif current_status == PipelineStatus.CANCELLED:
                                self._log('warning', 'Pipeline cancelado durante pausa')
                                return False
                        else:
                            # Timeout, verificar se foi cancelado
                            current_status = active_pipelines[self.pipeline_id]['status']
                            if current_status == PipelineStatus.CANCELLED:
                                self._log('warning', 'Pipeline cancelado durante pausa')
                                return False
                            elif current_status == PipelineStatus.PROCESSING:
                                self._pause_event.set()  # Sinalizar retomada
                                self._log('info', 'Pipeline retomado, continuando execu√ß√£o...')
                                return True
                elif status == PipelineStatus.CANCELLED:
                    self._log('warning', 'Pipeline cancelado pelo usu√°rio')
                    return False
            return True
        except Exception as e:
            self._log('warning', f'Erro ao verificar status do pipeline: {str(e)}')
            return True  # Continuar em caso de erro
    
    def _wait_for_resume(self):
        """Aguardar at√© que o pipeline seja retomado"""
        # Este m√©todo n√£o √© mais necess√°rio pois a l√≥gica foi movida para _check_pipeline_status
        pass
    
    # ================================
    # üéØ EXECU√á√ÉO COM RETOMADA AUTOM√ÅTICA
    # ================================
    
    def run_with_resume(self, steps: List[str] = None) -> Dict[str, Any]:
        """Executar pipeline com suporte a retomada autom√°tica"""
        try:
            # Criar estrutura de diret√≥rios do projeto
            self._create_project_directory()
            
            # Log de debug para verificar as etapas carregadas
            pipeline_steps_state = self.pipeline_state.get('steps', {})
            step_names = list(pipeline_steps_state.keys())
            self._log('info', f'DEBUG: Pipeline state carregado com etapas: {step_names}')
            
            # Verificar se script_processing est√° presente
            if 'SCRIPT_PROCESSING' in pipeline_steps_state:
                self._log('info', 'DEBUG: Etapa SCRIPT_PROCESSING encontrada no estado')
            else:
                self._log('warning', 'DEBUG: Etapa SCRIPT_PROCESSING N√ÉO encontrada no estado')
            
            # Se n√£o foram fornecidas etapas espec√≠ficas, usar as etapas do estado da pipeline
            if steps is None:
                # Obter etapas do estado da pipeline
                pipeline_steps = list(self.pipeline_state.get('steps', {}).keys())
                self._log('info', f'DEBUG: Usando etapas do estado da pipeline: {pipeline_steps}')
                
                # Se n√£o h√° etapas no estado, usar etapas padr√£o baseadas na configura√ß√£o
                if not pipeline_steps:
                    self._log('warning', 'DEBUG: Nenhuma etapa encontrada no estado, usando etapas padr√£o')
                    pipeline_steps = self._get_default_steps()
                    self._log('info', f'DEBUG: Etapas padr√£o determinadas: {pipeline_steps}')
                
                steps = pipeline_steps
            
            # Verificar se existe checkpoint para retomada
            if self.checkpoint_service.has_checkpoint():
                self._log('info', 'Checkpoint encontrado, retomando pipeline...')
                checkpoint_data = self.load_from_checkpoint()
                
                if checkpoint_data:
                    self._log('info', f'Pipeline retomada a partir da etapa: {checkpoint_data["next_step"]}')
                    # Continuar a partir da pr√≥xima etapa
                    remaining_steps = self._get_remaining_steps(checkpoint_data['next_step'], steps)
                else:
                    # Se n√£o conseguir carregar checkpoint, come√ßar do in√≠cio
                    remaining_steps = steps
            else:
                # Executar pipeline completa
                remaining_steps = steps
            
            # Executar etapas restantes
            for step in remaining_steps:
                # Verificar se pipeline foi pausado ou cancelado antes de cada etapa
                if not self._check_pipeline_status():
                    self._log('info', f'Pipeline pausado/cancelado antes da etapa: {step}')
                    return self.results
                
                try:
                    self._log('info', f'Executando etapa: {step}')
                    
                    if step == 'extraction':
                        self.run_extraction()
                    elif step == 'titles':
                        self.run_titles_generation()
                    elif step == 'premises':
                        self.run_premises_generation()
                    elif step == 'scripts':
                        self.run_scripts_generation()
                    elif step == 'script_processing':
                        self.run_script_processing()
                    elif step == 'tts':
                        self.run_tts_generation()
                    elif step == 'images':
                        self.run_images_generation()
                    elif step == 'video':
                        self.run_video_creation()
                    elif step == 'cleanup':
                        self.run_cleanup()
                    else:
                        self._log('warning', f'Etapa desconhecida: {step}')
                        continue
                    
                    # Verificar novamente ap√≥s a execu√ß√£o da etapa
                    if not self._check_pipeline_status():
                        self._log('info', f'Pipeline pausado/cancelado ap√≥s a etapa: {step}')
                        return self.results
                    
                    # Salvar checkpoint ap√≥s cada etapa bem-sucedida
                    if self.auto_checkpoint and step != 'cleanup':
                        self._save_checkpoint(step)
                    
                except Exception as e:
                    self._log('error', f'Erro na etapa {step}: {str(e)}')
                    # Salvar checkpoint mesmo em caso de erro
                    if self.auto_checkpoint:
                        self._save_checkpoint(f'{step}_failed')
                    raise
            
            self._log('info', 'Pipeline executada com sucesso!')
            self._log('info', f'Resultados finais: {list(self.results.keys())}')
            
            # Debug: verificar conte√∫do dos resultados
            for step, result in self.results.items():
                if isinstance(result, dict):
                    self._log('info', f'Step {step}: {len(str(result))} chars de dados')
                else:
                    self._log('info', f'Step {step}: tipo {type(result)}')
            
            return self.results
            
        except Exception as e:
            self._log('error', f'Erro na execu√ß√£o da pipeline: {str(e)}')
            raise
    
    def _get_default_steps(self) -> List[str]:
        """Obter lista padr√£o de etapas da pipeline baseada na configura√ß√£o"""
        enabled_steps = []
        
        # Log da configura√ß√£o para debug
        self._log('info', f'Configura√ß√£o da pipeline: {json.dumps(self.config, indent=2)}')
        
        # Verificar quais etapas est√£o habilitadas
        if self.config.get('extraction', {}).get('enabled', True):
            enabled_steps.append('extraction')
        if self.config.get('titles', {}).get('enabled', True):
            enabled_steps.append('titles')
        if self.config.get('premises', {}).get('enabled', True):
            enabled_steps.append('premises')
        if self.config.get('scripts', {}).get('enabled', True):
            enabled_steps.append('scripts')
        
        # Verificar script_processing especificamente
        script_processing_config = self.config.get('script_processing', {})
        script_processing_enabled = script_processing_config.get('enabled', True)
        self._log('info', f'Script processing config: {script_processing_config}')
        self._log('info', f'Script processing enabled: {script_processing_enabled}')
        
        if script_processing_enabled:
            enabled_steps.append('script_processing')
            
        if self.config.get('tts', {}).get('enabled', True):
            enabled_steps.append('tts')
        if self.config.get('images', {}).get('enabled', True):
            enabled_steps.append('images')
        if self.config.get('video', {}).get('enabled', True):
            enabled_steps.append('video')
        
        # Cleanup sempre habilitado se h√° pelo menos uma etapa
        if enabled_steps:
            enabled_steps.append('cleanup')
        
        self._log('info', f'Etapas habilitadas: {enabled_steps}')
        return enabled_steps
    
    def _get_remaining_steps(self, next_step: str, all_steps: List[str] = None) -> List[str]:
        """Obter etapas restantes a partir de uma etapa espec√≠fica"""
        if not all_steps:
            # Usar etapas do estado da pipeline em vez de _get_default_steps
            all_steps = list(self.pipeline_state.get('steps', {}).keys())
            self._log('info', f'Usando etapas do estado para remaining_steps: {all_steps}')
        
        try:
            start_index = all_steps.index(next_step)
            remaining = all_steps[start_index:]
            self._log('info', f'Etapas restantes a partir de {next_step}: {remaining}')
            return remaining
        except ValueError:
            # Se a etapa n√£o for encontrada, executar todas
            self._log('info', f'Etapa {next_step} n√£o encontrada, executando todas: {all_steps}')
            return all_steps