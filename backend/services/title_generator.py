"""
ü§ñ Servi√ßo de Gera√ß√£o de T√≠tulos com IA
Auto Video Producer - Gera√ß√£o inteligente de t√≠tulos virais
"""

import google.generativeai as genai
import json
import re
import random
from typing import List, Dict, Optional
import requests
import time

class TitleGenerator:
    def __init__(self):
        self.openai_client = None
        self.gemini_model = None
        self.openrouter_api_key = None
        
    def configure_openai(self, api_key: str):
        """Configurar cliente OpenAI"""
        try:
            print(f"üîç DEBUG: Tentando configurar OpenAI com chave: {api_key[:20]}...")
            from openai import OpenAI
            print("üîç DEBUG: Biblioteca OpenAI importada com sucesso")

            # Validar formato da chave
            if not api_key.startswith('sk-'):
                print(f"‚ùå Chave OpenAI inv√°lida: deve come√ßar com 'sk-'")
                return False

            self.openai_client = OpenAI(api_key=api_key)
            print("üîç DEBUG: Cliente OpenAI criado com sucesso")

            # Testar a conex√£o fazendo uma chamada simples
            try:
                models = self.openai_client.models.list()
                print("üîç DEBUG: Teste de conex√£o OpenAI bem-sucedido")
                return True
            except Exception as test_error:
                print(f"‚ùå Erro no teste de conex√£o OpenAI: {test_error}")
                self.openai_client = None
                return False

        except ImportError as e:
            print(f"‚ùå Erro de importa√ß√£o OpenAI: {e}")
            print("üí° Instale a biblioteca: pip install openai")
            return False
        except Exception as e:
            print(f"‚ùå Erro ao configurar OpenAI: {e}")
            print(f"üîç DEBUG: Tipo do erro: {type(e)}")
            self.openai_client = None
            return False
            
    def configure_gemini(self, api_key: str):
        """Configurar cliente Google Gemini"""
        try:
            print(f"üîç DEBUG: Tentando configurar Gemini com chave: {api_key[:20]}...")
            genai.configure(api_key=api_key)
            print("üîç DEBUG: Gemini configurado com sucesso")
            # Usar o modelo mais recente dispon√≠vel
            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            print("‚úÖ Gemini configurado com modelo: gemini-1.5-flash")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao configurar Gemini: {e}")
            print(f"üîç DEBUG: Tipo do erro: {type(e)}")
            self.gemini_model = None
            # Tentar modelo alternativo
            try:
                self.gemini_model = genai.GenerativeModel('gemini-1.5-pro')
                print("‚úÖ Gemini configurado com modelo alternativo: gemini-1.5-pro")
                return True
            except Exception as e2:
                print(f"‚ùå Erro ao configurar Gemini (modelo alternativo): {e2}")
                self.gemini_model = None
                return False

    def configure_openrouter(self, api_key: str):
        """Configurar cliente OpenRouter"""
        try:
            self.openrouter_api_key = api_key
            print("‚úÖ OpenRouter configurado com sucesso")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao configurar OpenRouter: {e}")
            self.openrouter_api_key = None
            return False
    
    def analyze_viral_patterns(self, titles: List[str]) -> Dict:
        """Analisar padr√µes virais nos t√≠tulos extra√≠dos"""
        patterns = {
            'emotional_triggers': [],
            'numbers': [],
            'power_words': [],
            'structures': [],
            'length_stats': {
                'min': 0,
                'max': 0,
                'avg': 0
            }
        }
        
        # Palavras-chave emocionais comuns
        emotional_words = [
            'INCR√çVEL', 'CHOCANTE', 'SEGREDO', 'REVELADO', 'NUNCA', 'SEMPRE',
            'MELHOR', 'PIOR', '√öNICO', 'EXCLUSIVO', 'URGENTE', '√öLTIMO',
            'PRIMEIRO', 'NOVO', 'ANTIGO', 'R√ÅPIDO', 'F√ÅCIL', 'DIF√çCIL',
            'GR√ÅTIS', 'CARO', 'BARATO', 'RICO', 'POBRE', 'FAMOSO'
        ]
        
        # Analisar cada t√≠tulo
        lengths = []
        for title in titles:
            title_upper = title.upper()
            lengths.append(len(title))
            
            # Buscar gatilhos emocionais
            for word in emotional_words:
                if word in title_upper:
                    patterns['emotional_triggers'].append(word)
            
            # Buscar n√∫meros
            numbers = re.findall(r'\d+', title)
            patterns['numbers'].extend(numbers)
            
            # Buscar estruturas comuns
            if title.startswith('COMO'):
                patterns['structures'].append('COMO_FAZER')
            elif '?' in title:
                patterns['structures'].append('PERGUNTA')
            elif title.count('|') > 0:
                patterns['structures'].append('SEPARADOR')
            elif title.isupper():
                patterns['structures'].append('MAIUSCULA')
        
        # Calcular estat√≠sticas de comprimento
        if lengths:
            patterns['length_stats'] = {
                'min': min(lengths),
                'max': max(lengths),
                'avg': sum(lengths) / len(lengths)
            }
        
        # Remover duplicatas e contar frequ√™ncias
        patterns['emotional_triggers'] = list(set(patterns['emotional_triggers']))
        patterns['numbers'] = list(set(patterns['numbers']))
        patterns['structures'] = list(set(patterns['structures']))
        
        return patterns
    
    def generate_titles_openai(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> List[str]:
        """Gerar t√≠tulos usando OpenAI GPT"""
        if not self.openai_client:
            raise Exception("OpenAI n√£o configurado")
        
        # Analisar padr√µes dos t√≠tulos de origem
        patterns = self.analyze_viral_patterns(source_titles)
        
        # Criar prompt baseado nos padr√µes encontrados
        prompt = self.create_openai_prompt(source_titles, topic, patterns, style, count)
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.8
            )

            content = response.choices[0].message.content
            titles = self.parse_generated_titles(content)

            return titles[:count]
            
        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenAI: {e}")
            return []
    
    def generate_titles_gemini(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> List[str]:
        """Gerar t√≠tulos usando Google Gemini com cache e fallback autom√°tico"""
        try:
            from routes.automations import handle_gemini_429_error, check_gemini_availability, get_fallback_provider_info
            import hashlib
            import json
            import os
            from datetime import datetime, timedelta
            
            # Sistema de cache simples
            cache_dir = "cache/gemini_titles"
            os.makedirs(cache_dir, exist_ok=True)
            
            # Gerar hash do prompt para cache
            cache_key = f"{str(source_titles)}_{topic}_{count}_{style}"
            prompt_hash = hashlib.md5(cache_key.encode()).hexdigest()
            cache_file = os.path.join(cache_dir, f"{prompt_hash}.json")
            
            # Verificar cache (v√°lido por 4 horas para t√≠tulos)
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    cache_time = datetime.fromisoformat(cache_data['timestamp'])
                    if datetime.now() - cache_time < timedelta(hours=4):
                        print(f"üì¶ [CACHE] Usando t√≠tulos em cache para Gemini ({len(cache_data['titles'])} t√≠tulos)")
                        return cache_data['titles']
                except Exception as e:
                    print(f"‚ö†Ô∏è [CACHE] Erro ao ler cache de t√≠tulos: {e}")
            
            # Verificar disponibilidade do Gemini
            if not check_gemini_availability():
                print("‚ö†Ô∏è [GEMINI] Todas as chaves Gemini esgotadas, usando fallback para t√≠tulos")
                fallback_info = get_fallback_provider_info()
                if fallback_info:
                    if fallback_info['provider'] == 'openai':
                        return self.generate_titles_openai(source_titles, topic, count, style)
                    elif fallback_info['provider'] == 'openrouter':
                        # Implementar fallback para OpenRouter se necess√°rio
                        print("‚ö†Ô∏è [FALLBACK] OpenRouter n√£o implementado para t√≠tulos, retornando lista vazia")
                        return []
                print("‚ö†Ô∏è [FALLBACK] Nenhum fallback dispon√≠vel para t√≠tulos")
                return []
            
            if not self.gemini_model:
                raise Exception("Gemini n√£o configurado")
            
            # Analisar padr√µes dos t√≠tulos de origem
            patterns = self.analyze_viral_patterns(source_titles)
            
            # Criar prompt baseado nos padr√µes encontrados
            prompt = self.create_gemini_prompt(source_titles, topic, patterns, style, count)
            
            print(f"üîç DEBUG: Enviando prompt para Gemini...")
            print(f"üîç DEBUG: T√≠tulos de origem: {source_titles}")
            print(f"üîç DEBUG: Quantidade solicitada: {count}")

            # Verificar cancelamento antes de chamar a IA
            try:
                from routes.workflow import check_workflow_status
                check_workflow_status()
            except:
                pass  # Se n√£o conseguir importar, continua

            # Usar fun√ß√£o centralizada de retry
            from routes.automations import generate_content_with_gemini_retry
            response_text = generate_content_with_gemini_retry(prompt)
            print(f"üîç DEBUG: Resposta bruta do Gemini: {response_text[:200]}...")

            titles = self.parse_generated_titles(response_text)
            print(f"üîç DEBUG: T√≠tulos parseados ({len(titles)}): {titles}")
            print(f"üîç DEBUG: Limitando para {count} t√≠tulos")

            limited_titles = titles[:count]
            print(f"üîç DEBUG: T√≠tulos finais ({len(limited_titles)}): {limited_titles}")
            
            # Salvar no cache
            try:
                cache_data = {
                    'titles': limited_titles,
                    'timestamp': datetime.now().isoformat(),
                    'prompt_hash': prompt_hash,
                    'count': count,
                    'style': style
                }
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(cache_data, f, ensure_ascii=False, indent=2)
                print(f"üì¶ [CACHE] T√≠tulos salvos no cache")
            except Exception as e:
                print(f"‚ö†Ô∏è [CACHE] Erro ao salvar cache de t√≠tulos: {e}")

            return limited_titles

        except Exception as e:
            error_str = str(e)
            
            # Tratar erro 429 especificamente
            if '429' in error_str or 'quota' in error_str.lower() or 'exceeded' in error_str.lower():
                print(f"üö´ [GEMINI] Erro 429 detectado nos t√≠tulos: {error_str}")
                # Obter a chave atual para passar para handle_gemini_429_error
                from routes.automations import GEMINI_KEYS_ROTATION
                current_key = None
                if GEMINI_KEYS_ROTATION['keys'] and GEMINI_KEYS_ROTATION['current_index'] < len(GEMINI_KEYS_ROTATION['keys']):
                    current_key = GEMINI_KEYS_ROTATION['keys'][GEMINI_KEYS_ROTATION['current_index']]
                handle_gemini_429_error(error_str, current_key)
                
                # Tentar fallback autom√°tico
                try:
                    from routes.automations import get_fallback_provider_info
                    fallback_info = get_fallback_provider_info()
                    if fallback_info:
                        print(f"üîÑ [FALLBACK] Usando {fallback_info['provider']} como fallback para t√≠tulos")
                        if fallback_info['provider'] == 'openai':
                            return self.generate_titles_openai(source_titles, topic, count, style)
                        elif fallback_info['provider'] == 'openrouter':
                            print("‚ö†Ô∏è [FALLBACK] OpenRouter n√£o implementado para t√≠tulos, retornando lista vazia")
                            return []
                except Exception as fallback_error:
                    print(f"‚ùå [FALLBACK] Erro no fallback dos t√≠tulos: {fallback_error}")
            
            print(f"‚ùå Erro na gera√ß√£o Gemini: {error_str}")
            return []
    
    def create_openai_prompt(self, source_titles: List[str], topic: str, patterns: Dict, style: str, count: int = 10) -> str:
        """Criar prompt otimizado para OpenAI"""
        prompt = f"""
Voc√™ √© um especialista em marketing digital para YouTube. Analise os t√≠tulos de refer√™ncia abaixo e crie NOVOS t√≠tulos SIMILARES mas MELHORADOS sobre o mesmo tema.

T√çTULOS DE REFER√äNCIA (extra√≠dos de canal de sucesso):
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles[:5]])}

PADR√ïES IDENTIFICADOS:
‚Ä¢ Gatilhos emocionais: {', '.join(patterns['emotional_triggers'][:10])}
‚Ä¢ N√∫meros populares: {', '.join(patterns['numbers'][:5])}
‚Ä¢ Estruturas: {', '.join(patterns['structures'])}
‚Ä¢ Comprimento m√©dio: {patterns['length_stats']['avg']:.0f} caracteres

INSTRU√á√ïES ESPEC√çFICAS:
1. üéØ MANTENHA o mesmo NICHO/TEMA dos t√≠tulos de refer√™ncia
2. üöÄ Crie 15 t√≠tulos SIMILARES mas MELHORADOS
3. üìà Use os padr√µes identificados para otimizar engajamento
4. üé™ Aplique gatilhos psicol√≥gicos mais fortes (curiosidade, urg√™ncia, exclusividade)
5. üî• Mantenha entre {patterns['length_stats']['min']} e {patterns['length_stats']['max']} caracteres
6. üí° Varie as estruturas mas mantenha o estilo {style}
7. üìä Foque em t√≠tulos que superem os originais em atratividade

IMPORTANTE: Os novos t√≠tulos devem ser sobre o MESMO TEMA dos t√≠tulos de refer√™ncia, mas mais otimizados para cliques.

FORMATO DE RESPOSTA:
1. [T√çTULO 1]
2. [T√çTULO 2]
...

IMPORTANTE: Gere EXATAMENTE {count} t√≠tulos, nem mais nem menos.

T√≠tulos ({count} t√≠tulos):
"""
        return prompt
    
    def create_gemini_prompt(self, source_titles: List[str], topic: str, patterns: Dict, style: str, count: int = 10) -> str:
        """Criar prompt otimizado para Gemini"""
        prompt = f"""
Voc√™ √© um especialista em marketing digital e cria√ß√£o de conte√∫do viral para YouTube.

TAREFA: Analisar os t√≠tulos de refer√™ncia abaixo e criar NOVOS t√≠tulos SIMILARES mas MELHORADOS sobre o mesmo tema/nicho.

T√çTULOS DE REFER√äNCIA (extra√≠dos de canal de sucesso):
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles[:5]])}

AN√ÅLISE DOS PADR√ïES IDENTIFICADOS:
‚Ä¢ Palavras-chave emocionais: {', '.join(patterns['emotional_triggers'][:8])}
‚Ä¢ N√∫meros eficazes: {', '.join(patterns['numbers'][:5])}
‚Ä¢ Estruturas que funcionam: {', '.join(patterns['structures'])}
‚Ä¢ Comprimento ideal: {patterns['length_stats']['min']}-{patterns['length_stats']['max']} caracteres

INSTRU√á√ïES ESPEC√çFICAS:
1. üéØ MANTENHA o mesmo NICHO/TEMA dos t√≠tulos de refer√™ncia
2. üöÄ MELHORE usando gatilhos psicol√≥gicos mais fortes
3. üìà OTIMIZE para maior engajamento e cliques
4. üé™ Use elementos de curiosidade, urg√™ncia, exclusividade
5. üî• Inclua emojis estrat√©gicos quando apropriado
6. üí° Varie as estruturas mas mantenha o estilo viral
7. üìä Crie t√≠tulos que superem os originais em atratividade

IMPORTANTE: Os novos t√≠tulos devem ser sobre o MESMO TEMA dos t√≠tulos de refer√™ncia, mas mais atrativos e otimizados.

FORMATO DE RESPOSTA:
Liste apenas os t√≠tulos numerados, um por linha:

1. [T√çTULO MELHORADO]
2. [T√çTULO MELHORADO]
...

IMPORTANTE: Gere EXATAMENTE {count} t√≠tulos, nem mais nem menos.

Gere os {count} t√≠tulos agora:
"""
        return prompt
    
    def parse_generated_titles(self, content: str) -> List[str]:
        """Extrair t√≠tulos do texto gerado pela IA"""
        titles = []

        print(f"üîç DEBUG: Parseando conte√∫do: {content[:200]}...")

        # Dividir por linhas
        lines = content.strip().split('\n')
        print(f"üîç DEBUG: {len(lines)} linhas encontradas")

        for i, line in enumerate(lines):
            original_line = line
            line = line.strip()

            # Remover numera√ß√£o (1., 2., etc.)
            line = re.sub(r'^\d+\.?\s*', '', line)

            # Remover marcadores (-, ‚Ä¢, etc.)
            line = re.sub(r'^[-‚Ä¢*]\s*', '', line)

            # Remover colchetes se existirem
            line = re.sub(r'^\[|\]$', '', line)

            print(f"üîç DEBUG: Linha {i+1}: '{original_line}' -> '{line}' (len: {len(line)})")

            # Verificar se √© um t√≠tulo v√°lido
            if line and len(line) > 10 and not line.startswith('T√≠tulo'):
                titles.append(line.strip())
                print(f"‚úÖ DEBUG: T√≠tulo aceito: '{line.strip()}'")
            else:
                print(f"‚ùå DEBUG: T√≠tulo rejeitado: '{line}' (muito curto ou inv√°lido)")

        print(f"üîç DEBUG: Total de t√≠tulos extra√≠dos: {len(titles)}")
        return titles
    
    def generate_titles_hybrid(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> Dict:
        """Gerar t√≠tulos usando m√∫ltiplas IAs e combinar resultados"""
        results = {
            'openai_titles': [],
            'gemini_titles': [],
            'combined_titles': [],
            'patterns_analysis': {},
            'success': False,
            'error': None
        }
        
        try:
            # Analisar padr√µes primeiro
            results['patterns_analysis'] = self.analyze_viral_patterns(source_titles)
            
            # Tentar OpenAI primeiro
            if self.openai_client:
                try:
                    openai_titles = self.generate_titles_openai(source_titles, topic, count, style)
                    results['openai_titles'] = openai_titles
                except Exception as e:
                    print(f"‚ö†Ô∏è OpenAI falhou: {e}")
            
            # Tentar Gemini como backup/complemento
            if self.gemini_model:
                try:
                    gemini_titles = self.generate_titles_gemini(source_titles, topic, count, style)
                    results['gemini_titles'] = gemini_titles
                except Exception as e:
                    print(f"‚ö†Ô∏è Gemini falhou: {e}")
            
            # Combinar e diversificar resultados
            all_titles = results['openai_titles'] + results['gemini_titles']
            
            if all_titles:
                # Remover duplicatas e selecionar os melhores
                unique_titles = list(dict.fromkeys(all_titles))  # Remove duplicatas mantendo ordem
                results['combined_titles'] = unique_titles[:count]
                results['success'] = True
            else:
                results['error'] = "Nenhuma IA conseguiu gerar t√≠tulos"
            
            return results
            
        except Exception as e:
            results['error'] = str(e)
            return results
    
    def score_title_quality(self, title: str, patterns: Dict) -> float:
        """Pontuar qualidade de um t√≠tulo baseado nos padr√µes virais"""
        score = 0.0
        title_upper = title.upper()

        # Pontua√ß√£o por gatilhos emocionais
        for trigger in patterns['emotional_triggers']:
            if trigger in title_upper:
                score += 2.0

        # Pontua√ß√£o por n√∫meros
        if re.search(r'\d+', title):
            score += 1.5

        # Pontua√ß√£o por comprimento ideal
        length = len(title)
        ideal_min = patterns['length_stats']['min']
        ideal_max = patterns['length_stats']['max']

        if ideal_min <= length <= ideal_max:
            score += 2.0
        elif abs(length - patterns['length_stats']['avg']) <= 10:
            score += 1.0

        # Pontua√ß√£o por estruturas eficazes
        if title.startswith('COMO'):
            score += 1.0
        if '?' in title:
            score += 0.5
        if title.count('|') > 0:
            score += 0.5

        return score

    def generate_titles_with_custom_prompt(self,
                                         source_titles: List[str],
                                         custom_prompt: str,
                                         count: int = 10,
                                         ai_provider: str = "auto",
                                         script_size: str = "medio") -> Dict:
        """Gerar t√≠tulos usando prompt personalizado"""
        results = {
            'generated_titles': [],
            'ai_provider_used': '',
            'patterns_analysis': {},
            'success': False,
            'error': None,
            'custom_prompt_used': custom_prompt
        }

        try:
            # Analisar padr√µes dos t√≠tulos originais
            results['patterns_analysis'] = self.analyze_viral_patterns(source_titles)

            # Criar prompt final combinando o personalizado com os t√≠tulos
            final_prompt = self.create_custom_prompt(source_titles, custom_prompt, count, script_size)

            # Tentar gerar com a IA escolhida
            if ai_provider == "openai" and self.openai_client:
                titles = self.generate_with_openai_custom(final_prompt)
                results['ai_provider_used'] = 'openai'
            elif ai_provider == "gemini" and self.gemini_model:
                titles = self.generate_with_gemini_custom(final_prompt)
                results['ai_provider_used'] = 'gemini'
            elif ai_provider == "openrouter" and self.openrouter_api_key:
                titles = self.generate_with_openrouter_custom(final_prompt, "anthropic/claude-3.5-sonnet")
                results['ai_provider_used'] = 'openrouter'
            else:
                # Modo autom√°tico - tentar OpenAI primeiro, depois OpenRouter, depois Gemini
                titles = []

                # Tentar OpenAI primeiro
                if self.openai_client:
                    try:
                        titles = self.generate_with_openai_custom(final_prompt)
                        results['ai_provider_used'] = 'openai'
                    except Exception as e:
                        print(f"‚ö†Ô∏è OpenAI falhou: {e}")

                # Tentar OpenRouter se OpenAI falhou
                if not titles and self.openrouter_api_key:
                    try:
                        titles = self.generate_with_openrouter_custom(final_prompt, "anthropic/claude-3.5-sonnet")
                        results['ai_provider_used'] = 'openrouter'
                    except Exception as e:
                        print(f"‚ö†Ô∏è OpenRouter falhou: {e}")

                # Tentar Gemini como √∫ltimo recurso
                if not titles and self.gemini_model:
                    try:
                        titles = self.generate_with_gemini_custom(final_prompt)
                        results['ai_provider_used'] = 'gemini'
                    except Exception as e:
                        print(f"‚ö†Ô∏è Gemini falhou: {e}")

                if not titles:
                    results['error'] = "Nenhuma IA conseguiu processar o prompt personalizado"
                    return results

            if titles:
                results['generated_titles'] = titles[:count]
                results['success'] = True
            else:
                results['error'] = "Nenhum t√≠tulo foi gerado"

            return results

        except Exception as e:
            results['error'] = str(e)
            return results

    def create_custom_prompt(self, source_titles: List[str], custom_prompt: str, count: int, script_size: str = "medio") -> str:
        """Criar prompt final combinando t√≠tulos originais com prompt personalizado"""
        
        # Definir instru√ß√µes espec√≠ficas de tamanho
        size_instructions = {
            'curto': "Crie t√≠tulos para roteiros CURTOS (1.500-2.000 palavras). Foque em temas diretos, tutoriais r√°pidos, dicas pr√°ticas e conte√∫do conciso.",
            'medio': "Crie t√≠tulos para roteiros M√âDIOS (3.500-5.000 palavras). Equilibre profundidade e acessibilidade, permitindo desenvolvimento moderado dos temas.",
            'longo': "Crie t√≠tulos para roteiros LONGOS (7.000-10.000 palavras). Foque em an√°lises profundas, estudos de caso detalhados, tutoriais completos e conte√∫do abrangente."
        }
        
        size_instruction = size_instructions.get(script_size, size_instructions['medio'])
        
        prompt = f"""
T√çTULOS ORIGINAIS EXTRA√çDOS DO YOUTUBE:
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles])}

INSTRU√á√ÉO PERSONALIZADA:
{custom_prompt}

INSTRU√á√ÉO DE TAMANHO:
{size_instruction}

TAREFA:
Com base nos t√≠tulos originais acima e seguindo a instru√ß√£o personalizada, crie {count} novos t√≠tulos √∫nicos e otimizados.

DIRETRIZES:
1. Use os t√≠tulos originais como inspira√ß√£o e refer√™ncia
2. Siga exatamente a instru√ß√£o personalizada fornecida
3. Considere o tamanho do roteiro especificado na cria√ß√£o dos t√≠tulos
4. Mantenha a ess√™ncia viral dos t√≠tulos originais
5. Crie t√≠tulos √∫nicos e atraentes
6. Foque em gerar curiosidade e engajamento

FORMATO DE RESPOSTA:
Liste apenas os t√≠tulos numerados, um por linha:

1. [T√çTULO]
2. [T√çTULO]
...

Gere os {count} t√≠tulos agora:
"""
        return prompt

    def generate_with_openai_custom(self, prompt: str) -> List[str]:
        """Gerar t√≠tulos com OpenAI usando prompt personalizado"""
        if not self.openai_client:
            raise Exception("OpenAI n√£o configurado")

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube. Siga exatamente as instru√ß√µes fornecidas."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.8
            )

            content = response.choices[0].message.content
            titles = self.parse_generated_titles(content)

            return titles

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenAI: {e}")
            raise e

    def generate_with_gemini_custom(self, prompt: str) -> List[str]:
        """Gerar t√≠tulos com Gemini usando prompt personalizado com sistema de retry autom√°tico"""
        if not self.gemini_model:
            raise Exception("Gemini n√£o configurado")

        try:
            from routes.automations import get_next_gemini_key, handle_gemini_429_error, get_gemini_keys_count
            
            # Usar a quantidade real de chaves dispon√≠veis
            max_retries = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
            print(f"üîë Usando {max_retries} chaves Gemini para gera√ß√£o de t√≠tulos")
            
            for attempt in range(max_retries):
                try:
                    print(f"üîç DEBUG: Tentativa {attempt + 1}/{max_retries} - Enviando prompt personalizado para Gemini...")
                    response = self.gemini_model.generate_content(prompt)
                    print(f"üîç DEBUG: Resposta bruta do Gemini: {response.text[:300]}...")

                    titles = self.parse_generated_titles(response.text)
                    print(f"üîç DEBUG: T√≠tulos parseados do Gemini: {titles}")
                    print(f"‚úÖ Sucesso na gera√ß√£o de t√≠tulos com Gemini na tentativa {attempt + 1}")

                    return titles

                except Exception as e:
                    error_str = str(e)
                    print(f"‚ùå Erro na tentativa {attempt + 1}: {error_str}")
                    
                    # Check if it's a quota error (429)
                    if "429" in error_str or "quota" in error_str.lower() or "rate limit" in error_str.lower():
                        if attempt < max_retries - 1:  # Not the last attempt
                            print(f"üîÑ Erro de quota detectado, tentando pr√≥xima chave Gemini...")
                            handle_gemini_429_error(error_str)
                            new_api_key = get_next_gemini_key()
                            if new_api_key:
                                print(f"üîë Nova chave Gemini obtida, reconfigurando...")
                                self.configure_gemini(new_api_key)
                                continue
                            else:
                                print("‚ùå Nenhuma chave Gemini dispon√≠vel")
                                break
                        else:
                            print("‚ùå Todas as tentativas de retry falharam")
                            handle_gemini_429_error(error_str)
                    else:
                        # For non-quota errors, don't retry
                        print(f"‚ùå Erro n√£o relacionado √† quota, parando tentativas: {error_str}")
                        raise e
            
            raise Exception("Falha na gera√ß√£o de t√≠tulos com Gemini ap√≥s todas as tentativas")

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o Gemini: {e}")
            raise e

    def generate_with_openrouter_custom(self, prompt: str, model: str = "anthropic/claude-3.5-sonnet") -> List[str]:
        """Gerar t√≠tulos com OpenRouter usando prompt personalizado"""
        if not self.openrouter_api_key:
            raise Exception("OpenRouter n√£o configurado")

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:5173",
                "X-Title": "Auto Video Producer"
            }

            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube. Siga exatamente as instru√ß√µes fornecidas."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 1000,
                "temperature": 0.8
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                titles = self.parse_generated_titles(content)
                return titles
            else:
                raise Exception(f"OpenRouter API error: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenRouter: {e}")
            raise e
