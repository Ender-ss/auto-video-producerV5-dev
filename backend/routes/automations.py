"""
ü§ñ Automations Routes
Rotas para automa√ß√µes de conte√∫do com IA
"""

from flask import Blueprint, request, jsonify
from datetime import datetime
import requests
import json
import re
import time
import openai
import os
import base64
import wave
import io
import threading
from utils.error_messages import auto_format_error, format_error_response

# Importar sistema de logs em tempo real
try:
    from routes.system import add_real_time_log
except ImportError:
    # Fallback se n√£o conseguir importar
    def add_real_time_log(message, level="info", source="automations"):
        print(f"[{level.upper()}] [{source}] {message}")

# Import AI libraries
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# Sistema de rota√ß√£o de chaves Gemini
GEMINI_KEYS_ROTATION = {
    'keys': [],
    'current_index': 0,
    'usage_count': {},
    'last_reset': datetime.now().date()
}

# Sistema de rota√ß√£o de chaves RapidAPI
RAPIDAPI_KEYS_ROTATION = {
    'keys': [],
    'current_index': 0,
    'failed_keys': set(),  # Chaves que falharam por quota excedida
    'last_reset': datetime.now().date()
}

# Sistema de controle de jobs TTS
TTS_JOBS = {}
TTS_JOB_COUNTER = 0

# Sistema de throttling inteligente para RapidAPI (OTIMIZADO)
RAPIDAPI_THROTTLE = {
    'last_request_time': 0,
    'min_delay': 1.0,  # Delay m√≠nimo otimizado para 1s entre requisi√ß√µes
    'adaptive_delay': 1.0,  # Delay adaptativo otimizado baseado em rate limiting
    'max_delay': 60.0,  # Delay m√°ximo de 60s
    'consecutive_429s': 0,  # Contador de 429s consecutivos
    'sequential_delay': 1.0,  # Delay adicional otimizado entre chamadas sequenciais
    'lock': threading.Lock()  # Lock para thread safety
}

# Sistema de cache otimizado para RapidAPI com persist√™ncia
RAPIDAPI_CACHE = {
    'data': {},  # Cache de dados
    'timestamps': {},  # Timestamps dos dados
    'ttl': 3600,  # TTL padr√£o aumentado para 1 hora (3600s)
    'channel_ttl': 7200,  # TTL para dados de canal: 2 horas
    'video_ttl': 1800,  # TTL para v√≠deos: 30 minutos
    'file_path': os.path.join(os.path.dirname(__file__), '..', 'cache', 'rapidapi_cache.json'),
    'lock': threading.Lock()  # Lock para thread safety
}

# Sistema de rate limiting global para RapidAPI
RAPIDAPI_RATE_LIMIT = {
    'requests_per_minute': 0,  # Contador de requisi√ß√µes por minuto
    'requests_per_hour': 0,    # Contador de requisi√ß√µes por hora
    'minute_window_start': 0,  # Timestamp do in√≠cio da janela de minuto
    'hour_window_start': 0,    # Timestamp do in√≠cio da janela de hora
    'max_requests_per_minute': 50,  # Limite m√°ximo por minuto (ajustado para 1000/hora)
    'max_requests_per_hour': 900,   # Limite m√°ximo por hora (margem de seguran√ßa para 1000/hora)
    'pause_until': 0,          # Timestamp at√© quando pausar requisi√ß√µes
    'total_requests_today': 0, # Total de requisi√ß√µes hoje
    'last_reset_date': datetime.now().date(),  # Data do √∫ltimo reset
    'lock': threading.Lock()   # Lock para thread safety
}

# Import TitleGenerator
try:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from services.title_generator import TitleGenerator
    TITLE_GENERATOR_AVAILABLE = True
    print("‚úÖ TitleGenerator importado com sucesso")
except ImportError as e:
    TITLE_GENERATOR_AVAILABLE = False
    print(f"‚ö†Ô∏è TitleGenerator n√£o dispon√≠vel: {e}")

    # Fallback: criar classe mock
    class TitleGenerator:
        def __init__(self):
            pass
        def configure_openai(self, key):
            return False
        def configure_gemini(self, key):
            return False
        def generate_titles_with_custom_prompt(self, *args, **kwargs):
            return {'success': False, 'error': 'TitleGenerator n√£o dispon√≠vel'}

# Import AI Services functions
try:
    from services.ai_services import (
        generate_script_chapters_with_openai,
        generate_script_chapters_with_gemini,
        generate_script_chapters_with_claude,
        generate_script_chapters_with_openrouter
    )
    AI_SERVICES_AVAILABLE = True
    print("‚úÖ AI Services importado com sucesso")
except ImportError as e:
    AI_SERVICES_AVAILABLE = False
    print(f"‚ö†Ô∏è AI Services n√£o dispon√≠vel: {e}")
    
    # Fallback: criar fun√ß√µes mock
    def generate_script_chapters_with_openai(*args, **kwargs):
        return {'success': False, 'error': 'AI Services n√£o dispon√≠vel'}
    
    def generate_script_chapters_with_gemini(*args, **kwargs):
        return {'success': False, 'error': 'AI Services n√£o dispon√≠vel'}
    
    def generate_script_chapters_with_claude(*args, **kwargs):
        return {'success': False, 'error': 'AI Services n√£o dispon√≠vel'}
    
    def generate_script_chapters_with_openrouter(*args, **kwargs):
        return {'success': False, 'error': 'AI Services n√£o dispon√≠vel'}

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import google.genai as google_genai
    from google.genai import types
    GOOGLE_GENAI_TTS_AVAILABLE = True
except ImportError:
    GOOGLE_GENAI_TTS_AVAILABLE = False

automations_bp = Blueprint('automations', __name__)

def load_gemini_keys():
    """Carregar chaves Gemini do arquivo de configura√ß√£o"""
    try:
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                keys = json.load(f)

            # Coletar todas as chaves Gemini v√°lidas
            gemini_keys = []
            invalid_keys = []
            
            for key, value in keys.items():
                if 'gemini' in key.lower() and value:
                    # Verificar se √© uma string v√°lida (n√£o um dicion√°rio)
                    if isinstance(value, str) and len(value) > 10 and value.startswith('AIza'):
                        gemini_keys.append(value)
                    else:
                        invalid_keys.append(key)
                        print(f"‚ö†Ô∏è Chave Gemini inv√°lida ignorada: {key} (formato incorreto)")

            # Adicionar chave padr√£o se n√£o houver outras
            default_key = 'AIzaSyBqUjzLHNPycDIzvwnI5JisOwmNubkfRRc'
            if default_key not in gemini_keys:
                gemini_keys.append(default_key)

            GEMINI_KEYS_ROTATION['keys'] = gemini_keys
            print(f"üîë Carregadas {len(gemini_keys)} chaves Gemini v√°lidas para rota√ß√£o")
            if invalid_keys:
                print(f"‚ö†Ô∏è Ignoradas {len(invalid_keys)} chaves Gemini inv√°lidas")
            
            # Logs detalhados para debug
            for i, key in enumerate(gemini_keys):
                print(f"üîç [DEBUG] Chave {i+1}: {key[:20]}... (tamanho: {len(key)})")
            
            add_real_time_log(f"üîë Carregadas {len(gemini_keys)} chaves Gemini", "info", "gemini-load")
            return gemini_keys
    except Exception as e:
        print(f"‚ùå Erro ao carregar chaves Gemini: {e}")
        # Usar chave padr√£o como fallback
        GEMINI_KEYS_ROTATION['keys'] = ['AIzaSyBqUjzLHNPycDIzvwnI5JisOwmNubkfRRc']

    return GEMINI_KEYS_ROTATION['keys']

def get_gemini_keys_count():
    """Obter a quantidade de chaves Gemini dispon√≠veis"""
    # Carregar chaves se n√£o estiverem carregadas
    if not GEMINI_KEYS_ROTATION['keys']:
        load_gemini_keys()
    
    # Retornar a quantidade de chaves dispon√≠veis
    return len(GEMINI_KEYS_ROTATION['keys'])

def load_rapidapi_keys():
    """Carregar chaves RapidAPI do arquivo de configura√ß√£o"""
    try:
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                keys = json.load(f)

            # Carregar array de chaves RapidAPI
            rapidapi_keys = keys.get('rapidapi_keys', [])
            
            # Adicionar chave principal se existir
            if keys.get('rapidapi'):
                rapidapi_keys.append(keys.get('rapidapi'))
            
            # Adicionar chaves individuais de rota√ß√£o
            for i in range(1, 11):  # rapidapi_1 at√© rapidapi_10
                key_name = f'rapidapi_{i}'
                if keys.get(key_name):
                    rapidapi_keys.append(keys.get(key_name))

            # Filtrar chaves v√°lidas e remover duplicatas
            valid_keys = list(set([key for key in rapidapi_keys if key and len(key) > 10]))
            
            RAPIDAPI_KEYS_ROTATION['keys'] = valid_keys
            RAPIDAPI_KEYS_ROTATION['failed_keys'] = set()  # Reset das chaves falhadas
            print(f"üîë Carregadas {len(valid_keys)} chaves RapidAPI para rota√ß√£o")
            return valid_keys
    except Exception as e:
        print(f"‚ùå Erro ao carregar chaves RapidAPI: {e}")
        RAPIDAPI_KEYS_ROTATION['keys'] = []

    return RAPIDAPI_KEYS_ROTATION['keys']

def get_next_gemini_key():
    """Obter pr√≥xima chave Gemini na rota√ß√£o"""
    # Carregar chaves se n√£o estiverem carregadas
    if not GEMINI_KEYS_ROTATION['keys']:
        load_gemini_keys()

    # Reset di√°rio do contador
    today = datetime.now().date()
    if GEMINI_KEYS_ROTATION['last_reset'] != today:
        GEMINI_KEYS_ROTATION['usage_count'] = {}
        GEMINI_KEYS_ROTATION['last_reset'] = today
        GEMINI_KEYS_ROTATION['current_index'] = 0
        print("üîÑ Reset di√°rio do contador de uso das chaves Gemini")
        add_real_time_log("üîÑ Reset di√°rio do contador de uso das chaves Gemini", "info", "gemini-rotation")

    keys = GEMINI_KEYS_ROTATION['keys']
    if not keys:
        return None

    # Encontrar chave com menor uso
    min_usage = float('inf')
    best_key_index = 0

    for i, key in enumerate(keys):
        usage = GEMINI_KEYS_ROTATION['usage_count'].get(key, 0)
        if usage < min_usage:
            min_usage = usage
            best_key_index = i

    # N√£o mais limitar arbitrariamente - as chaves ser√£o rotacionadas com base nos erros da API
    selected_key = keys[best_key_index]

    # Incrementar contador de uso para fins de monitoramento
    GEMINI_KEYS_ROTATION['usage_count'][selected_key] = GEMINI_KEYS_ROTATION['usage_count'].get(selected_key, 0) + 1

    usage_count = GEMINI_KEYS_ROTATION['usage_count'][selected_key]
    
    # Logs detalhados para debug
    print(f"üîë Usando chave Gemini {best_key_index + 1}/{len(keys)} (uso total: {usage_count})")
    print(f"üîç [DEBUG] Chave selecionada: {selected_key[:20]}... (√≠ndice: {best_key_index})")
    print(f"üîç [DEBUG] Estado das chaves: {[(i, GEMINI_KEYS_ROTATION['usage_count'].get(key, 0)) for i, key in enumerate(keys)]}")
    
    add_real_time_log(f"üîë Usando chave Gemini {best_key_index + 1}/{len(keys)} (uso total: {usage_count})", "info", "gemini-rotation")
    add_real_time_log(f"üîç Chave: {selected_key[:20]}... (√≠ndice: {best_key_index})", "debug", "gemini-key-detail")

    return selected_key

def handle_gemini_429_error(error_message, current_key=None):
    """Tratar erro 429 espec√≠fico do Gemini com logs detalhados"""
    print(f"üö´ ERRO 429 GEMINI: {error_message}")
    add_real_time_log(f"üö´ ERRO 429 GEMINI: Quota excedida - {error_message}", "error", "gemini-429")
    
    # Log detalhado sobre o estado atual das chaves
    total_usage = sum(GEMINI_KEYS_ROTATION['usage_count'].values())
    num_keys = len(GEMINI_KEYS_ROTATION['keys'])
    
    print(f"üìä Estado das chaves Gemini: {total_usage} requisi√ß√µes usadas com {num_keys} chaves")
    add_real_time_log(f"üìä Estado Gemini: {total_usage} req usadas, {num_keys} chaves dispon√≠veis", "info", "gemini-status")
    
    # Marcar apenas a chave atual como esgotada, n√£o todas
    if current_key and current_key in GEMINI_KEYS_ROTATION['keys']:
        # Ao inv√©s de definir um valor fixo, manter o contador real mas garantir que essa chave n√£o seja usada novamente
        # Isso permitir√° que a chave seja reutilizada no pr√≥ximo reset
        GEMINI_KEYS_ROTATION['usage_count'][current_key] = float('inf')  # Marcar como esgotada
        print(f"‚ö†Ô∏è Chave Gemini {current_key[:20]}... marcada como esgotada.")
        add_real_time_log(f"‚ö†Ô∏è Chave Gemini marcada como esgotada: {current_key[:20]}...", "warning", "gemini-key-exhausted")
    
    # Verificar se ainda h√° chaves dispon√≠veis
    available_keys = 0
    for key in GEMINI_KEYS_ROTATION['keys']:
        if GEMINI_KEYS_ROTATION['usage_count'].get(key, 0) < 250:
            available_keys += 1
    
    if available_keys == 0:
        print("‚ö†Ô∏è Todas as chaves Gemini esgotadas. Fallback autom√°tico ativado.")
        add_real_time_log("‚ö†Ô∏è Fallback autom√°tico ativado para Gemini", "warning", "gemini-fallback")
        return False
    else:
        print(f"‚úÖ Ainda h√° {available_keys} chaves Gemini dispon√≠veis.")
        add_real_time_log(f"‚úÖ {available_keys} chaves Gemini ainda dispon√≠veis", "info", "gemini-available")
        return True

def check_gemini_availability():
    """Verificar se h√° chaves Gemini dispon√≠veis"""
    if not GEMINI_KEYS_ROTATION['keys']:
        load_gemini_keys()
    
    # Reset di√°rio
    today = datetime.now().date()
    if GEMINI_KEYS_ROTATION['last_reset'] != today:
        GEMINI_KEYS_ROTATION['usage_count'] = {}
        GEMINI_KEYS_ROTATION['last_reset'] = today
    
    # Verificar se alguma chave ainda tem quota dispon√≠vel
    for key in GEMINI_KEYS_ROTATION['keys']:
        usage = GEMINI_KEYS_ROTATION['usage_count'].get(key, 0)
        if usage < 250:  # Limite de 250 por chave (otimizado para free tier)
            return True
    
    return False

def get_fallback_provider_info():
    """Obter informa√ß√µes sobre provedores de fallback dispon√≠veis com hierarquia: Gemini ‚Üí OpenRouter ‚Üí OpenAI"""
    try:
        print("üîç [FALLBACK DEBUG] Iniciando verifica√ß√£o de provedores de fallback...")
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
        print(f"üîç [FALLBACK DEBUG] Caminho do arquivo de configura√ß√£o: {config_path}")
        
        if os.path.exists(config_path):
            print("üîç [FALLBACK DEBUG] Arquivo de configura√ß√£o encontrado, carregando...")
            with open(config_path, 'r') as f:
                keys = json.load(f)
            
            print(f"üîç [FALLBACK DEBUG] Chaves carregadas: {list(keys.keys()) if keys else 'Nenhuma'}")
            
            # Verificar OpenRouter primeiro (fallback secund√°rio preferido)
            openrouter_key = keys.get('openrouter', '')
            print(f"üîç [FALLBACK DEBUG] Chave OpenRouter: {'Presente' if openrouter_key else 'Ausente'} (tamanho: {len(openrouter_key)})")
            if openrouter_key and len(openrouter_key) > 10:
                print(f"‚úÖ [FALLBACK DEBUG] OpenRouter dispon√≠vel como fallback secund√°rio (chave: {openrouter_key[:10]}...)")
                add_real_time_log("üîÑ OpenRouter dispon√≠vel como fallback secund√°rio", "info", "fallback")
                return {
                    'provider': 'openrouter',
                    'key': openrouter_key,
                    'available': ['openrouter'],
                    'priority': 2
                }
            else:
                print("‚ùå [FALLBACK DEBUG] OpenRouter n√£o dispon√≠vel (chave inv√°lida ou muito curta)")
            
            # Verificar OpenAI como terceira op√ß√£o (fallback terci√°rio)
            openai_key = keys.get('openai', '')
            print(f"üîç [FALLBACK DEBUG] Chave OpenAI: {'Presente' if openai_key else 'Ausente'} (tamanho: {len(openai_key)})")
            if openai_key and len(openai_key) > 10:
                print(f"‚úÖ [FALLBACK DEBUG] OpenAI dispon√≠vel como fallback terci√°rio (chave: {openai_key[:10]}...)")
                add_real_time_log("üîÑ OpenAI dispon√≠vel como fallback terci√°rio", "info", "fallback")
                return {
                    'provider': 'openai',
                    'key': openai_key,
                    'available': ['openai'],
                    'priority': 3
                }
            else:
                print("‚ùå [FALLBACK DEBUG] OpenAI n√£o dispon√≠vel (chave inv√°lida ou muito curta)")
        else:
            print("‚ùå [FALLBACK DEBUG] Arquivo de configura√ß√£o n√£o encontrado")
                
        print(f"‚ùå [FALLBACK DEBUG] Nenhum provedor de fallback dispon√≠vel")
        add_real_time_log("‚ùå Nenhum provedor de fallback dispon√≠vel", "error", "fallback")
        return None
        
    except Exception as e:
        print(f"‚ùå [FALLBACK DEBUG] Erro ao verificar provedores: {e}")
        import traceback
        print(f"‚ùå [FALLBACK DEBUG] Traceback: {traceback.format_exc()}")
        add_real_time_log(f"‚ùå Erro ao verificar provedores de fallback: {e}", "error", "fallback")
        return None

def get_next_rapidapi_key():
    """Obter pr√≥xima chave RapidAPI na rota√ß√£o, evitando chaves que falharam por quota"""
    if not RAPIDAPI_KEYS_ROTATION['keys']:
        load_rapidapi_keys()
    
    if not RAPIDAPI_KEYS_ROTATION['keys']:
        return None
    
    # Reset di√°rio das chaves falhadas
    today = datetime.now().date()
    if RAPIDAPI_KEYS_ROTATION['last_reset'] != today:
        RAPIDAPI_KEYS_ROTATION['failed_keys'] = set()
        RAPIDAPI_KEYS_ROTATION['last_reset'] = today
        print("üîÑ Reset di√°rio: chaves RapidAPI falhadas foram limpas")
        add_real_time_log("üîÑ Reset di√°rio: chaves RapidAPI falhadas foram limpas", "info", "rapidapi-rotation")
    
    # Filtrar chaves dispon√≠veis (n√£o falhadas)
    available_keys = [key for key in RAPIDAPI_KEYS_ROTATION['keys'] if key not in RAPIDAPI_KEYS_ROTATION['failed_keys']]
    
    if not available_keys:
        print("‚ö†Ô∏è Todas as chaves RapidAPI excederam a quota. Aguarde reset di√°rio.")
        add_real_time_log("‚ö†Ô∏è Todas as chaves RapidAPI excederam a quota. Aguarde reset di√°rio.", "warning", "rapidapi-rotation")
        return None
    
    # Usar √≠ndice circular apenas nas chaves dispon√≠veis
    if RAPIDAPI_KEYS_ROTATION['current_index'] >= len(available_keys):
        RAPIDAPI_KEYS_ROTATION['current_index'] = 0
    
    current_key = available_keys[RAPIDAPI_KEYS_ROTATION['current_index']]
    
    # Avan√ßar para pr√≥xima chave dispon√≠vel
    RAPIDAPI_KEYS_ROTATION['current_index'] = (RAPIDAPI_KEYS_ROTATION['current_index'] + 1) % len(available_keys)
    
    print(f"üîë Usando chave RapidAPI ({len(available_keys)} dispon√≠veis): {current_key[:20]}...")
    add_real_time_log(f"üîë Usando chave RapidAPI ({len(available_keys)} dispon√≠veis): {current_key[:20]}...", "info", "rapidapi-rotation")
    
    return current_key

def mark_rapidapi_key_failed(api_key):
    """Marcar uma chave RapidAPI como falhada por quota excedida"""
    if api_key:
        RAPIDAPI_KEYS_ROTATION['failed_keys'].add(api_key)
        print(f"‚ùå Chave RapidAPI marcada como falhada: {api_key[:20]}...")
        add_real_time_log(f"‚ùå Chave RapidAPI marcada como falhada: {api_key[:20]}...", "error", "rapidapi-rotation")
        print(f"üìä Chaves falhadas: {len(RAPIDAPI_KEYS_ROTATION['failed_keys'])}/{len(RAPIDAPI_KEYS_ROTATION['keys'])}")
        add_real_time_log(f"üìä Chaves falhadas: {len(RAPIDAPI_KEYS_ROTATION['failed_keys'])}/{len(RAPIDAPI_KEYS_ROTATION['keys'])}", "info", "rapidapi-rotation")
        
        # Se todas as chaves falharam, informar
        if len(RAPIDAPI_KEYS_ROTATION['failed_keys']) >= len(RAPIDAPI_KEYS_ROTATION['keys']):
            print("‚ö†Ô∏è ATEN√á√ÉO: Todas as chaves RapidAPI excederam a quota mensal!")

def apply_rapidapi_throttle():
    """Aplicar throttling m√≠nimo para m√°xima velocidade"""
    print(f"üîç DEBUG THROTTLE: Throttling m√≠nimo aplicado")
    
    with RAPIDAPI_THROTTLE['lock']:
        current_time = time.time()
        time_since_last = current_time - RAPIDAPI_THROTTLE['last_request_time']
        
        # Delay m√≠nimo apenas se necess√°rio (m√°ximo 0.5s)
        min_delay = 0.5
        
        if time_since_last < min_delay:
            sleep_time = min_delay - time_since_last
            print(f"‚è±Ô∏è Delay m√≠nimo: {sleep_time:.2f}s")
            time.sleep(sleep_time)
        
        RAPIDAPI_THROTTLE['last_request_time'] = time.time()

def handle_rapidapi_429():
    """Lidar com erro 429 (rate limiting) da RapidAPI - VERS√ÉO OTIMIZADA"""
    with RAPIDAPI_THROTTLE['lock']:
        RAPIDAPI_THROTTLE['consecutive_429s'] += 1
        
        # Aumentar delay adaptativo de forma mais conservadora
        if RAPIDAPI_THROTTLE['consecutive_429s'] == 1:
            RAPIDAPI_THROTTLE['adaptive_delay'] = 10.0  # Primeiro 429: 10s
        elif RAPIDAPI_THROTTLE['consecutive_429s'] == 2:
            RAPIDAPI_THROTTLE['adaptive_delay'] = 20.0  # Segundo 429: 20s
        elif RAPIDAPI_THROTTLE['consecutive_429s'] == 3:
            RAPIDAPI_THROTTLE['adaptive_delay'] = 40.0  # Terceiro 429: 40s
        else:
            RAPIDAPI_THROTTLE['adaptive_delay'] = min(60.0, RAPIDAPI_THROTTLE['adaptive_delay'] * 1.5)  # M√°ximo 60s
        
        print(f"üö´ Rate limit detectado! Aumentando delay para {RAPIDAPI_THROTTLE['adaptive_delay']}s (429s consecutivos: {RAPIDAPI_THROTTLE['consecutive_429s']})")
        add_real_time_log(f"üö´ Rate limit detectado! Delay aumentado para {RAPIDAPI_THROTTLE['adaptive_delay']}s", "warning", "rapidapi-throttle")

def reset_rapidapi_throttle_success():
    """Resetar throttling ap√≥s requisi√ß√£o bem-sucedida e incrementar rate limiting global"""
    # Incrementar contador de rate limiting global
    increment_rate_limit()
    
    with RAPIDAPI_THROTTLE['lock']:
        if RAPIDAPI_THROTTLE['consecutive_429s'] > 0:
            print(f"‚úÖ Requisi√ß√£o RapidAPI bem-sucedida! Resetando throttling (era {RAPIDAPI_THROTTLE['adaptive_delay']}s)")
            add_real_time_log("‚úÖ Requisi√ß√£o RapidAPI bem-sucedida! Throttling resetado", "info", "rapidapi-throttle")
        
        RAPIDAPI_THROTTLE['consecutive_429s'] = 0
        RAPIDAPI_THROTTLE['adaptive_delay'] = RAPIDAPI_THROTTLE['min_delay']

def get_cache_key(endpoint, params):
    """Gerar chave de cache baseada no endpoint e par√¢metros"""
    import hashlib
    # Criar string √∫nica baseada no endpoint e par√¢metros
    cache_string = f"{endpoint}_{str(sorted(params.items()))}"
    return hashlib.md5(cache_string.encode()).hexdigest()

def get_from_cache(endpoint, params, custom_ttl=None, cache_subdir=None):
    """Obter dados do cache se ainda v√°lidos - VERS√ÉO SEM LOCK"""
    try:
        print(f"üíæ CACHE DEBUG: Iniciando verifica√ß√£o de cache para {endpoint}")
        cache_key = get_cache_key(endpoint, params)
        print(f"üíæ CACHE DEBUG: Cache key gerada: {cache_key[:20]}...")
        
        # Se um subdiret√≥rio de cache foi especificado, usar um arquivo de cache separado
        if cache_subdir:
            cache_dir = os.path.join(os.path.dirname(__file__), '..', 'cache', cache_subdir)
            cache_file = os.path.join(cache_dir, 'rapidapi_cache.json')
            
            # Carregar cache do arquivo especificado
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    cache_store = cache_data.get('data', {})
                    cache_timestamps = cache_data.get('timestamps', {})
                except Exception as e:
                    print(f"‚ùå Erro ao carregar cache persistente: {e}")
                    cache_store = {}
                    cache_timestamps = {}
            else:
                cache_store = {}
                cache_timestamps = {}
        else:
            # Usar o cache global
            cache_store = RAPIDAPI_CACHE['data']
            cache_timestamps = RAPIDAPI_CACHE['timestamps']
        
        if cache_key in cache_store:
            print(f"üíæ CACHE DEBUG: Cache encontrado para {endpoint}")
            timestamp = cache_timestamps.get(cache_key, 0)
            
            # Determinar TTL baseado no tipo de endpoint
            if custom_ttl:
                ttl = custom_ttl
            elif 'channel' in endpoint.lower():
                ttl = RAPIDAPI_CACHE['channel_ttl']  # 2 horas para dados de canal
            elif 'video' in endpoint.lower():
                ttl = RAPIDAPI_CACHE['video_ttl']  # 30 minutos para v√≠deos
            else:
                ttl = RAPIDAPI_CACHE['ttl']  # 1 hora padr√£o
            
            current_time = time.time()
            age = current_time - timestamp
            
            print(f"üíæ CACHE DEBUG: Age: {age:.0f}s, TTL: {ttl}s")
            
            if age < ttl:
                remaining_time = ttl - age
                print(f"üì¶ Cache hit para {endpoint} (restam: {remaining_time:.0f}s)")
                return cache_store[cache_key]
            else:
                # Cache expirado
                print(f"‚è∞ Cache expirado para {endpoint}")
                # Se estivermos usando cache global, remover do cache global
                if not cache_subdir and cache_key in RAPIDAPI_CACHE['data']:
                    del RAPIDAPI_CACHE['data'][cache_key]
                    del RAPIDAPI_CACHE['timestamps'][cache_key]
        else:
            print(f"üíæ CACHE DEBUG: Nenhum cache encontrado para {endpoint}")
        
        print(f"üíæ CACHE DEBUG: Retornando None para {endpoint}")
        return None
        
    except Exception as e:
        print(f"‚ùå Erro em get_from_cache: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def save_to_cache(endpoint, params, data, custom_ttl=None, cache_subdir=None):
    """Salvar dados no cache - VERS√ÉO OTIMIZADA"""
    print(f"üîç DEBUG: Iniciando save_to_cache para {endpoint}")
    
    try:
        # Se um subdiret√≥rio de cache foi especificado, usar um arquivo de cache separado
        if cache_subdir:
            cache_dir = os.path.join(os.path.dirname(__file__), '..', 'cache', cache_subdir)
            cache_file = os.path.join(cache_dir, 'rapidapi_cache.json')
            
            # Criar diret√≥rio se n√£o existir
            if not os.path.exists(cache_dir):
                os.makedirs(cache_dir)
            
            # Carregar cache existente
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                except Exception as e:
                    print(f"‚ùå Erro ao carregar cache persistente: {e}")
                    cache_data = {'data': {}, 'timestamps': {}}
            else:
                cache_data = {'data': {}, 'timestamps': {}}
            
            # Atualizar cache
            cache_key = get_cache_key(endpoint, params)
            cache_data['data'][cache_key] = data
            cache_data['timestamps'][cache_key] = time.time()
            
            # Determinar TTL baseado no tipo de endpoint
            if custom_ttl:
                ttl = custom_ttl
            elif 'channel' in endpoint.lower():
                ttl = RAPIDAPI_CACHE['channel_ttl']  # 2 horas para dados de canal
            elif 'video' in endpoint.lower():
                ttl = RAPIDAPI_CACHE['video_ttl']  # 30 minutos para v√≠deos
            else:
                ttl = RAPIDAPI_CACHE['ttl']  # 1 hora padr√£o
                
            print(f"üíæ Dados salvos no cache para {endpoint} (TTL: {ttl}s = {ttl/3600:.1f}h)")
            add_real_time_log(f"[CACHE] Cache salvo para {endpoint} (TTL: {ttl/3600:.1f}h)", "info", "rapidapi-cache")
            
            # Salvar cache atualizado
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False)
        else:
            # Usar o cache global
            print(f"üîç DEBUG: Adquirindo lock do cache...")
            with RAPIDAPI_CACHE['lock']:
                print(f"üîç DEBUG: Lock adquirido, gerando cache_key...")
                cache_key = get_cache_key(endpoint, params)
                print(f"üîç DEBUG: Cache key gerada: {cache_key[:20]}...")
                
                print(f"üîç DEBUG: Salvando dados no cache...")
                RAPIDAPI_CACHE['data'][cache_key] = data
                RAPIDAPI_CACHE['timestamps'][cache_key] = time.time()
                print(f"üîç DEBUG: Dados salvos no cache interno")
                
                # Determinar TTL baseado no tipo de endpoint
                if custom_ttl:
                    ttl = custom_ttl
                elif 'channel' in endpoint.lower():
                    ttl = RAPIDAPI_CACHE['channel_ttl']  # 2 horas para dados de canal
                elif 'video' in endpoint.lower():
                    ttl = RAPIDAPI_CACHE['video_ttl']  # 30 minutos para v√≠deos
                else:
                    ttl = RAPIDAPI_CACHE['ttl']  # 1 hora padr√£o
                    
                print(f"üíæ Dados salvos no cache para {endpoint} (TTL: {ttl}s = {ttl/3600:.1f}h)")
                add_real_time_log(f"[CACHE] Cache salvo para {endpoint} (TTL: {ttl/3600:.1f}h)", "info", "rapidapi-cache")
            
            print(f"üîç DEBUG: Lock liberado, chamando save_persistent_cache...")
            # Salvar cache persistente ap√≥s cada opera√ß√£o
            save_persistent_cache()
        
        print(f"üîç DEBUG: save_to_cache conclu√≠do com sucesso para {endpoint}")
        
    except Exception as e:
        print(f"‚ùå ERRO em save_to_cache: {e}")
        raise

def load_persistent_cache():
    """Carregar cache persistente do arquivo"""
    try:
        cache_file = RAPIDAPI_CACHE['file_path']
        cache_dir = os.path.dirname(cache_file)
        
        # Criar diret√≥rio se n√£o existir
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
            print(f"üìÅ Diret√≥rio de cache criado: {cache_dir}")
            return
        
        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            with RAPIDAPI_CACHE['lock']:
                RAPIDAPI_CACHE['data'] = cache_data.get('data', {})
                RAPIDAPI_CACHE['timestamps'] = cache_data.get('timestamps', {})
            
            # Limpar cache expirado ap√≥s carregar
            clear_expired_cache()
            
            print(f"üì¶ Cache persistente carregado: {len(RAPIDAPI_CACHE['data'])} itens")
            add_real_time_log(f"üì¶ Cache persistente carregado: {len(RAPIDAPI_CACHE['data'])} itens", "info", "rapidapi-cache")
        else:
            print("üì¶ Arquivo de cache n√£o encontrado, iniciando com cache vazio")
            
    except Exception as e:
        print(f"‚ùå Erro ao carregar cache persistente: {e}")
        add_real_time_log(f"‚ùå Erro ao carregar cache persistente: {e}", "error", "rapidapi-cache")

def save_persistent_cache():
    """Salvar cache persistente no arquivo"""
    print(f"üîç DEBUG: Iniciando save_persistent_cache")
    
    try:
        print(f"üîç DEBUG: Obtendo caminho do arquivo de cache...")
        cache_file = RAPIDAPI_CACHE['file_path']
        cache_dir = os.path.dirname(cache_file)
        print(f"üîç DEBUG: Cache file: {cache_file}")
        
        # Criar diret√≥rio se n√£o existir
        print(f"üîç DEBUG: Verificando se diret√≥rio existe...")
        if not os.path.exists(cache_dir):
            print(f"üîç DEBUG: Criando diret√≥rio: {cache_dir}")
            os.makedirs(cache_dir)
        
        print(f"üîç DEBUG: Adquirindo lock para leitura dos dados...")
        with RAPIDAPI_CACHE['lock']:
            print(f"üîç DEBUG: Lock adquirido, preparando dados...")
            cache_data = {
                'data': RAPIDAPI_CACHE['data'],
                'timestamps': RAPIDAPI_CACHE['timestamps'],
                'saved_at': time.time()
            }
            print(f"üîç DEBUG: Dados preparados: {len(cache_data['data'])} itens")
        
        print(f"üîç DEBUG: Lock liberado, abrindo arquivo para escrita...")
        with open(cache_file, 'w', encoding='utf-8') as f:
            print(f"üîç DEBUG: Arquivo aberto, salvando JSON...")
            json.dump(cache_data, f, indent=2, ensure_ascii=False)
            print(f"üîç DEBUG: JSON salvo com sucesso")
        
        print(f"üíæ Cache persistente salvo: {len(cache_data['data'])} itens")
        add_real_time_log(f"üíæ Cache persistente salvo: {len(cache_data['data'])} itens", "info", "rapidapi-cache")
        print(f"üîç DEBUG: save_persistent_cache conclu√≠do com sucesso")
        
    except Exception as e:
        print(f"‚ùå ERRO em save_persistent_cache: {e}")
        add_real_time_log(f"‚ùå Erro ao salvar cache persistente: {e}", "error", "rapidapi-cache")
        raise

def clear_expired_cache():
    """Limpar cache expirado"""
    with RAPIDAPI_CACHE['lock']:
        current_time = time.time()
        expired_keys = []
        
        for cache_key, timestamp in RAPIDAPI_CACHE['timestamps'].items():
            if current_time - timestamp >= RAPIDAPI_CACHE['ttl']:
                expired_keys.append(cache_key)
        
        for key in expired_keys:
            del RAPIDAPI_CACHE['data'][key]
            del RAPIDAPI_CACHE['timestamps'][key]
        
        if expired_keys:
            print(f"üßπ Removidas {len(expired_keys)} entradas expiradas do cache")
            add_real_time_log(f"üßπ Cache limpo: {len(expired_keys)} entradas removidas", "info", "rapidapi-cache")
    
    return True

def check_rate_limit():
    """Verificar se pode fazer requisi√ß√£o baseado no rate limiting global"""
    with RAPIDAPI_RATE_LIMIT['lock']:
        current_time = time.time()
        
        # Reset di√°rio
        today = datetime.now().date()
        if RAPIDAPI_RATE_LIMIT['last_reset_date'] != today:
            RAPIDAPI_RATE_LIMIT['total_requests_today'] = 0
            RAPIDAPI_RATE_LIMIT['last_reset_date'] = today
            print("üîÑ Reset di√°rio do contador de requisi√ß√µes RapidAPI")
            add_real_time_log("üîÑ Reset di√°rio do contador de requisi√ß√µes RapidAPI", "info", "rapidapi-rate-limit")
        
        # Verificar se est√° em pausa for√ßada
        if current_time < RAPIDAPI_RATE_LIMIT['pause_until']:
            remaining = int(RAPIDAPI_RATE_LIMIT['pause_until'] - current_time)
            print(f"‚è∏Ô∏è Rate limit ativo: aguardando {remaining}s")
            return False, f"Rate limit ativo. Aguarde {remaining} segundos."
        
        # Reset da janela de minuto
        if current_time - RAPIDAPI_RATE_LIMIT['minute_window_start'] >= 60:
            RAPIDAPI_RATE_LIMIT['requests_per_minute'] = 0
            RAPIDAPI_RATE_LIMIT['minute_window_start'] = current_time
        
        # Reset da janela de hora
        if current_time - RAPIDAPI_RATE_LIMIT['hour_window_start'] >= 3600:
            RAPIDAPI_RATE_LIMIT['requests_per_hour'] = 0
            RAPIDAPI_RATE_LIMIT['hour_window_start'] = current_time
        
        # Verificar limites
        if RAPIDAPI_RATE_LIMIT['requests_per_minute'] >= RAPIDAPI_RATE_LIMIT['max_requests_per_minute']:
            # Pausar at√© o pr√≥ximo minuto
            pause_time = 60 - (current_time - RAPIDAPI_RATE_LIMIT['minute_window_start'])
            RAPIDAPI_RATE_LIMIT['pause_until'] = current_time + pause_time
            print(f"üö´ Limite por minuto atingido: pausando por {int(pause_time)}s")
            add_real_time_log(f"üö´ Limite por minuto atingido: pausando por {int(pause_time)}s", "warning", "rapidapi-rate-limit")
            return False, f"Limite de {RAPIDAPI_RATE_LIMIT['max_requests_per_minute']} requisi√ß√µes por minuto atingido."
        
        if RAPIDAPI_RATE_LIMIT['requests_per_hour'] >= RAPIDAPI_RATE_LIMIT['max_requests_per_hour']:
            # Pausar at√© a pr√≥xima hora
            pause_time = 3600 - (current_time - RAPIDAPI_RATE_LIMIT['hour_window_start'])
            RAPIDAPI_RATE_LIMIT['pause_until'] = current_time + pause_time
            print(f"üö´ Limite por hora atingido: pausando por {int(pause_time/60)}min")
            add_real_time_log(f"üö´ Limite por hora atingido: pausando por {int(pause_time/60)}min", "warning", "rapidapi-rate-limit")
            return False, f"Limite de {RAPIDAPI_RATE_LIMIT['max_requests_per_hour']} requisi√ß√µes por hora atingido."
        
        return True, "OK"

def increment_rate_limit():
    """Incrementar contadores de rate limiting ap√≥s requisi√ß√£o bem-sucedida"""
    with RAPIDAPI_RATE_LIMIT['lock']:
        RAPIDAPI_RATE_LIMIT['requests_per_minute'] += 1
        RAPIDAPI_RATE_LIMIT['requests_per_hour'] += 1
        RAPIDAPI_RATE_LIMIT['total_requests_today'] += 1
        
        print(f"üìä Rate limit: {RAPIDAPI_RATE_LIMIT['requests_per_minute']}/min, {RAPIDAPI_RATE_LIMIT['requests_per_hour']}/h, {RAPIDAPI_RATE_LIMIT['total_requests_today']} hoje")
        add_real_time_log(f"üìä Requisi√ß√µes: {RAPIDAPI_RATE_LIMIT['requests_per_minute']}/min, {RAPIDAPI_RATE_LIMIT['requests_per_hour']}/h", "info", "rapidapi-rate-limit")

def get_rate_limit_status():
    """Obter status atual do rate limiting"""
    with RAPIDAPI_RATE_LIMIT['lock']:
        current_time = time.time()
        
        # Calcular tempo restante nas janelas
        minute_remaining = 60 - (current_time - RAPIDAPI_RATE_LIMIT['minute_window_start'])
        hour_remaining = 3600 - (current_time - RAPIDAPI_RATE_LIMIT['hour_window_start'])
        
        return {
            'requests_per_minute': RAPIDAPI_RATE_LIMIT['requests_per_minute'],
            'max_requests_per_minute': RAPIDAPI_RATE_LIMIT['max_requests_per_minute'],
            'requests_per_hour': RAPIDAPI_RATE_LIMIT['requests_per_hour'],
            'max_requests_per_hour': RAPIDAPI_RATE_LIMIT['max_requests_per_hour'],
            'total_requests_today': RAPIDAPI_RATE_LIMIT['total_requests_today'],
            'minute_window_remaining': max(0, int(minute_remaining)),
            'hour_window_remaining': max(0, int(hour_remaining/60)),
            'is_paused': current_time < RAPIDAPI_RATE_LIMIT['pause_until'],
            'pause_remaining': max(0, int(RAPIDAPI_RATE_LIMIT['pause_until'] - current_time))
        }



# ================================
# üìä MONITORAMENTO RAPIDAPI
# ================================

@automations_bp.route('/rapidapi-status', methods=['GET'])
def get_rapidapi_status():
    """Obter status atual do RapidAPI incluindo rate limiting"""
    try:
        # Status do rate limiting
        rate_limit_status = get_rate_limit_status()
        
        # Status do throttling
        throttle_status = {
            'adaptive_delay': RAPIDAPI_THROTTLE['adaptive_delay'],
            'min_delay': RAPIDAPI_THROTTLE['min_delay'],
            'consecutive_429s': RAPIDAPI_THROTTLE['consecutive_429s'],
            'last_request_time': RAPIDAPI_THROTTLE['last_request_time']
        }
        
        # Status do cache
        cache_status = {
            'total_items': len(RAPIDAPI_CACHE['data']),
            'ttl_default': RAPIDAPI_CACHE['ttl'],
            'ttl_channel': RAPIDAPI_CACHE['channel_ttl'],
            'ttl_video': RAPIDAPI_CACHE['video_ttl']
        }
        
        # Adicionar informa√ß√£o sobre o m√©todo usado
        result_data = {
            'videos': filtered_videos,
            'total_videos': len(filtered_videos),
            'channel_details': channel_details.get('data', {}),
            'extraction_method': 'RapidAPI',
            'extraction_time': f'{extraction_time:.2f}s'
        }
        
        return jsonify({
            'success': True,
            'data': {
                'rate_limit': rate_limit_status,
                'throttle': throttle_status,
                'cache': cache_status,
                'timestamp': time.time()
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/rapidapi-cache/clear', methods=['POST'])
def clear_rapidapi_cache():
    """Limpar cache do RapidAPI"""
    try:
        with RAPIDAPI_CACHE['lock']:
            items_count = len(RAPIDAPI_CACHE['data'])
            RAPIDAPI_CACHE['data'].clear()
            RAPIDAPI_CACHE['timestamps'].clear()
        
        # Salvar cache vazio
        save_persistent_cache()
        
        print(f"üßπ Cache RapidAPI limpo: {items_count} itens removidos")
        add_real_time_log(f"üßπ Cache RapidAPI limpo: {items_count} itens removidos", "info", "rapidapi-cache")
        
        return jsonify({
            'success': True,
            'message': f'Cache limpo com sucesso. {items_count} itens removidos.'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/rapidapi-throttle/reset', methods=['POST'])
def reset_rapidapi_throttle():
    """Resetar throttling do RapidAPI"""
    try:
        with RAPIDAPI_THROTTLE['lock']:
            old_delay = RAPIDAPI_THROTTLE['adaptive_delay']
            RAPIDAPI_THROTTLE['adaptive_delay'] = RAPIDAPI_THROTTLE['min_delay']
            RAPIDAPI_THROTTLE['consecutive_429s'] = 0
        
        print(f"üîÑ Throttling RapidAPI resetado: {old_delay}s ‚Üí {RAPIDAPI_THROTTLE['min_delay']}s")
        add_real_time_log(f"üîÑ Throttling RapidAPI resetado: {old_delay}s ‚Üí {RAPIDAPI_THROTTLE['min_delay']}s", "info", "rapidapi-throttle")
        
        return jsonify({
            'success': True,
            'message': f'Throttling resetado de {old_delay}s para {RAPIDAPI_THROTTLE["min_delay"]}s'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ================================
# üß™ TESTE RAPIDAPI
# ================================

@automations_bp.route('/test-rapidapi-manual', methods=['POST'])
def test_rapidapi_manual():
    """Testar conex√£o com RapidAPI YouTube V2 com chave manual"""
    import time
    
    try:
        data = request.get_json()
        api_key = data.get('api_key', '').strip()

        if not api_key:
            return jsonify({
                'success': False,
                'error': 'Chave da API RapidAPI √© obrigat√≥ria'
            }), 400

        # Testar com um canal conhecido
        test_channel = "UCX6OQ3DkcsbYNE6H8uQQuVA"  # MrBeast

        headers = {
            "X-RapidAPI-Key": api_key,
            "X-RapidAPI-Host": "youtube-v2.p.rapidapi.com"
        }

        # Testar endpoint de detalhes do canal com delays otimizados
        max_retries = 2
        base_delay = 1  # Delay m√≠nimo: 1 segundo
        
        for attempt in range(max_retries):
            if attempt > 0:
                delay = base_delay * (3 ** (attempt - 1))  # Backoff mais agressivo (3x)
                print(f"‚è≥ Aguardando {delay}s antes da tentativa {attempt + 1}...")
                time.sleep(delay)
            else:
                # Delay inicial mesmo na primeira tentativa
                print(f"‚è≥ Aguardando {base_delay}s para evitar rate limiting...")
                time.sleep(base_delay)
                
            response = requests.get(
                "https://youtube-v2.p.rapidapi.com/channel/details",
                headers=headers,
                params={"channel_id": test_channel},
                timeout=30
            )
            
            if response.status_code == 429:
                if attempt == max_retries - 1:
                    return jsonify({
                        'success': False,
                        'error': 'Limite de requisi√ß√µes excedido (429). Aguarde alguns minutos e tente novamente.'
                    })
                print(f"‚ö†Ô∏è Rate limit atingido (429), tentando novamente...")
                continue
            elif response.status_code == 200:
                # Resetar throttling ap√≥s sucesso
                reset_rapidapi_throttle_success()
                break

        return jsonify({
            'success': True,
            'data': {
                'status_code': response.status_code,
                'response': response.json() if response.status_code == 200 else response.text,
                'test_channel': test_channel
            }
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500



# ================================
# üì∫ EXTRA√á√ÉO YOUTUBE
# ================================

@automations_bp.route('/extract-youtube', methods=['POST'])
def extract_youtube_channel_content():
    """Extrair conte√∫do de canal do YouTube usando RapidAPI"""
    import time
    import threading
    
    # Timeout global usando threading (compat√≠vel com Windows)
    extraction_start_time = time.time()
    timeout_occurred = threading.Event()
    
    def timeout_handler():
        time.sleep(120)  # 120 segundos
        timeout_occurred.set()
    
    # Iniciar thread de timeout
    timeout_thread = threading.Thread(target=timeout_handler, daemon=True)
    timeout_thread.start()
    
    try:
        print(f"üöÄ Iniciando extra√ß√£o do YouTube √†s {time.strftime('%H:%M:%S')}")
        print(f"üîç DEBUG: Iniciando extract_youtube_channel_content")
        
        # Verificar se h√° dados JSON v√°lidos
        try:
            data = request.get_json()
            if data is None:
                print(f"‚ùå DEBUG: Dados JSON inv√°lidos ou ausentes")
                return jsonify({
                    'success': False,
                    'error': 'Dados JSON inv√°lidos ou ausentes'
                }), 400
        except Exception as json_error:
            print(f"‚ùå DEBUG: Erro ao processar JSON: {str(json_error)}")
            return jsonify({
                'success': False,
                'error': f'Erro ao processar JSON: {str(json_error)}'
            }), 400
        
        url = data.get('url', '').strip()
        channel_id_input = data.get('channel_id', '').strip()
        config = data.get('config', {})
        extraction_method = data.get('extraction_method', 'auto')  # auto, rapidapi, ytdlp

        print(f"üîç DEBUG: Recebida requisi√ß√£o - URL: {url}, Channel ID: {channel_id_input}, Config: {config}, M√©todo: {extraction_method}")
        
        # Priorizar channel_id se fornecido, sen√£o usar url
        input_value = channel_id_input if channel_id_input else url
        input_type = 'channel_id' if channel_id_input else 'url'
        
        print(f"üîç DEBUG: Usando {input_type}: {input_value}")

        if not input_value:
            print(f"‚ùå DEBUG: URL ou Channel ID vazio ou ausente")
            return jsonify({
                'success': False,
                'error': 'URL ou ID do canal √© obrigat√≥rio'
            }), 400

        print(f"üöÄ DEBUG EXTRA√á√ÉO: Iniciando extra√ß√£o do YouTube √†s {time.strftime('%H:%M:%S')}")
        print(f"üìä DEBUG EXTRA√á√ÉO: Input type: {input_type}, Input value: {input_value}")
        print(f"‚öôÔ∏è DEBUG EXTRA√á√ÉO: Configura√ß√£o: {config}")
        print(f"üîß DEBUG EXTRA√á√ÉO: M√©todo de extra√ß√£o: {extraction_method}")
        
        # Se m√©todo for apenas yt-dlp, usar diretamente
        if extraction_method == 'ytdlp':
            print(f"üõ°Ô∏è Usando yt-dlp diretamente (m√©todo selecionado)")
            try:
                ytdlp_result = get_channel_videos_ytdlp(input_value, config.get('max_titles', 10))
                if ytdlp_result.get('success'):
                    # Aplicar filtros se especificados
                    videos = ytdlp_result['data']['videos']
                    if config:
                        videos = filter_videos_by_config(videos, config)
                    
                    # Adicionar informa√ß√£o sobre o m√©todo usado
                    result_data = ytdlp_result['data']
                    result_data['extraction_method'] = 'yt-dlp'
                    result_data['videos'] = videos
                    result_data['total_videos'] = len(videos)
                    result_data['extraction_time'] = time.time() - extraction_start_time
                    
                    return jsonify({
                        'success': True,
                        'data': result_data,
                        'message': f'‚úÖ Extra√ß√£o conclu√≠da via yt-dlp. {len(videos)} v√≠deos encontrados.'
                    })
                else:
                    return jsonify({
                        'success': False,
                        'error': f'Erro no yt-dlp: {ytdlp_result.get("error", "Erro desconhecido")}'
                    }), 400
            except Exception as ytdlp_error:
                return jsonify({
                    'success': False,
                    'error': f'Erro no yt-dlp: {str(ytdlp_error)}'
                }), 400
        
        # Para m√©todos 'rapidapi' e 'auto', precisamos de chave RapidAPI
        api_key = get_next_rapidapi_key()
        if not api_key and extraction_method == 'rapidapi':
            return jsonify({
                'success': False,
                'error': 'Nenhuma chave RapidAPI dispon√≠vel. Verifique as configura√ß√µes.'
            }), 400
        elif not api_key and extraction_method == 'auto':
            # Se n√£o h√° chave RapidAPI no modo auto, usar yt-dlp diretamente
            print(f"‚ö†Ô∏è Nenhuma chave RapidAPI dispon√≠vel, usando yt-dlp diretamente")
            try:
                ytdlp_result = get_channel_videos_ytdlp(input_value, config.get('max_titles', 10))
                if ytdlp_result.get('success'):
                    videos = ytdlp_result['data']['videos']
                    if config:
                        videos = filter_videos_by_config(videos, config)
                    
                    result_data = ytdlp_result['data']
                    result_data['extraction_method'] = 'yt-dlp (sem chave RapidAPI)'
                    result_data['videos'] = videos
                    result_data['total_videos'] = len(videos)
                    result_data['extraction_time'] = time.time() - extraction_start_time
                    
                    return jsonify({
                        'success': True,
                        'data': result_data,
                        'message': f'‚úÖ Extra√ß√£o conclu√≠da via yt-dlp (sem chave RapidAPI). {len(videos)} v√≠deos encontrados.'
                    })
                else:
                    return jsonify({
                        'success': False,
                        'error': f'Erro no yt-dlp: {ytdlp_result.get("error", "Erro desconhecido")}'
                    }), 400
            except Exception as ytdlp_error:
                return jsonify({
                    'success': False,
                    'error': f'Erro no yt-dlp: {str(ytdlp_error)}'
                }), 400
        
        print(f"üîë DEBUG: Usando chave RapidAPI: {api_key[:10]}...")
        
        # Definir n√∫mero m√°ximo de tentativas com chaves diferentes
        max_key_attempts = 3
        
        # Determinar se √© ID do canal ou URL/nome
        channel_id = None
        channel_name = None

        # Se foi fornecido channel_id diretamente, usar ele
        if input_type == 'channel_id' and input_value.startswith('UC') and len(input_value) == 24:
            channel_id = input_value
            print(f"üîç DEBUG: Usando ID do canal fornecido diretamente: {channel_id}")
        elif input_value.startswith('UC') and len(input_value) == 24:
            channel_id = input_value
            print(f"üîç DEBUG: Detectado ID do canal na entrada: {channel_id}")
        else:
            # Tentar extrair ID do canal da URL
            channel_id = extract_channel_id_from_url(input_value, api_key)

            if channel_id:
                print(f"üîç DEBUG: ID do canal extra√≠do da URL: {channel_id}")
            else:
                # Extrair nome do canal para busca
                channel_name = extract_channel_name_or_id(input_value)
                print(f"üîç DEBUG: Nome extra√≠do do canal: {channel_name}")

                if not channel_name:
                    return jsonify({
                        'success': False,
                        'error': 'Formato inv√°lido. Use: Nome do canal, @handle, URL completa ou ID do canal'
                    }), 400

                # Verificar timeout antes de buscar ID do canal
                if timeout_occurred.is_set():
                    elapsed_time = time.time() - extraction_start_time
                    print(f"‚è±Ô∏è TIMEOUT: Opera√ß√£o cancelada durante busca de ID ap√≥s {elapsed_time:.2f}s")
                    return jsonify({
                        'success': False,
                        'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout. A busca do canal est√° demorando muito.'
                    }), 408
                
                # Obter ID do canal usando a API com rota√ß√£o de chaves
                print(f"üîç DEBUG EXTRA√á√ÉO: Iniciando busca de ID do canal para: {channel_name}")
                print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido at√© agora: {time.time() - extraction_start_time:.2f}s")
                
                # Tentar at√© 3 vezes com diferentes chaves se necess√°rio
                channel_id_result = None
                
                for key_attempt in range(max_key_attempts):
                    current_key = get_next_rapidapi_key()
                    if not current_key:
                        return jsonify({
                            'success': False,
                            'error': 'Nenhuma chave RapidAPI dispon√≠vel'
                        }), 400
                    
                    print(f"üîë DEBUG: Tentativa {key_attempt + 1} com chave: {current_key[:10]}...")
                    channel_id_result = get_channel_id_rapidapi(channel_name, current_key)
                    
                    if channel_id_result['success']:
                        break
                    elif 'quota' in channel_id_result.get('error', '').lower() or 'monthly' in channel_id_result.get('error', '').lower():
                        print(f"‚ö†Ô∏è Quota excedida para chave {current_key[:10]}..., tentando pr√≥xima chave")
                        mark_rapidapi_key_failed(current_key)
                        continue
                    elif 'chave rapidapi inv√°lida' in channel_id_result.get('error', '').lower() or 'sem permiss√µes' in channel_id_result.get('error', '').lower():
                        print(f"üö´ Chave RapidAPI inv√°lida: {current_key[:10]}..., tentando pr√≥xima chave")
                        mark_rapidapi_key_failed(current_key)
                        continue
                    else:
                        # Erro n√£o relacionado √† quota ou chave inv√°lida, parar tentativas
                        break
        
        print(f"üîç DEBUG: Resultado da busca do ID: {channel_id_result}")
        
        if not channel_id_result['success']:
            # Se RapidAPI falhou e estamos no modo auto, tentar yt-dlp como fallback
            if extraction_method == 'auto':
                print(f"‚ö†Ô∏è RapidAPI falhou para busca de ID, tentando yt-dlp como fallback...")
                try:
                    ytdlp_result = get_channel_videos_ytdlp(input_value, config.get('max_titles', 10))
                    if ytdlp_result.get('success'):
                        print(f"‚úÖ yt-dlp funcionou como fallback!")
                        # Aplicar filtros se especificados
                        videos = ytdlp_result['data']['videos']
                        if config:
                            videos = filter_videos_by_config(videos, config)
                        
                        # Adicionar informa√ß√£o sobre o m√©todo usado
                        result_data = ytdlp_result['data']
                        result_data['extraction_method'] = 'yt-dlp (fallback)'
                        result_data['videos'] = videos
                        result_data['total_videos'] = len(videos)
                        result_data['extraction_time'] = time.time() - extraction_start_time
                        
                        return jsonify({
                            'success': True,
                            'data': result_data,
                            'message': f'‚úÖ Extra√ß√£o conclu√≠da via yt-dlp (fallback). {len(videos)} v√≠deos encontrados.'
                        })
                    else:
                        print(f"‚ùå yt-dlp tamb√©m falhou: {ytdlp_result.get('error', 'Erro desconhecido')}")
                except Exception as ytdlp_error:
                    print(f"‚ùå Erro no fallback yt-dlp: {str(ytdlp_error)}")
            
            return jsonify(channel_id_result), 400
        
        channel_id = channel_id_result['data']['channel_id']
        print(f"üîç DEBUG: ID do canal obtido: {channel_id}")
        
        # Delay removido para acelerar extra√ß√£o
        print(f"‚ö° Delay sequencial removido ap√≥s get_channel_id_rapidapi")

        # Verificar timeout antes de buscar v√≠deos
        if timeout_occurred.is_set():
            elapsed_time = time.time() - extraction_start_time
            print(f"‚è±Ô∏è TIMEOUT: Opera√ß√£o cancelada antes da busca de v√≠deos ap√≥s {elapsed_time:.2f}s")
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout. A busca est√° demorando muito.'
            }), 408
        
        # Obter v√≠deos do canal com rota√ß√£o de chaves
        print(f"üé¨ DEBUG EXTRA√á√ÉO: Iniciando busca de v√≠deos do canal: {channel_id}")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido at√© busca de v√≠deos: {time.time() - extraction_start_time:.2f}s")
        
        # Tentar at√© 3 vezes com diferentes chaves se necess√°rio
        videos_result = None
        
        for key_attempt in range(max_key_attempts):
            current_key = get_next_rapidapi_key()
            if not current_key:
                return jsonify({
                    'success': False,
                    'error': 'Nenhuma chave RapidAPI dispon√≠vel para buscar v√≠deos'
                }), 400
            
            print(f"üîë DEBUG: Tentativa {key_attempt + 1} para v√≠deos com chave: {current_key[:10]}...")
            videos_result = get_channel_videos_rapidapi(channel_id, current_key)
            
            if videos_result['success']:
                break
            elif 'quota' in videos_result.get('error', '').lower() or 'monthly' in videos_result.get('error', '').lower():
                print(f"‚ö†Ô∏è Quota excedida para chave {current_key[:10]}..., tentando pr√≥xima chave")
                mark_rapidapi_key_failed(current_key)
                continue
            else:
                # Erro n√£o relacionado √† quota, parar tentativas
                break
        
        print(f"‚úÖ DEBUG EXTRA√á√ÉO: Loop de detalhes do canal conclu√≠do")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo ap√≥s detalhes do canal: {time.time() - extraction_start_time:.2f}s")
        
        print(f"‚úÖ DEBUG EXTRA√á√ÉO: Busca de v√≠deos conclu√≠da - Sucesso: {videos_result.get('success', False)}, Total: {len(videos_result.get('data', {}).get('videos', []))}")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido ap√≥s busca de v√≠deos: {time.time() - extraction_start_time:.2f}s")
        print(f"üîç DEBUG EXTRA√á√ÉO: Continuando para pr√≥xima etapa...")
        if not videos_result['success']:
            # Se RapidAPI falhou e estamos no modo auto, tentar yt-dlp como fallback
            if extraction_method == 'auto':
                print(f"‚ö†Ô∏è RapidAPI falhou para busca de v√≠deos, tentando yt-dlp como fallback...")
                try:
                    ytdlp_result = get_channel_videos_ytdlp(input_value, config.get('max_titles', 10))
                    if ytdlp_result.get('success'):
                        print(f"‚úÖ yt-dlp funcionou como fallback!")
                        # Aplicar filtros se especificados
                        videos = ytdlp_result['data']['videos']
                        if config:
                            videos = filter_videos_by_config(videos, config)
                        
                        # Adicionar informa√ß√£o sobre o m√©todo usado
                        result_data = ytdlp_result['data']
                        result_data['extraction_method'] = 'yt-dlp (fallback)'
                        result_data['videos'] = videos
                        result_data['total_videos'] = len(videos)
                        result_data['extraction_time'] = time.time() - extraction_start_time
                        
                        return jsonify({
                            'success': True,
                            'data': result_data,
                            'message': f'‚úÖ Extra√ß√£o conclu√≠da via yt-dlp (fallback). {len(videos)} v√≠deos encontrados.'
                        })
                    else:
                        print(f"‚ùå yt-dlp tamb√©m falhou: {ytdlp_result.get('error', 'Erro desconhecido')}")
                except Exception as ytdlp_error:
                    print(f"‚ùå Erro no fallback yt-dlp: {str(ytdlp_error)}")
            
            return jsonify(videos_result), 400
        
        # Delay removido para acelerar extra√ß√£o
        print(f"‚ö° DEBUG EXTRA√á√ÉO: Delay sequencial removido ap√≥s get_channel_videos_rapidapi")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo total sem delay: {time.time() - extraction_start_time:.2f}s")
        print(f"üîç DEBUG EXTRA√á√ÉO: Verificando timeout antes de buscar detalhes do canal...")
        
        # Verificar timeout antes de buscar detalhes do canal
        if timeout_occurred.is_set():
            elapsed_time = time.time() - extraction_start_time
            print(f"‚è±Ô∏è TIMEOUT: Opera√ß√£o cancelada antes da busca de detalhes ap√≥s {elapsed_time:.2f}s")
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout. A busca est√° demorando muito.'
            }), 408
        
        # Verificar timeout antes de buscar detalhes do canal
        if timeout_occurred.is_set():
            elapsed_time = time.time() - extraction_start_time
            print(f"‚è±Ô∏è TIMEOUT: Opera√ß√£o cancelada antes da busca de detalhes ap√≥s {elapsed_time:.2f}s")
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout. A extra√ß√£o est√° demorando muito.'
            }), 408
        
        # Obter detalhes do canal com rota√ß√£o de chaves
        print(f"üìã DEBUG EXTRA√á√ÉO: Iniciando busca de detalhes do canal: {channel_id}")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido at√© busca de detalhes: {time.time() - extraction_start_time:.2f}s")
        print(f"üîç DEBUG EXTRA√á√ÉO: Entrando no loop de tentativas para detalhes do canal...")
        channel_details = None
        
        for key_attempt in range(max_key_attempts):
            current_key = get_next_rapidapi_key()
            if not current_key:
                # Se n√£o conseguir chave para detalhes, continuar sem eles
                channel_details = {'success': False}
                break
            
            print(f"üîë DEBUG: Tentativa {key_attempt + 1} para detalhes com chave: {current_key[:10]}...")
            channel_details = get_channel_details_rapidapi(channel_id, current_key)
            
            if channel_details['success']:
                break
            elif 'quota' in channel_details.get('error', '').lower() or 'monthly' in channel_details.get('error', '').lower():
                print(f"‚ö†Ô∏è Quota excedida para chave {current_key[:10]}..., tentando pr√≥xima chave")
                mark_rapidapi_key_failed(current_key)
                continue
            else:
                # Erro n√£o relacionado √† quota, parar tentativas
                break
        
        # Verificar timeout antes de filtrar v√≠deos
        if timeout_occurred.is_set():
            elapsed_time = time.time() - extraction_start_time
            print(f"‚è±Ô∏è TIMEOUT: Opera√ß√£o cancelada antes do filtro ap√≥s {elapsed_time:.2f}s")
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout. A extra√ß√£o est√° demorando muito.'
            }), 408
        
        # Filtrar v√≠deos baseado na configura√ß√£o
        print(f"üîß DEBUG EXTRA√á√ÉO: Iniciando filtro de v√≠deos")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido at√© filtro: {time.time() - extraction_start_time:.2f}s")
        print(f"üîç DEBUG EXTRA√á√ÉO: Chamando filter_videos_by_config...")
        original_videos = videos_result['data']['videos']
        print(f"üìä DEBUG EXTRA√á√ÉO: V√≠deos antes do filtro: {len(original_videos)}")
        print(f"‚öôÔ∏è DEBUG EXTRA√á√ÉO: Configura√ß√£o de filtros: {config}")

        filtered_videos = filter_videos_by_config(original_videos, config)
        print(f"‚úÖ DEBUG EXTRA√á√ÉO: V√≠deos ap√≥s filtro: {len(filtered_videos)}")
        print(f"‚è±Ô∏è DEBUG EXTRA√á√ÉO: Tempo decorrido ap√≥s filtro: {time.time() - extraction_start_time:.2f}s")

        # Verificar timeout antes de retornar
        if timeout_occurred.is_set():
            elapsed_time = time.time() - extraction_start_time
            print(f"‚è±Ô∏è TIMEOUT GLOBAL: Opera√ß√£o cancelada ap√≥s {elapsed_time:.2f}s")
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout global (120s). A extra√ß√£o est√° demorando muito para responder.'
            }), 408
        
        extraction_time = time.time() - extraction_start_time
        print(f"‚úÖ Extra√ß√£o conclu√≠da em {extraction_time:.2f}s √†s {time.strftime('%H:%M:%S')}")
        
        # Adicionar dados adicionais ao result_data
        result_data.update({
            'channel_id': channel_id,
            'channel_name': channel_details['data']['title'] if channel_details['success'] else (channel_name or channel_id),
            'channel_description': channel_details['data']['description'] if channel_details['success'] else '',
            'total_views': sum(int(video.get('views', 0)) for video in filtered_videos),
            'total_likes': sum(int(video.get('like_count', 0)) for video in filtered_videos)
        })
        
        return jsonify({
            'success': True,
            'data': result_data,
            'message': f'‚úÖ Extra√ß√£o conclu√≠da via RapidAPI. {len(filtered_videos)} v√≠deos encontrados.'
        })
    
    except Exception as e:
        extraction_time = time.time() - extraction_start_time
        print(f"‚ùå Erro na extra√ß√£o ap√≥s {extraction_time:.2f}s: {str(e)}")
        
        # Verificar se foi timeout
        if timeout_occurred.is_set():
            return jsonify({
                'success': False,
                'error': '‚è±Ô∏è Opera√ß√£o cancelada por timeout global (120s). A extra√ß√£o est√° demorando muito para responder.'
            }), 408
        
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

# ================================
# üéØ GERA√á√ÉO DE T√çTULOS
# ================================

# ENDPOINT ANTIGO COMENTADO - USAR O NOVO ENDPOINT NA LINHA 2626
# @automations_bp.route('/generate-titles', methods=['POST'])
# def generate_titles_with_ai():
#     """Gerar t√≠tulos usando diferentes agentes de IA"""
#     try:
#         data = request.get_json()
#         agent = data.get('agent', 'gemini').lower()
#         api_key = data.get('api_key', '').strip()
#         instructions = data.get('instructions', '').strip()
#         source_titles = data.get('source_titles', [])
#         
#         if not api_key:
#             return jsonify({
#                 'success': False,
#                 'error': f'Chave da API {agent.upper()} √© obrigat√≥ria'
#             }), 400
#         
#         if not source_titles:
#             return jsonify({
#                 'success': False,
#                 'error': 'T√≠tulos de origem s√£o obrigat√≥rios'
#             }), 400
#         
#         if not instructions:
#             instructions = 'Crie t√≠tulos virais e chamativos baseados nos t√≠tulos fornecidos.'
#         
#         # Gerar t√≠tulos baseado no agente selecionado
#         if agent == 'chatgpt' or agent == 'openai':
#             result = generate_titles_with_openai(source_titles, instructions, api_key)
#         elif agent == 'claude':
#             result = generate_titles_with_claude(source_titles, instructions, api_key)
#         elif agent == 'gemini':
#             result = generate_titles_with_gemini(source_titles, instructions, api_key)
#         elif agent == 'openrouter':
#             result = generate_titles_with_openrouter(source_titles, instructions, api_key)
#         else:
#             return jsonify({
#                 'success': False,
#                 'error': f'Agente {agent} n√£o suportado'
#             }), 400
#         
#         return jsonify(result)
#     
#     except Exception as e:
#         return jsonify({
#             'success': False,
#             'error': f'Erro interno: {str(e)}'
#         }), 500

# ================================
# üìù GERA√á√ÉO DE ROTEIROS
# ================================

@automations_bp.route('/generate-script', methods=['POST'])
def generate_script_chapters():
    """Gerar roteiro completo com m√∫ltiplos cap√≠tulos usando Storyteller Unlimited"""
    try:
        from services.storyteller_service import StorytellerService
        
        data = request.get_json()
        title = data.get('title', '').strip()
        context = data.get('context', '').strip()
        num_chapters = data.get('num_chapters', 10)
        
        # Par√¢metros do Storyteller
        agent = data.get('storyteller_agent', 'millionaire_stories')
        target_words = data.get('target_words', 2500)
        
        if not title:
            return jsonify({
                'success': False,
                'error': 'T√≠tulo √© obrigat√≥rio'
            }), 400
            
        if not context:
            return jsonify({
                'success': False,
                'error': 'Contexto √© obrigat√≥rio'
            }), 400
        
        # Inicializar Storyteller Service
        storyteller_service = StorytellerService()
        
        print(f"üé¨ [STORYTELLER_AUTOMATION] Gerando roteiro com agente {agent}...")
        
        # Gerar roteiro com Storyteller Unlimited
        result = storyteller_service.generate_storyteller_script(
            title=title,
            premise=context,
            agent_type=agent if agent else 'millionaire_stories',
            num_chapters=num_chapters,
            provider='gemini'
        )
        
        if not result:
            return jsonify({
                'success': False,
                'error': 'Falha ao gerar roteiro com Storyteller Unlimited'
            }), 500
        
        chapters_data = result.get('chapters') or []
        if chapters_data:
            script_content = result.get('full_script', "\n\n".join(ch.get('content', '') for ch in chapters_data))
        else:
            script_content = result.get('full_script', '')
        
        # Formatar para compatibilidade
        return jsonify({
            'success': True,
            'script': script_content,
            'title': title,
            'context': context,
            'num_chapters': num_chapters,
            'character_count': len(script_content),
            'word_count': len(script_content.split()),
            'estimated_duration_minutes': len(script_content) // 200,
            'system_used': 'storyteller_unlimited',
            'agent_used': agent
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

# ================================
# üé≠ GERA√á√ÉO DE PREMISSAS
# ================================

@automations_bp.route('/generate-premise', methods=['POST'])
def generate_premise_with_ai():
    """Gerar premissa narrativa usando diferentes agentes de IA"""
    try:
        data = request.get_json()
        agent = data.get('agent', 'gemini').lower()
        api_key = data.get('api_key', '').strip()
        title = data.get('title', '').strip()
        resume = data.get('resume', '').strip()
        agent_prompt = data.get('agent_prompt', '').strip()

        # Para Gemini, usar rota√ß√£o de chaves se n√£o fornecida
        if not api_key and agent == 'gemini':
            api_key = get_next_gemini_key()
            if not api_key:
                return jsonify({
                    'success': False,
                    'error': 'Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.'
                }), 400
            print(f"üîÑ Usando rota√ß√£o de chaves Gemini para generate-premise")
            add_real_time_log(f"üîÑ Usando rota√ß√£o de chaves Gemini para generate-premise", "info", "gemini-rotation")
        elif not api_key:
            return jsonify({
                'success': False,
                'error': f'Chave da API {agent.upper()} √© obrigat√≥ria'
            }), 400

        if not title:
            return jsonify({
                'success': False,
                'error': 'T√≠tulo √© obrigat√≥rio'
            }), 400

        # Usar prompt padr√£o se n√£o fornecido
        if not agent_prompt:
            agent_prompt = "Crie uma premissa narrativa envolvente e criativa baseada no t√≠tulo e resumo fornecidos. A premissa deve ser clara, interessante e adequada para um v√≠deo educativo."

        # Gerar premissa baseado no agente selecionado
        if agent == 'chatgpt' or agent == 'openai':
            result = generate_premise_with_openai(title, resume, agent_prompt, api_key)
        elif agent == 'claude':
            result = generate_premise_with_claude(title, resume, agent_prompt, api_key)
        elif agent == 'gemini':
            result = generate_premise_with_gemini(title, resume, agent_prompt, api_key)
        elif agent == 'openrouter':
            result = generate_premise_with_openrouter(title, resume, agent_prompt, api_key)
        else:
            return jsonify({
                'success': False,
                'error': f'Agente {agent} n√£o suportado'
            }), 400

        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

def generate_premise_with_gemini(title, resume, prompt, api_key=None):
    """Gerar premissa usando Gemini com rota√ß√£o de chaves e retry autom√°tico"""
    import google.generativeai as genai
    
    # Tentar m√∫ltiplas chaves se necess√°rio
    # Usar a quantidade real de chaves dispon√≠veis
    max_retries = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
    print(f"üîë Usando {max_retries} chaves Gemini para premissa")
    last_error = None
    
    for attempt in range(max_retries):
        try:
            # Se n√£o foi fornecida chave ou tentativa anterior falhou, usar rota√ß√£o
            if not api_key or attempt > 0:
                api_key = get_next_gemini_key()
                if not api_key:
                    return {
                        'success': False,
                        'error': 'Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.'
                    }
                print(f"üîÑ Tentativa {attempt + 1}/{max_retries}: Usando rota√ß√£o de chaves Gemini para premissa")
            
            # Configurar Gemini diretamente
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # Criar prompt completo
            full_prompt = f"""
{prompt}

T√≠tulo: {title}
Resumo: {resume}

Por favor, crie uma premissa narrativa envolvente baseada no t√≠tulo e resumo fornecidos.
"""
            
            # Gerar conte√∫do diretamente com Gemini
            response = model.generate_content(full_prompt)
            premise_text = response.text.strip()
            print(f"‚úÖ Sucesso na gera√ß√£o de premissa com Gemini na tentativa {attempt + 1}")
            
            return {
                'success': True,
                'premise': premise_text,
                'title': title,
                'resume': resume
            }
            
        except Exception as e:
            error_str = str(e)
            last_error = error_str
            print(f"‚ùå Erro na tentativa {attempt + 1}: {error_str}")
            
            # Check if it's a quota error (429)
            if "429" in error_str or "quota" in error_str.lower() or "rate limit" in error_str.lower():
                if attempt < max_retries - 1:  # Not the last attempt
                    print(f"üîÑ Erro de quota detectado, tentando pr√≥xima chave Gemini...")
                    handle_gemini_429_error(error_str, api_key)
                    api_key = None  # For√ßar nova chave na pr√≥xima tentativa
                    continue
                else:
                    print("‚ùå Todas as tentativas de retry falharam")
                    handle_gemini_429_error(error_str, api_key)
            else:
                # For non-quota errors, don't retry
                print(f"‚ùå Erro n√£o relacionado √† quota, parando tentativas: {error_str}")
                break
    
    # Se chegou aqui, todas as tentativas falharam
    final_error = f'Falha na gera√ß√£o de premissa com Gemini ap√≥s todas as {max_retries} tentativas. √öltimo erro: {last_error}'
    return {
        'success': False,
        'error': final_error
    }

def generate_script_chapters_with_gemini_retry(title, context, num_chapters, api_key=None):
    """Gerar roteiro usando Gemini com rota√ß√£o de chaves e retry autom√°tico"""
    # Tentar m√∫ltiplas chaves se necess√°rio
    # Usar a quantidade real de chaves dispon√≠veis
    max_key_attempts = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
    print(f"üîë Usando {max_key_attempts} chaves Gemini para an√°lise de emo√ß√µes")
    last_error = None
    
    for attempt in range(max_key_attempts):
        try:
            # Se n√£o foi fornecida chave ou tentativa anterior falhou, usar rota√ß√£o
            if not api_key or attempt > 0:
                api_key = get_next_gemini_key()
                if not api_key:
                    return {
                        'success': False,
                        'error': 'Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.'
                    }
                print(f"üîÑ Tentativa {attempt + 1}: Usando rota√ß√£o de chaves Gemini para roteiro")
                add_real_time_log(f"üîÑ Tentativa {attempt + 1}: Usando rota√ß√£o de chaves Gemini para roteiro", "info", "gemini-rotation")
            
            # Chamar fun√ß√£o original do ai_services com retry
            result = generate_script_chapters_with_gemini(title, context, num_chapters, api_key)
            
            # Se sucesso, retornar resultado
            if result.get('success'):
                return result
            
            # Se falha, verificar se √© erro de quota
            error_str = result.get('error', '')
            last_error = error_str
            print(f"‚ùå Tentativa {attempt + 1} falhou: {error_str}")
            
            # Se √© erro 429 (quota exceeded), tentar pr√≥xima chave
            if "429" in error_str or "quota" in error_str.lower() or "exceeded" in error_str.lower():
                print(f"üîÑ Erro de cota detectado, tentando pr√≥xima chave...")
                handle_gemini_429_error(error_str, api_key)
                api_key = None  # For√ßar nova chave na pr√≥xima tentativa
                continue
            else:
                # Outros erros, n√£o tentar novamente
                print(f"üõë Erro n√£o relacionado √† cota, parando tentativas")
                break
                
        except Exception as e:
            error_str = str(e)
            last_error = error_str
            print(f"‚ùå Tentativa {attempt + 1} falhou com exce√ß√£o: {error_str}")
            
            # Se √© erro 429 (quota exceeded), tentar pr√≥xima chave
            if "429" in error_str or "quota" in error_str.lower() or "exceeded" in error_str.lower():
                print(f"üîÑ Erro de cota detectado, tentando pr√≥xima chave...")
                handle_gemini_429_error(error_str, api_key)
                api_key = None  # For√ßar nova chave na pr√≥xima tentativa
                continue
            else:
                # Outros erros, n√£o tentar novamente
                print(f"üõë Erro n√£o relacionado √† cota, parando tentativas")
                break
    
    # Se chegou aqui, todas as tentativas falharam
    final_error = f'Todas as {max_key_attempts} chaves Gemini falharam. √öltimo erro: {last_error}'
    return {
        'success': False,
        'error': final_error
    }

# ================================
# üé§ TEXT-TO-SPEECH
# ================================

@automations_bp.route('/generate-tts', methods=['POST'])
def generate_tts_gemini():
    """Gerar √°udio TTS usando Gemini 2.5"""
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        api_key = data.get('api_key', '').strip()
        voice_name = data.get('voice_name', 'Kore')
        model = data.get('model', 'gemini-2.5-flash-preview-tts')

        if not text:
            return jsonify({
                'success': False,
                'error': 'Texto √© obrigat√≥rio'
            }), 400

        if not GOOGLE_GENAI_TTS_AVAILABLE:
            return jsonify({
                'success': False,
                'error': 'Biblioteca google-genai n√£o instalada'
            }), 400

        # Par√¢metros adicionais para Gemini TTS
        speed = data.get('speed', 1.0)
        pitch = data.get('pitch', 0.0)
        volume_gain_db = data.get('volume_gain_db', 0.0)

        # Criar job ID para controle
        global TTS_JOB_COUNTER
        TTS_JOB_COUNTER += 1
        job_id = f"tts_{TTS_JOB_COUNTER}"

        # Registrar job
        TTS_JOBS[job_id] = {
            'status': 'running',
            'text': text[:50] + '...' if len(text) > 50 else text,
            'start_time': time.time(),
            'cancelled': False
        }

        add_real_time_log(f"üéµ Iniciando TTS Job {job_id} - {len(text)} chars", "info", "tts-gemini")

        # Tentar m√∫ltiplas chaves se necess√°rio
        # Usar a quantidade real de chaves dispon√≠veis
        max_key_attempts = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
        print(f"üîë Usando {max_key_attempts} chaves Gemini para TTS")
        last_error = None

        for attempt in range(max_key_attempts):
            # Verificar se job foi cancelado
            if TTS_JOBS.get(job_id, {}).get('cancelled', False):
                add_real_time_log(f"üõë TTS Job {job_id} cancelado pelo usu√°rio", "warning", "tts-gemini")
                TTS_JOBS[job_id]['status'] = 'cancelled'
                return jsonify({
                    'success': False,
                    'error': 'Gera√ß√£o cancelada pelo usu√°rio',
                    'job_id': job_id
                })

            # Se n√£o foi fornecida chave ou tentativa anterior falhou, usar rota√ß√£o
            if not api_key or attempt > 0:
                api_key = get_next_gemini_key()
                if not api_key:
                    TTS_JOBS[job_id]['status'] = 'failed'
                    return jsonify({
                        'success': False,
                        'error': 'Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.',
                        'job_id': job_id
                    }), 400
                print(f"üîÑ Tentativa {attempt + 1}: Usando rota√ß√£o de chaves Gemini")
                add_real_time_log(f"üîÑ Tentativa {attempt + 1}: Usando rota√ß√£o de chaves Gemini", "info", "tts-gemini")

            # Gerar √°udio TTS usando Gemini
            result = generate_tts_with_gemini(
                text, api_key, voice_name, model,
                speed=speed, pitch=pitch, volume_gain_db=volume_gain_db,
                job_id=job_id
            )

            # Verificar se foi bem-sucedido
            if result.get('success', False):
                TTS_JOBS[job_id]['status'] = 'completed'
                add_real_time_log(f"‚úÖ TTS Gemini gerado com sucesso - {len(text)} chars", "success", "tts-gemini")
                result['job_id'] = job_id
                return jsonify(result)

            # Se falhou, verificar o erro
            last_error = result.get('error', 'Erro desconhecido')
            print(f"‚ùå Tentativa {attempt + 1} falhou: {last_error}")
            add_real_time_log(f"‚ùå Tentativa {attempt + 1} falhou: {last_error}", "error", "tts-gemini")

            # Se √© erro 429 (quota exceeded), tentar pr√≥xima chave
            if "429" in last_error or "quota" in last_error.lower() or "exceeded" in last_error.lower():
                print(f"üîÑ Erro de cota detectado, tentando pr√≥xima chave...")
                add_real_time_log(f"üîÑ Erro de cota detectado, tentando pr√≥xima chave...", "warning", "tts-gemini")
                api_key = None  # For√ßar nova chave na pr√≥xima tentativa
                continue
            else:
                # Outros erros, n√£o tentar novamente
                print(f"üõë Erro n√£o relacionado √† cota, parando tentativas")
                break

        # Se chegou aqui, todas as tentativas falharam
        TTS_JOBS[job_id]['status'] = 'failed'
        final_error = f'Todas as {max_key_attempts} chaves Gemini falharam. √öltimo erro: {last_error}'
        add_real_time_log(f"‚ùå {final_error}", "error", "tts-gemini")
        return jsonify({
            'success': False,
            'error': final_error,
            'job_id': job_id
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@automations_bp.route('/generate-tts-kokoro', methods=['POST'])
def generate_tts_kokoro():
    """Gerar √°udio TTS usando Kokoro FastAPI"""
    try:
        data = request.get_json()
        text = data.get('text', '')
        voice_name = data.get('voice', 'af_bella')
        kokoro_url = data.get('kokoro_url', 'http://localhost:8880')
        speed = data.get('speed', 1.0)
        language = data.get('language', 'en')

        if not text:
            return jsonify({
                'success': False,
                'error': 'Texto √© obrigat√≥rio'
            }), 400

        # Criar job ID para controle
        global TTS_JOB_COUNTER
        TTS_JOB_COUNTER += 1
        job_id = f"kokoro_{TTS_JOB_COUNTER}"

        # Registrar job
        TTS_JOBS[job_id] = {
            'status': 'running',
            'text': text[:50] + '...' if len(text) > 50 else text,
            'start_time': time.time(),
            'cancelled': False
        }

        add_real_time_log(f"üéµ Iniciando Kokoro TTS Job {job_id} - {len(text)} chars", "info", "tts-kokoro")

        try:
            # Gerar √°udio TTS usando Kokoro
            result = generate_tts_with_kokoro(
                text, kokoro_url=kokoro_url, voice_name=voice_name,
                speed=speed, language=language, job_id=job_id
            )

            # Verificar se foi bem-sucedido
            if result.get('success', False):
                TTS_JOBS[job_id]['status'] = 'completed'
                add_real_time_log(f"‚úÖ Kokoro TTS gerado com sucesso - {len(text)} chars", "success", "tts-kokoro")
                result['job_id'] = job_id
                return jsonify(result)
            else:
                TTS_JOBS[job_id]['status'] = 'failed'
                return jsonify(result)

        except Exception as e:
            error_msg = str(e)
            
            # Verificar se √© um erro de √°udio inv√°lido (zeros) - usar fallback
            if "zeros" in error_msg.lower() or "fallback necess√°rio" in error_msg:
                add_real_time_log(f"‚ö†Ô∏è Kokoro falhou com √°udio inv√°lido - tentando fallback Gemini", "warning", "tts-kokoro")
                
                try:
                    # Tentar fallback com Gemini TTS
                    gemini_result = generate_tts_with_gemini(
                        text, voice_name='Aoede', job_id=job_id
                    )
                    
                    if gemini_result.get('success', False):
                        TTS_JOBS[job_id]['status'] = 'completed'
                        add_real_time_log(f"‚úÖ Fallback Gemini TTS bem-sucedido - {len(text)} chars", "success", "tts-fallback")
                        gemini_result['job_id'] = job_id
                        gemini_result['fallback_used'] = 'gemini'
                        gemini_result['original_provider'] = 'kokoro'
                        return jsonify(gemini_result)
                    else:
                        TTS_JOBS[job_id]['status'] = 'failed'
                        fallback_error = f'Kokoro falhou e fallback Gemini tamb√©m falhou: {gemini_result.get("error", "Erro desconhecido")}'
                        add_real_time_log(f"‚ùå {fallback_error}", "error", "tts-fallback")
                        return jsonify({
                            'success': False,
                            'error': fallback_error,
                            'job_id': job_id
                        })
                        
                except Exception as fallback_error:
                    TTS_JOBS[job_id]['status'] = 'failed'
                    final_error = f'Kokoro falhou e erro no fallback Gemini: {str(fallback_error)}'
                    add_real_time_log(f"‚ùå {final_error}", "error", "tts-fallback")
                    return jsonify({
                        'success': False,
                        'error': final_error,
                        'job_id': job_id
                    })
            else:
                # Erro normal do Kokoro (n√£o relacionado a √°udio inv√°lido)
                TTS_JOBS[job_id]['status'] = 'failed'
                error_msg = f'Erro ao gerar √°udio com Kokoro: {error_msg}'
                add_real_time_log(f"‚ùå {error_msg}", "error", "tts-kokoro")
                return jsonify({
                    'success': False,
                    'error': error_msg,
                    'job_id': job_id
                })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@automations_bp.route('/test-kokoro', methods=['POST'])
def test_kokoro():
    """Testar conex√£o com API Kokoro"""
    try:
        data = request.get_json()
        kokoro_url = data.get('kokoro_url', 'http://localhost:8880')

        # Testar endpoint de vozes
        voices_url = f"{kokoro_url}/v1/audio/voices"

        print(f"üîç Testando conex√£o Kokoro: {voices_url}")
        add_real_time_log(f"üîç Testando conex√£o Kokoro: {kokoro_url}", "info", "kokoro-test")

        response = requests.get(voices_url, timeout=10)

        if response.status_code == 200:
            voices_data = response.json()
            voices = voices_data.get('voices', [])

            add_real_time_log(f"‚úÖ Kokoro conectado com sucesso - {len(voices)} vozes dispon√≠veis", "success", "kokoro-test")

            return jsonify({
                'success': True,
                'message': f'Conex√£o com Kokoro estabelecida com sucesso',
                'url': kokoro_url,
                'voices_count': len(voices),
                'voices': voices[:10]  # Mostrar apenas as primeiras 10 vozes
            })
        else:
            error_msg = f"Erro ao conectar com Kokoro: {response.status_code} - {response.text}"
            add_real_time_log(f"‚ùå {error_msg}", "error", "kokoro-test")
            return jsonify({
                'success': False,
                'error': error_msg
            })

    except requests.exceptions.ConnectionError:
        error_msg = f"N√£o foi poss√≠vel conectar com Kokoro em {kokoro_url}. Verifique se o servidor est√° rodando."
        add_real_time_log(f"‚ùå {error_msg}", "error", "kokoro-test")
        return jsonify({
            'success': False,
            'error': error_msg
        })
    except Exception as e:
        error_msg = f"Erro ao testar Kokoro: {str(e)}"
        add_real_time_log(f"‚ùå {error_msg}", "error", "kokoro-test")
        return jsonify({
            'success': False,
            'error': error_msg
        })

@automations_bp.route('/generate-tts-elevenlabs', methods=['POST'])
def generate_tts_elevenlabs():
    """Gerar √°udio TTS usando ElevenLabs"""
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        api_key = data.get('api_key', '').strip()
        voice_id = data.get('voice_id', 'default')
        model_id = data.get('model_id', 'eleven_monolingual_v1')

        if not text:
            return jsonify({
                'success': False,
                'error': 'Texto √© obrigat√≥rio'
            }), 400

        if not api_key:
            return jsonify({
                'success': False,
                'error': 'Chave da API ElevenLabs √© obrigat√≥ria'
            }), 400

        # Par√¢metros adicionais para ElevenLabs
        stability = data.get('stability', 0.5)
        similarity_boost = data.get('similarity_boost', 0.5)
        style = data.get('style', 0.0)
        use_speaker_boost = data.get('use_speaker_boost', True)

        # Gerar √°udio TTS usando ElevenLabs
        result = generate_tts_with_elevenlabs(
            text, api_key, voice_id, model_id,
            stability=stability, similarity_boost=similarity_boost,
            style=style, use_speaker_boost=use_speaker_boost
        )
        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

# Fun√ß√£o removida - duplicada mais abaixo

@automations_bp.route('/download/<filename>')
def download_audio(filename):
    """Download de arquivos de √°udio gerados"""
    try:
        import os
        from flask import send_file

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        filepath = os.path.join(temp_dir, filename)

        if not os.path.exists(filepath):
            return jsonify({
                'success': False,
                'error': 'Arquivo n√£o encontrado'
            }), 404

        return send_file(filepath, as_attachment=True, download_name=filename)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro no download: {str(e)}'
        }), 500

@automations_bp.route('/join-audio', methods=['POST'])
def join_audio_segments():
    """Juntar m√∫ltiplos segmentos de √°udio em um arquivo √∫nico"""
    try:
        data = request.get_json()
        segments = data.get('segments', [])

        if not segments:
            return jsonify({
                'success': False,
                'error': 'Nenhum segmento fornecido'
            }), 400

        # Juntar √°udios usando a fun√ß√£o auxiliar
        result = join_audio_files(segments)
        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

# ================================
# üìä LOGS DE AUTOMA√á√ïES
# ================================

@automations_bp.route('/logs', methods=['GET'])
def get_automation_logs():
    """Obter logs de automa√ß√µes"""
    try:
        from app import AutomationLog
        
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        automation_type = request.args.get('type', None)
        
        query = AutomationLog.query
        
        if automation_type:
            query = query.filter_by(automation_type=automation_type)
        
        logs = query.order_by(AutomationLog.created_at.desc()).paginate(
            page=page, per_page=per_page, error_out=False
        )
        
        return jsonify({
            'success': True,
            'data': {
                'logs': [log.to_dict() for log in logs.items],
                'total': logs.total,
                'pages': logs.pages,
                'current_page': page,
                'per_page': per_page
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ================================
# üõ†Ô∏è FUN√á√ïES AUXILIARES
# ================================

def convert_to_youtube_url(input_str):
    """Converter nome do canal ou URL incompleta para URL completa do YouTube"""
    import re
    
    input_str = input_str.strip()
    print(f"üîç DEBUG: Convertendo entrada: '{input_str}'")
    
    # Se j√° √© uma URL completa do YouTube, retornar como est√°
    if input_str.startswith(('https://www.youtube.com/', 'https://youtube.com/', 'http://www.youtube.com/', 'http://youtube.com/')):
        print(f"‚úÖ URL completa detectada: {input_str}")
        return input_str
    
    # Se √© um ID de canal (UC...)
    if input_str.startswith('UC') and len(input_str) == 24:
        url = f"https://www.youtube.com/channel/{input_str}"
        print(f"üÜî ID do canal convertido para: {url}")
        return url
    
    # Se cont√©m apenas o nome do canal (ex: 'MrBeast', '@MrBeast')
    # Remover @ se presente
    channel_name = input_str.lstrip('@')
    
    # Verificar se √© um nome de canal v√°lido (apenas letras, n√∫meros, underscore, h√≠fen)
    if re.match(r'^[a-zA-Z0-9_-]+$', channel_name):
        # Tentar formato @username primeiro (mais moderno)
        url = f"https://www.youtube.com/@{channel_name}"
        print(f"üì∫ Nome do canal convertido para: {url}")
        return url
    
    # Se n√£o conseguiu processar, tentar como est√°
    print(f"‚ö†Ô∏è N√£o foi poss√≠vel processar '{input_str}', usando como est√°")
    return input_str

def get_channel_id_from_handle(handle, api_key):
    """Converter handle (@MrBeast) em channel ID usando YouTube API"""
    try:
        from googleapiclient.discovery import build
        
        # Remover @ se presente
        handle = handle.lstrip('@')
        
        # Construir servi√ßo YouTube API
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        # Buscar canal por handle
        search_response = youtube.search().list(
            q=handle,
            type='channel',
            part='id,snippet',
            maxResults=5
        ).execute()
        
        # Procurar canal que corresponde exatamente ao handle
        for item in search_response.get('items', []):
            channel_title = item['snippet']['title'].lower()
            if handle.lower() in channel_title or channel_title in handle.lower():
                return item['id']['channelId']
        
        # Se n√£o encontrou correspond√™ncia exata, tentar o primeiro resultado
        if search_response.get('items'):
            return search_response['items'][0]['id']['channelId']
            
        return None
        
    except Exception as e:
        print(f"‚ùå Erro ao buscar channel ID para handle {handle}: {e}")
        return None

def extract_channel_id_from_url(url, api_key=None):
    """Extrair ID do canal da URL do YouTube"""
    import re

    # Se j√° for um ID de canal
    if url.startswith('UC') and len(url) == 24:
        return url

    # Padr√£o para URL com ID do canal
    channel_id_pattern = r'youtube\.com/channel/(UC[a-zA-Z0-9_-]{22})'
    match = re.search(channel_id_pattern, url)
    if match:
        return match.group(1)

    # Para handles (@handle), tentar converter usando RapidAPI
    if api_key:
        # Extrair handle da URL ou usar diretamente
        handle_patterns = [
            r'youtube\.com/@([^/?&\s]+)',
            r'^@([^/?&\s]+)$',
            r'^([^/?&\s@]+)$'  # Nome simples como 'MrBeast'
        ]
        
        for pattern in handle_patterns:
            match = re.search(pattern, url)
            if match:
                handle = match.group(1)
                print(f"üîç Tentando converter handle '{handle}' em channel ID usando RapidAPI...")
                # Usar RapidAPI para converter handle em channel ID
                result = get_channel_id_rapidapi(handle, api_key)
                if result and result.get('success'):
                    channel_id = result['data']['channel_id']
                    print(f"‚úÖ Handle '{handle}' convertido para channel ID: {channel_id}")
                    return channel_id
                else:
                    print(f"‚ùå Erro ao converter handle '{handle}': {result.get('error', 'Erro desconhecido')}")
                break
    
    # Se n√£o conseguiu converter, retornar None
    print(f"‚ùå N√£o foi poss√≠vel extrair channel ID de: {url}")
    return None

def extract_channel_name_or_id(input_str):
    """Extrair nome ou ID do canal de URL do YouTube"""
    input_str = input_str.strip()
    print(f"üîç DEBUG: Processando entrada: '{input_str}'")

    if input_str.startswith('UC') and len(input_str) == 24:
        print(f"üîç DEBUG: ID do canal detectado: {input_str}")
        return input_str

    patterns = [
        r'youtube\.com/@([^/?&\s]+)',
        r'youtube\.com/c/([^/?&\s]+)',
        r'youtube\.com/channel/([^/?&\s]+)',
        r'youtube\.com/user/([^/?&\s]+)',
        r'^@([^/?&\s]+)$',
        r'^([^/?&\s@]+)$'
    ]

    for pattern in patterns:
        match = re.search(pattern, input_str)
        if match:
            extracted = match.group(1)
            print(f"üîç DEBUG: Padr√£o '{pattern}' encontrou: '{extracted}'")
            if extracted.startswith('UC') and len(extracted) == 24:
                print(f"üîç DEBUG: ID do canal v√°lido: {extracted}")
                return extracted
            print(f"üîç DEBUG: Nome/handle do canal: {extracted}")
            return extracted

    print(f"üîç DEBUG: Nenhum padr√£o encontrado para: {input_str}")
    return None

def get_channel_id_rapidapi(channel_name, api_key):
    """Obter ID do canal usando RapidAPI YouTube V2 com rota√ß√£o de chaves e cache"""
    try:
        # Verificar cache primeiro
        cache_params = {'channel_name': channel_name}
        cached_result = get_from_cache('channel_id', cache_params, custom_ttl=3600, cache_subdir='channel_id')  # Cache por 1 hora
        if cached_result:
            return cached_result
        
        # Limpar cache expirado
        clear_expired_cache()
        
        url = "https://youtube-v2.p.rapidapi.com/channel/id"

        # Carregar chaves RapidAPI para rota√ß√£o
        load_rapidapi_keys()
        
        # Usar chave fornecida ou obter da rota√ß√£o
        print(f"üîë SELE√á√ÉO: Determinando qual chave usar...")
        current_api_key = api_key
        if not current_api_key or len(RAPIDAPI_KEYS_ROTATION['keys']) > 1:
            print(f"üîÑ ROTA√á√ÉO: Obtendo pr√≥xima chave da rota√ß√£o")
            rotation_key = get_next_rapidapi_key()
            if rotation_key:
                current_api_key = rotation_key
                print(f"‚úÖ ROTA√á√ÉO: Usando chave da rota√ß√£o: {current_api_key[:20]}...")
            else:
                print(f"‚ùå ROTA√á√ÉO: Nenhuma chave dispon√≠vel na rota√ß√£o")
        else:
            print(f"‚úÖ FORNECIDA: Usando chave fornecida: {current_api_key[:20]}...")
        
        if not current_api_key:
            print(f"‚ùå ERRO: Nenhuma chave API dispon√≠vel")
            return {
                'success': False,
                'error': 'Nenhuma chave RapidAPI dispon√≠vel'
            }

        headers = {
            "X-RapidAPI-Key": current_api_key,
            "X-RapidAPI-Host": "youtube-v2.p.rapidapi.com"
        }

        params = {"channel_name": channel_name}

        print(f"üîç DEBUG: Buscando ID do canal para: {channel_name}")
        print(f"üîç DEBUG: URL: {url}")
        print(f"üîç DEBUG: Params: {params}")

        # Retry otimizado com delays m√≠nimos
        max_retries = 2  # M√°ximo 2 tentativas
        base_delay = 1   # Delay m√≠nimo: 1 segundo
        
        for attempt in range(max_retries):
            try:
                # Aplicar throttling inteligente antes da requisi√ß√£o
                apply_rapidapi_throttle()
                
                # Adicionar delay entre tentativas para evitar rate limiting
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # Backoff mais conservador (2x)
                    print(f"‚è≥ Aguardando {delay}s antes da tentativa {attempt + 1}...")
                    time.sleep(delay)
                    
                response = requests.get(url, headers=headers, params=params, timeout=30)
                print(f"üîç DEBUG: Status da resposta: {response.status_code}")
                
                # Verificar se √© erro 429 (Too Many Requests)
                if response.status_code == 429:
                    # Aplicar tratamento de rate limiting
                    handle_rapidapi_429()
                    
                    # Verificar se a resposta cont√©m informa√ß√£o sobre quota excedida
                    try:
                        error_data = response.json()
                        if 'quota' in str(error_data).lower() or 'monthly' in str(error_data).lower():
                            print(f"üìä Quota mensal excedida para chave: {current_api_key[:20]}...")
                            mark_rapidapi_key_failed(current_api_key)
                            
                            # Tentar obter nova chave da rota√ß√£o
                            new_key = get_next_rapidapi_key()
                            if new_key and new_key != current_api_key:
                                current_api_key = new_key
                                headers["X-RapidAPI-Key"] = current_api_key
                                print(f"üîÑ Tentando com nova chave: {current_api_key[:20]}...")
                                continue
                    except:
                        pass
                    
                    if attempt == max_retries - 1:
                        return {
                            'success': False,
                            'error': 'Limite de requisi√ß√µes excedido (429). Tente novamente em alguns minutos.'
                        }
                    print(f"‚ö†Ô∏è Rate limit atingido (429), tentando novamente...")
                    continue
                    
                # Verificar se √© erro 403 (Forbidden) - chave inv√°lida
                elif response.status_code == 403:
                    print(f"üö´ Chave RapidAPI inv√°lida ou sem permiss√µes: {current_api_key[:20]}...")
                    mark_rapidapi_key_failed(current_api_key)
                    
                    # Tentar obter nova chave da rota√ß√£o
                    new_key = get_next_rapidapi_key()
                    if new_key and new_key != current_api_key:
                        current_api_key = new_key
                        headers["X-RapidAPI-Key"] = current_api_key
                        print(f"üîÑ Tentando com nova chave ap√≥s 403: {current_api_key[:20]}...")
                        continue
                    else:
                        return {
                            'success': False,
                            'error': 'Todas as chaves RapidAPI est√£o inv√°lidas ou sem permiss√µes. Verifique suas chaves na configura√ß√£o.'
                        }
                    
                # Se chegou aqui com status 200, sair do loop
                if response.status_code == 200:
                    break
                    
            except requests.exceptions.Timeout:
                if attempt == max_retries - 1:  # √öltima tentativa
                    raise
                print(f"üîÑ Tentativa {attempt + 1} falhou (timeout), tentando novamente...")
                continue

        if response.status_code != 200:
            print(f"üîç DEBUG: Erro na resposta: {response.text}")
            
            # Tratamento espec√≠fico para diferentes c√≥digos de erro
            if response.status_code == 429:
                error_msg = 'Limite de requisi√ß√µes excedido (100/m√™s ou 1000/hora). Aguarde alguns minutos e tente novamente.'
            elif response.status_code == 401:
                error_msg = 'Chave de API inv√°lida ou expirada. Verifique suas chaves RapidAPI.'
            elif response.status_code == 403:
                error_msg = 'Chave RapidAPI inv√°lida ou sem permiss√µes. Todas as chaves configuradas est√£o com problema. Verifique suas chaves na configura√ß√£o.'
            elif response.status_code == 404:
                error_msg = 'Canal n√£o encontrado. Verifique o nome do canal.'
            else:
                error_msg = f'Erro na API RapidAPI: {response.status_code} - {response.text}'
                
            return {
                'success': False,
                'error': error_msg
            }

        data = response.json()
        print(f"üîç DEBUG: Resposta da API: {data}")

        if 'channel_id' not in data:
            return {
                'success': False,
                'error': 'Canal n√£o encontrado'
            }

        result = {
            'success': True,
            'data': {
                'channel_id': data['channel_id'],
                'channel_name': data.get('channel_name', channel_name)
            }
        }
        
        # Salvar no cache
        save_to_cache('channel_id', cache_params, result, custom_ttl=3600, cache_subdir='channel_id')
        
        return result

    except Exception as e:
        return {
            'success': False,
            'error': f'Erro ao buscar ID do canal: {str(e)}'
        }

def get_channel_details_rapidapi(channel_id, api_key):
    """Obter detalhes do canal usando RapidAPI YouTube V2 com rate limiting, rota√ß√£o de chaves e cache"""
    import time
    
    try:
        # Verificar cache primeiro
        cache_params = {'channel_id': channel_id}
        cached_result = get_from_cache('channel_details', cache_params, custom_ttl=1800, cache_subdir='channel_details')  # Cache por 30 minutos
        if cached_result:
            return cached_result
        
        # Limpar cache expirado
        clear_expired_cache()
        
        url = "https://youtube-v2.p.rapidapi.com/channel/details"

        # Carregar chaves RapidAPI para rota√ß√£o
        load_rapidapi_keys()
        
        # Usar chave fornecida ou obter da rota√ß√£o
        current_api_key = api_key
        if not current_api_key or len(RAPIDAPI_KEYS_ROTATION['keys']) > 1:
            rotation_key = get_next_rapidapi_key()
            if rotation_key:
                current_api_key = rotation_key
                print(f"üîÑ Usando chave da rota√ß√£o: {current_api_key[:20]}...")

        headers = {
            "X-RapidAPI-Key": current_api_key,
            "X-RapidAPI-Host": "youtube-v2.p.rapidapi.com"
        }

        params = {"channel_id": channel_id}

        # Retry otimizado com delays m√≠nimos
        max_retries = 2  # M√°ximo 2 tentativas
        base_delay = 1   # Delay m√≠nimo: 1 segundo
        
        for attempt in range(max_retries):
            # Aplicar throttling inteligente antes da requisi√ß√£o
            apply_rapidapi_throttle()
            
            if attempt > 0:
                delay = base_delay * (2 ** (attempt - 1))  # Backoff mais conservador (2x)
                print(f"‚è≥ Aguardando {delay}s antes da tentativa {attempt + 1}...")
                time.sleep(delay)
                
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code == 429:
                # Aplicar tratamento de rate limiting
                handle_rapidapi_429()
                # Verificar se a resposta cont√©m informa√ß√£o sobre quota excedida
                try:
                    error_data = response.json()
                    if 'quota' in str(error_data).lower() or 'monthly' in str(error_data).lower():
                        print(f"üìä Quota mensal excedida para chave: {current_api_key[:20]}...")
                        mark_rapidapi_key_failed(current_api_key)
                        
                        # Tentar obter nova chave da rota√ß√£o
                        new_key = get_next_rapidapi_key()
                        if new_key and new_key != current_api_key:
                            current_api_key = new_key
                            headers["X-RapidAPI-Key"] = current_api_key
                            print(f"üîÑ Tentando com nova chave: {current_api_key[:20]}...")
                            continue
                except:
                    pass
                
                if attempt == max_retries - 1:
                    return {
                        'success': False,
                        'error': 'Limite de requisi√ß√µes excedido (429). Tente novamente em alguns minutos.'
                    }
                print(f"‚ö†Ô∏è Rate limit atingido (429), tentando novamente...")
                continue
                
            # Verificar se √© erro 403 (Forbidden) - chave inv√°lida
            elif response.status_code == 403:
                print(f"üö´ Chave RapidAPI inv√°lida ou sem permiss√µes: {current_api_key[:20]}...")
                mark_rapidapi_key_failed(current_api_key)
                
                # Tentar obter nova chave da rota√ß√£o
                new_key = get_next_rapidapi_key()
                if new_key and new_key != current_api_key:
                    current_api_key = new_key
                    headers["X-RapidAPI-Key"] = current_api_key
                    print(f"üîÑ Tentando com nova chave ap√≥s 403: {current_api_key[:20]}...")
                    continue
                else:
                    return {
                        'success': False,
                        'error': 'Todas as chaves RapidAPI est√£o inv√°lidas ou sem permiss√µes. Verifique suas chaves na configura√ß√£o.'
                    }
            
            # Se chegou aqui com status 200, sair do loop
            if response.status_code == 200:
                # Resetar throttling ap√≥s sucesso
                reset_rapidapi_throttle_success()
                break

        if response.status_code != 200:
            if response.status_code == 429:
                error_msg = 'Limite de requisi√ß√µes excedido (100/m√™s ou 1000/hora). Aguarde alguns minutos e tente novamente.'
            elif response.status_code == 401:
                error_msg = 'Chave de API inv√°lida ou expirada. Verifique suas chaves RapidAPI.'
            elif response.status_code == 403:
                error_msg = 'Chave RapidAPI inv√°lida ou sem permiss√µes. Todas as chaves configuradas est√£o com problema. Verifique suas chaves na configura√ß√£o.'
            elif response.status_code == 404:
                error_msg = 'Canal n√£o encontrado. Verifique o ID do canal.'
            else:
                error_msg = f'Erro na API RapidAPI: {response.status_code}'
                
            return {
                'success': False,
                'error': error_msg
            }

        data = response.json()

        result = {
            'success': True,
            'data': {
                'title': data.get('title', ''),
                'description': data.get('description', ''),
                'subscriber_count': data.get('subscriber_count', 0),
                'video_count': data.get('video_count', 0)
            }
        }
        
        # Salvar no cache
        save_to_cache('channel_details', cache_params, result, custom_ttl=1800, cache_subdir='channel_details')
        
        return result

    except Exception as e:
        return {
            'success': False,
            'error': f'Erro ao buscar detalhes do canal: {str(e)}'
        }

def get_channel_videos_rapidapi(channel_id, api_key, max_results=50):
    """Obter v√≠deos do canal usando RapidAPI YouTube V2 - vers√£o simplificada"""
    import time
    import requests
    
    try:
        print(f"üöÄ IN√çCIO: get_channel_videos_rapidapi chamada com channel_id={channel_id}, max_results={max_results}")
        print(f"üîë API Key fornecida: {'Sim' if api_key else 'N√£o'} (length: {len(api_key) if api_key else 0})")
        
        # Verificar cache primeiro
        print(f"üíæ CACHE: Verificando cache para channel_id={channel_id}")
        cache_params = {
            'channel_id': channel_id,
            'max_results': min(max_results, 50)
        }
        cached_result = get_from_cache('channel_videos', cache_params, custom_ttl=600, cache_subdir='channel_videos')  # Cache por 10 minutos
        if cached_result:
            print(f"‚úÖ CACHE: Resultado encontrado no cache, retornando dados salvos")
            return cached_result
        
        print(f"‚ùå CACHE: Nenhum resultado no cache, prosseguindo com requisi√ß√£o √† API")
        
        # Limpar cache expirado
        print(f"üßπ CACHE: Limpando cache expirado")
        clear_expired_cache()
        
        # Usar chave fornecida ou obter da rota√ß√£o
        current_api_key = api_key
        if not current_api_key:
            load_rapidapi_keys()
            current_api_key = get_next_rapidapi_key()
        
        if not current_api_key:
            print(f"‚ùå ERRO: Nenhuma chave RapidAPI dispon√≠vel")
            return {
                'success': False,
                'error': 'Nenhuma chave RapidAPI dispon√≠vel'
            }
        
        print(f"üîë CHAVE: Usando chave: {current_api_key[:20]}...")
        
        # Fazer requisi√ß√£o HTTP direta (similar ao endpoint debug-extract-simple que funcionou)
        url = "https://youtube-v2.p.rapidapi.com/channel/videos"
        headers = {
            "X-RapidAPI-Key": current_api_key,
            "X-RapidAPI-Host": "youtube-v2.p.rapidapi.com"
        }
        params = {
            "channel_id": channel_id,
            "max_results": min(max_results, 50)
        }
        
        print(f"üì° REQUISI√á√ÉO: Fazendo requisi√ß√£o para {url}")
        print(f"üìã PAR√ÇMETROS: {params}")
        
        start_time = time.time()
        response = requests.get(url, headers=headers, params=params, timeout=30)
        elapsed_time = time.time() - start_time
        
        print(f"‚úÖ RESPOSTA: Requisi√ß√£o conclu√≠da em {elapsed_time:.2f}s")
        print(f"üìä STATUS: {response.status_code}")
        print(f"üìè TAMANHO: {len(response.content)} bytes")
        
        # Verificar se a resposta foi bem-sucedida
        if response.status_code != 200:
            print(f"‚ùå ERRO: Status {response.status_code}: {response.text[:200]}")
            return {
                'success': False,
                'error': f'Erro na API RapidAPI ({response.status_code}): {response.text[:200]}'
            }
        
        # Parse da resposta JSON
        print(f"üìÑ JSON: Iniciando parse da resposta JSON")
        try:
            data = response.json()
            print(f"‚úÖ JSON: Parse bem-sucedido")
            print(f"üìä JSON: Tamanho dos dados: {len(str(data))} caracteres")
            print(f"üîë JSON: Chaves principais: {list(data.keys()) if isinstance(data, dict) else 'N√£o √© dict'}")
        except Exception as e:
            print(f"‚ùå JSON: Falha no parse da resposta")
            print(f"‚ùå JSON: Erro: {str(e)}")
            print(f"‚ùå JSON: Tipo da resposta: {type(response.content)}")
            print(f"‚ùå JSON: Primeiros 200 chars: {response.text[:200]}")
            return {
                'success': False,
                'error': f'Falha ao processar resposta JSON: {str(e)}'
            }

        print(f"\nüîç VALIDA√á√ÉO: Verificando estrutura dos dados")
        if 'videos' not in data:
            print(f"‚ùå VALIDA√á√ÉO: Chave 'videos' n√£o encontrada")
            print(f"üîë VALIDA√á√ÉO: Chaves dispon√≠veis na resposta: {list(data.keys())}")
            # Verificar se h√° erro na resposta da API
            if 'error' in data:
                print(f"‚ùå VALIDA√á√ÉO: Erro da API encontrado: {data['error']}")
                return {
                    'success': False,
                    'error': f'Erro da API RapidAPI: {data["error"]}'
                }
            print(f"‚ùå VALIDA√á√ÉO: Nenhum v√≠deo encontrado - estrutura inesperada")
            return {
                'success': False,
                'error': 'Nenhum v√≠deo encontrado no canal - verifique se o ID do canal est√° correto'
            }
        
        print(f"‚úÖ VALIDA√á√ÉO: Chave 'videos' encontrada")

        print(f"üîç DEBUG: Encontrados {len(data['videos'])} v√≠deos na resposta")
        print(f"‚úÖ PROGRESSO: {len(data['videos'])} v√≠deos encontrados, iniciando processamento...")

        # Processar dados dos v√≠deos
        videos = []
        for i, video in enumerate(data['videos']):
            if i < 3:  # Log apenas os primeiros 3 v√≠deos para debug
                print(f"üîç DEBUG: V√≠deo {i+1}: {video}")

            # A API RapidAPI retorna 'number_of_views' como inteiro
            processed_video = {
                'video_id': video.get('video_id', ''),
                'title': video.get('title', ''),
                'description': video.get('description', ''),
                'thumbnail': video.get('thumbnail', ''),
                'duration': video.get('video_length', ''),  # API usa 'video_length'
                'views': parse_view_count(video.get('number_of_views', 0)),  # API usa 'number_of_views'
                'likes': parse_count(video.get('likes', '0')),
                'published_at': video.get('published_time', ''),  # API usa 'published_time'
                'url': f"https://youtube.com/watch?v={video.get('video_id', '')}"
            }
            videos.append(processed_video)

            if i < 3:  # Log apenas os primeiros 3 v√≠deos processados
                print(f"üîç DEBUG: V√≠deo processado {i+1}: views={processed_video['views']}, title={processed_video['title'][:50]}...")

        result = {
            'success': True,
            'data': {
                'videos': videos,
                'total_videos': len(videos),
                'total_count': len(videos),
                'message': f'‚úÖ {len(videos)} t√≠tulos extra√≠dos com sucesso!'
            }
        }
        
        print(f"üéâ PROGRESSO: Processamento conclu√≠do com sucesso!")
        print(f"üìä PROGRESSO: Total de v√≠deos processados: {len(videos)}")
        
        # Salvar no cache para evitar chamadas futuras
        save_to_cache('channel_videos', cache_params, result, custom_ttl=600, cache_subdir='channel_videos')
        
        return result

    except Exception as e:
        print(f"‚ùå PROGRESSO: Erro durante busca de v√≠deos: {str(e)}")
        return {
            'success': False,
            'error': f'Erro ao buscar v√≠deos: {str(e)}'
        }

def filter_videos_by_config(videos, config):
    """Filtrar v√≠deos baseado na configura√ß√£o fornecida"""
    if not videos:
        print("üîç DEBUG: Nenhum v√≠deo para filtrar")
        return []

    print(f"üîç DEBUG: Iniciando filtros com {len(videos)} v√≠deos")
    filtered = videos.copy()

    # Filtro por views m√≠nimas
    min_views = config.get('min_views', 0)
    print(f"üîç DEBUG: Filtro min_views: {min_views}")
    if min_views > 0:
        before_count = len(filtered)
        filtered = [v for v in filtered if v.get('views', 0) >= min_views]
        print(f"üîç DEBUG: Ap√≥s filtro min_views: {before_count} -> {len(filtered)}")
        if len(filtered) > 0:
            print(f"üîç DEBUG: Exemplo de v√≠deo que passou: views={filtered[0].get('views', 0)}")

    # Filtro por views m√°ximas (s√≥ aplicar se for maior que 0)
    max_views = config.get('max_views', 0)
    if max_views is not None and max_views > 0:
        print(f"üîç DEBUG: Filtro max_views: {max_views}")
        before_count = len(filtered)
        filtered = [v for v in filtered if v.get('views', 0) <= max_views]
        print(f"üîç DEBUG: Ap√≥s filtro max_views: {before_count} -> {len(filtered)}")
    else:
        print(f"üîç DEBUG: Filtro max_views: {max_views} (ignorado - sem limite m√°ximo)")

    # Filtro por dias (DESABILITADO - API usa formato relativo como "20 hours ago")
    days_filter = config.get('days', 0)
    print(f"üîç DEBUG: Filtro de dias: {days_filter} (DESABILITADO)")
    print(f"üîç DEBUG: Ap√≥s filtro de dias: {len(filtered)} (todos mantidos)")

    # Limitar n√∫mero m√°ximo de t√≠tulos
    max_titles = config.get('max_titles', 50)
    if max_titles > 0:
        before_limit = len(filtered)
        filtered = filtered[:max_titles]
        print(f"üîç DEBUG: Limitando t√≠tulos: {before_limit} -> {len(filtered)} (max: {max_titles})")

    print(f"üîç DEBUG: RESULTADO FINAL: {len(filtered)} v√≠deos")
    if filtered:
        print(f"üîç DEBUG: Primeiro t√≠tulo: {filtered[0].get('title', 'N/A')}")
        print(f"üîç DEBUG: Primeiros 3 t√≠tulos:")
        for i, video in enumerate(filtered[:3]):
            print(f"üîç DEBUG: {i+1}. {video.get('title', 'N/A')} ({video.get('views', 0)} views)")
    else:
        print(f"üîç DEBUG: ‚ùå NENHUM V√çDEO NO RESULTADO FINAL!")

    return filtered

def parse_view_count(view_input):
    """Converter string ou n√∫mero de views para n√∫mero inteiro"""
    if not view_input:
        return 0

    # Se j√° for um n√∫mero inteiro, retornar diretamente
    if isinstance(view_input, int):
        return view_input

    # Se for float, converter para int
    if isinstance(view_input, float):
        return int(view_input)

    # Converter para string e processar
    view_str = str(view_input).lower().replace(',', '').replace('.', '')

    # Extrair apenas n√∫meros e multiplicadores
    import re
    match = re.search(r'([\d,\.]+)\s*([kmb]?)', view_str)
    if not match:
        return 0

    number_str, multiplier = match.groups()
    try:
        number = float(number_str.replace(',', ''))

        if multiplier == 'k':
            return int(number * 1000)
        elif multiplier == 'm':
            return int(number * 1000000)
        elif multiplier == 'b':
            return int(number * 1000000000)
        else:
            return int(number)
    except ValueError:
        return 0

def parse_count(count_str):
    """Converter string de contagem para n√∫mero"""
    if not count_str:
        return 0

    try:
        # Remover caracteres n√£o num√©ricos exceto pontos e v√≠rgulas
        clean_str = re.sub(r'[^\d,\.]', '', str(count_str))
        if clean_str:
            return int(float(clean_str.replace(',', '')))
    except ValueError:
        pass

    return 0

def get_channel_videos_youtube_api(channel_id, api_key, max_results=50):
    """Obter v√≠deos do canal usando YouTube Data API v3 oficial"""
    try:
        from googleapiclient.discovery import build
        from googleapiclient.errors import HttpError
        import isodate
        from datetime import datetime
        
        print(f"üöÄ IN√çCIO: get_channel_videos_youtube_api chamada com channel_id={channel_id}, max_results={max_results}")
        print(f"üîë API Key fornecida: {'Sim' if api_key else 'N√£o'} (length: {len(api_key) if api_key else 0})")
        
        if not api_key:
            return {
                'success': False,
                'error': 'Chave da YouTube API √© obrigat√≥ria'
            }
        
        # Verificar cache primeiro
        cache_params = {
            'channel_id': channel_id,
            'max_results': min(max_results, 50),
            'api_type': 'youtube_official'
        }
        cached_result = get_from_cache('channel_videos_youtube', cache_params, custom_ttl=600, cache_subdir='channel_videos_youtube')
        if cached_result:
            print(f"‚úÖ CACHE: Resultado encontrado no cache, retornando dados salvos")
            return cached_result
        
        # Construir servi√ßo da YouTube API
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        # Buscar v√≠deos do canal
        search_response = youtube.search().list(
            part='id,snippet',
            channelId=channel_id,
            type='video',
            order='date',
            maxResults=min(max_results, 50)
        ).execute()
        
        video_ids = [item['id']['videoId'] for item in search_response['items']]
        
        if not video_ids:
            return {
                'success': False,
                'error': 'Nenhum v√≠deo encontrado no canal'
            }
        
        # Obter estat√≠sticas detalhadas dos v√≠deos
        videos_response = youtube.videos().list(
            part='statistics,contentDetails,snippet',
            id=','.join(video_ids)
        ).execute()
        
        videos = []
        for video in videos_response['items']:
            # Converter dura√ß√£o ISO 8601 para formato leg√≠vel
            duration_iso = video['contentDetails']['duration']
            duration = isodate.parse_duration(duration_iso)
            duration_str = str(duration).replace('0:', '')
            
            # Processar dados do v√≠deo
            processed_video = {
                'video_id': video['id'],
                'title': video['snippet']['title'],
                'description': video['snippet']['description'][:500],  # Limitar descri√ß√£o
                'thumbnail': video['snippet']['thumbnails'].get('high', {}).get('url', ''),
                'duration': duration_str,
                'views': int(video['statistics'].get('viewCount', 0)),
                'likes': int(video['statistics'].get('likeCount', 0)),
                'published_at': video['snippet']['publishedAt'],
                'url': f"https://youtube.com/watch?v={video['id']}"
            }
            videos.append(processed_video)
        
        result = {
            'success': True,
            'data': {
                'videos': videos,
                'total_videos': len(videos),
                'total_count': len(videos),
                'message': f'‚úÖ {len(videos)} t√≠tulos extra√≠dos com sucesso via YouTube API oficial!'
            }
        }
        
        # Salvar no cache
        save_to_cache('channel_videos_youtube', cache_params, result, custom_ttl=600, cache_subdir='channel_videos_youtube')
        
        print(f"üéâ PROGRESSO: YouTube API - {len(videos)} v√≠deos processados com sucesso!")
        return result
        
    except HttpError as e:
        error_msg = f'Erro da YouTube API: {str(e)}'
        print(f"‚ùå ERRO YouTube API: {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }
    except Exception as e:
        error_msg = f'Erro ao buscar v√≠deos via YouTube API: {str(e)}'
        print(f"‚ùå ERRO: {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

def get_channel_videos_ytdlp(channel_url, max_results=50):
    """Obter v√≠deos do canal usando yt-dlp"""
    try:
        import yt_dlp
        
        print(f"üöÄ IN√çCIO: get_channel_videos_ytdlp chamada com channel_url={channel_url}, max_results={max_results}")
        
        # Converter nome do canal para URL completa se necess√°rio
        processed_url = convert_to_youtube_url(channel_url)
        print(f"üîó URL processada: {processed_url}")
        
        # Verificar cache primeiro
        cache_params = {
            'channel_url': processed_url,
            'max_results': min(max_results, 50),
            'api_type': 'ytdlp'
        }
        cached_result = get_from_cache('channel_videos_ytdlp', cache_params, custom_ttl=600, cache_subdir='channel_videos_ytdlp')
        if cached_result:
            print(f"‚úÖ CACHE: Resultado encontrado no cache, retornando dados salvos")
            return cached_result
        
        # Configurar yt-dlp para extrair v√≠deos do canal
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': 'in_playlist',  # Extrair metadados da playlist diretamente
            'playlistend': min(max_results, 50),
            'ignoreerrors': True,
            'socket_timeout': 20,
            'retries': 1,
        }
        
        # Garantir que estamos acessando a p√°gina de v√≠deos do canal
        if processed_url.startswith('https://www.youtube.com/@'):
            # Se j√° √© um handle, adicionar /videos
            if not processed_url.endswith('/videos'):
                processed_url = f"{processed_url}/videos"
        elif processed_url.startswith('@'):
            # Converter handle para URL completa
            channel_name = processed_url.lstrip('@')
            processed_url = f"https://www.youtube.com/@{channel_name}/videos"
        elif 'youtube.com/channel/' in processed_url:
            # Se √© channel ID, adicionar /videos
            if not processed_url.endswith('/videos'):
                processed_url = f"{processed_url}/videos"
        
        possible_urls = [processed_url]
        print(f"üîç DEBUG: URL final para extra√ß√£o: {processed_url}")
        
        # Extrair informa√ß√µes do canal
        print(f"üîç DEBUG: Criando inst√¢ncia YoutubeDL com opts: {ydl_opts}")
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            channel_info = None
            last_error = None
            
            for i, url in enumerate(possible_urls):
                try:
                    print(f"üîÑ Tentando URL {i+1}/{len(possible_urls)}: {url}")
                    print(f"üîç DEBUG: Iniciando extract_info para {url}...")
                    
                    # Usar timeout manual com threading
                    import threading
                    import time
                    
                    try:
                        print(f"üîç DEBUG: Iniciando extract_info diretamente para {url}")
                        channel_info = ydl.extract_info(url, download=False)
                        print(f"üîç DEBUG: extract_info conclu√≠do com sucesso")
                    except Exception as e:
                        print(f"‚ùå Erro em extract_info: {str(e)}")
                        last_error = str(e)
                        continue
                    
                    # Handle channel redirect to playlist
                    if channel_info and channel_info.get('_type') == 'url':
                        playlist_url = channel_info['url']
                        print(f"üîÑ Detectado redirecionamento para playlist: {playlist_url}")
                        try:
                            channel_info = ydl.extract_info(playlist_url, download=False)
                            print(f"üîç DEBUG: extract_info da playlist conclu√≠do com sucesso")
                        except Exception as e:
                            print(f"‚ùå Erro ao extrair playlist: {str(e)}")
                            last_error = str(e)
                            continue
                    
                    if channel_info and 'entries' in channel_info:
                        print(f"‚úÖ Sucesso com URL: {url}")
                        break
                    else:
                        print(f"‚ö†Ô∏è URL {url} n√£o retornou entries v√°lidas")
                        
                except Exception as e:
                    last_error = str(e)
                    print(f"‚ùå Tentativa falhou para URL {url}: {last_error}")
                    continue
            
            if channel_info:
                print(f"DEBUG: Channel info type: {channel_info.get('_type')}")
                print(f"DEBUG: Keys in channel_info: {list(channel_info.keys())}")
                print(f"DEBUG: Has entries: {'entries' in channel_info}")
                print(f"DEBUG: Number of entries: {len(channel_info.get('entries', []))}")
            if not channel_info or 'entries' not in channel_info:
                error_msg = f'N√£o foi poss√≠vel extrair informa√ß√µes do canal. √öltimo erro: {last_error}'
                print(f"‚ùå ERRO: {error_msg}")
                return {
                    'success': False,
                    'error': error_msg
                }
            
            videos = []
            entries_list = list(channel_info['entries'])[:max_results]
            print(f"üìä Processando {len(entries_list)} entradas...")
            
            for i, entry in enumerate(entries_list):
                if not entry:  # Pular entradas vazias
                    print(f"  ‚ö†Ô∏è Entrada {i+1} vazia, pulando...")
                    continue
                
                try:
                    print(f"  üîÑ Processando entrada {i+1}/{len(entries_list)}...")
                    print(f"  üîç DEBUG: Dados da entrada: {entry}")
                    
                    # Com extract_flat=True, os dados v√™m em formato diferente
                    title = entry.get('title', '') if entry.get('title') else ''
                    video_id = entry.get('id', '')
                    
                    # Para extract_flat, precisamos extrair informa√ß√µes adicionais se necess√°rio
                    if not title and entry.get('url'):
                        # Se n√£o temos t√≠tulo, tentar extrair da URL
                        title = f"V√≠deo {video_id}"
                    
                    processed_video = {
                        'video_id': video_id,
                        'title': title,
                        'description': entry.get('description', '')[:500] if entry.get('description') else '',
                        'thumbnail': entry.get('thumbnail', ''),
                        'duration': str(entry.get('duration', 0)) + 's' if entry.get('duration') else '',
                        'views': entry.get('view_count', 0) or 0,
                        'likes': entry.get('like_count', 0) or 0,
                        'published_at': entry.get('upload_date', ''),
                        'url': entry.get('url', f"https://youtube.com/watch?v={video_id}")
                    }
                    
                    videos.append(processed_video)
                    print(f"  ‚úÖ Entrada {i+1} processada: {title[:50]}...")
                    
                except Exception as e:
                    print(f"  ‚ùå Erro na entrada {i+1}: {str(e)[:100]}...")
                    continue
            
            # Extrair informa√ß√µes do canal
            channel_info = {
                'name': channel_info.get('uploader', channel_info.get('channel', '')),
                'description': channel_info.get('description', ''),
                'subscriber_count': channel_info.get('subscriber_count') or channel_info.get('channel_follower_count', 0),
                'video_count': channel_info.get('playlist_count') or channel_info.get('n_entries', len(videos))
            }
            
            result = {
                'success': True,
                'data': {
                    'channel_info': channel_info,
                    'videos': videos,
                    'total_videos': len(videos),
                    'total_count': len(videos),
                    'message': f'‚úÖ {len(videos)} t√≠tulos extra√≠dos com sucesso via yt-dlp!'
                }
            }
            
            # Salvar no cache
            save_to_cache('channel_videos_ytdlp', cache_params, result, custom_ttl=600, cache_subdir='channel_videos_ytdlp')
            
            print(f"üéâ PROGRESSO: yt-dlp - {len(videos)} v√≠deos processados com sucesso!")
            return result
            
    except ImportError:
        error_msg = 'yt-dlp n√£o est√° instalado'
        print(f"‚ùå ERRO: {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }
    except Exception as e:
        error_msg = f'Erro ao buscar v√≠deos via yt-dlp: {str(e)}'
        print(f"‚ùå ERRO: {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

@automations_bp.route('/generate-titles', methods=['POST'])
def generate_titles():
    """Gerar t√≠tulos virais baseados em t√≠tulos extra√≠dos"""
    try:
        data = request.get_json()

        # Validar dados de entrada
        source_titles = data.get('source_titles', [])
        topic = data.get('topic', '')
        count = data.get('count', 10)
        style = data.get('style', 'viral')
        ai_provider = data.get('ai_provider', 'auto')  # 'openai', 'gemini', 'auto'

        if not source_titles:
            return jsonify({
                'success': False,
                'error': 'T√≠tulos de origem s√£o obrigat√≥rios'
            }), 400

        if not topic:
            return jsonify({
                'success': False,
                'error': 'T√≥pico √© obrigat√≥rio'
            }), 400

        # Carregar chaves de API - priorizar as enviadas pelo frontend
        api_keys = data.get('api_keys', {})
        
        # Se n√£o foram enviadas chaves pelo frontend, carregar do arquivo
        if not api_keys:
            config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    api_keys = json.load(f)

        # Inicializar gerador de t√≠tulos
        title_generator = TitleGenerator()

        # Configurar IAs dispon√≠veis
        openai_configured = False
        gemini_configured = False
        openrouter_configured = False

        if api_keys.get('openai'):
            openai_configured = title_generator.configure_openai(api_keys['openai'])

        gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
        if gemini_key:
            gemini_configured = title_generator.configure_gemini(gemini_key)

        if api_keys.get('openrouter'):
            openrouter_configured = title_generator.configure_openrouter(api_keys['openrouter'])

        if not openai_configured and not gemini_configured and not openrouter_configured:
            return jsonify({
                'success': False,
                'error': 'Nenhuma IA configurada. Configure OpenAI, Gemini ou OpenRouter nas configura√ß√µes.'
            }), 400

        print(f"ü§ñ Gerando t√≠tulos sobre '{topic}' baseado em {len(source_titles)} t√≠tulos de refer√™ncia")

        # Gerar t√≠tulos baseado no provider escolhido com fallback autom√°tico
        results = None
        
        if ai_provider == 'openai' and openai_configured:
            try:
                generated_titles = title_generator.generate_titles_openai(source_titles, topic, count, style)
                results = {
                    'generated_titles': generated_titles,
                    'ai_provider_used': 'openai',
                    'patterns_analysis': title_generator.analyze_viral_patterns(source_titles)
                }
                add_real_time_log("‚úÖ T√≠tulos gerados com OpenAI", "info", "titles-openai")
            except Exception as e:
                error_msg = str(e).lower()
                if '429' in error_msg or 'quota' in error_msg or 'insufficient_quota' in error_msg:
                    add_real_time_log(f"‚ö†Ô∏è OpenAI quota excedida, tentando Gemini como fallback: {e}", "warning", "titles-fallback")
                    if gemini_configured:
                        try:
                            generated_titles = title_generator.generate_titles_gemini(source_titles, topic, count, style)
                            results = {
                                'generated_titles': generated_titles,
                                'ai_provider_used': 'gemini (fallback)',
                                'patterns_analysis': title_generator.analyze_viral_patterns(source_titles)
                            }
                            add_real_time_log("‚úÖ T√≠tulos gerados com Gemini (fallback)", "info", "titles-gemini-fallback")
                        except Exception as gemini_error:
                            add_real_time_log(f"‚ùå Gemini fallback tamb√©m falhou: {gemini_error}", "error", "titles-fallback-failed")
                            raise e  # Re-raise o erro original do OpenAI
                    else:
                        add_real_time_log("‚ùå Gemini n√£o configurado para fallback", "error", "titles-no-fallback")
                        raise e
                else:
                    add_real_time_log(f"‚ùå Erro OpenAI (n√£o quota): {e}", "error", "titles-openai-error")
                    raise e
        elif ai_provider == 'gemini' and gemini_configured:
            generated_titles = title_generator.generate_titles_gemini(source_titles, topic, count, style)
            results = {
                'generated_titles': generated_titles,
                'ai_provider_used': 'gemini',
                'patterns_analysis': title_generator.analyze_viral_patterns(source_titles)
            }
            add_real_time_log("‚úÖ T√≠tulos gerados com Gemini", "info", "titles-gemini")
        else:
            # Modo autom√°tico - tentar OpenAI primeiro, depois Gemini se falhar
            if openai_configured:
                try:
                    results = title_generator.generate_titles_hybrid(source_titles, topic, count, style)
                    add_real_time_log("‚úÖ T√≠tulos gerados com modo h√≠brido (OpenAI)", "info", "titles-hybrid")
                except Exception as e:
                    error_msg = str(e).lower()
                    if ('429' in error_msg or 'quota' in error_msg or 'insufficient_quota' in error_msg) and gemini_configured:
                        add_real_time_log(f"‚ö†Ô∏è Modo h√≠brido falhou (quota), tentando Gemini: {e}", "warning", "titles-hybrid-fallback")
                        try:
                            generated_titles = title_generator.generate_titles_gemini(source_titles, topic, count, style)
                            results = {
                                'generated_titles': generated_titles,
                                'ai_provider_used': 'gemini (auto-fallback)',
                                'patterns_analysis': title_generator.analyze_viral_patterns(source_titles)
                            }
                            add_real_time_log("‚úÖ T√≠tulos gerados com Gemini (auto-fallback)", "info", "titles-auto-fallback")
                        except Exception as gemini_error:
                            add_real_time_log(f"‚ùå Auto-fallback para Gemini falhou: {gemini_error}", "error", "titles-auto-fallback-failed")
                            raise e
                    else:
                        raise e
            elif gemini_configured:
                # Se s√≥ Gemini estiver configurado
                generated_titles = title_generator.generate_titles_gemini(source_titles, topic, count, style)
                results = {
                    'generated_titles': generated_titles,
                    'ai_provider_used': 'gemini (only available)',
                    'patterns_analysis': title_generator.analyze_viral_patterns(source_titles)
                }
                add_real_time_log("‚úÖ T√≠tulos gerados com Gemini (√∫nica op√ß√£o)", "info", "titles-gemini-only")
            else:
                # Usar h√≠brido como √∫ltimo recurso
                results = title_generator.generate_titles_hybrid(source_titles, topic, count, style)

        if results.get('success', True) and (results.get('generated_titles') or results.get('combined_titles')):
            final_titles = results.get('combined_titles') or results.get('generated_titles', [])

            return jsonify({
                'success': True,
                'data': {
                    'generated_titles': final_titles,
                    'total_generated': len(final_titles),
                    'ai_provider_used': results.get('ai_provider_used', 'hybrid'),
                    'patterns_analysis': results.get('patterns_analysis', {}),
                    'source_titles_count': len(source_titles),
                    'topic': topic,
                    'style': style
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': results.get('error', 'Falha na gera√ß√£o de t√≠tulos')
            }), 500

    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de t√≠tulos: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/analyze-titles', methods=['POST'])
def analyze_titles():
    """Analisar padr√µes virais em uma lista de t√≠tulos"""
    try:
        data = request.get_json()
        titles = data.get('titles', [])

        if not titles:
            return jsonify({
                'success': False,
                'error': 'Lista de t√≠tulos √© obrigat√≥ria'
            }), 400

        # Inicializar gerador para usar a an√°lise
        title_generator = TitleGenerator()
        patterns = title_generator.analyze_viral_patterns(titles)

        return jsonify({
            'success': True,
            'data': {
                'patterns': patterns,
                'total_titles_analyzed': len(titles),
                'analysis_summary': {
                    'most_common_triggers': patterns['emotional_triggers'][:5],
                    'popular_numbers': patterns['numbers'][:3],
                    'effective_structures': patterns['structures'],
                    'optimal_length': f"{patterns['length_stats']['min']}-{patterns['length_stats']['max']} chars"
                }
            }
        })

    except Exception as e:
        print(f"‚ùå Erro na an√°lise de t√≠tulos: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/generate-titles-custom', methods=['POST'])
def generate_titles_custom():
    """Gerar t√≠tulos usando prompt personalizado baseado em t√≠tulos extra√≠dos"""
    try:
        data = request.get_json()

        # Validar dados de entrada
        source_titles = data.get('source_titles', [])
        custom_prompt = data.get('custom_prompt', '')
        count = data.get('count', 10)
        ai_provider = data.get('ai_provider', 'auto')  # 'openai', 'gemini', 'auto'
        script_size = data.get('script_size', 'medio')  # 'curto', 'medio', 'longo'

        if not source_titles:
            return jsonify({
                'success': False,
                'error': 'T√≠tulos de origem s√£o obrigat√≥rios'
            }), 400

        if not custom_prompt.strip():
            return jsonify({
                'success': False,
                'error': 'Prompt personalizado √© obrigat√≥rio'
            }), 400

        # Carregar chaves de API
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
        api_keys = {}

        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                api_keys = json.load(f)

        # Inicializar gerador de t√≠tulos
        title_generator = TitleGenerator()

        # Configurar IAs dispon√≠veis
        openai_configured = False
        gemini_configured = False
        openrouter_configured = False

        if api_keys.get('openai'):
            openai_configured = title_generator.configure_openai(api_keys['openai'])

        gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
        if gemini_key:
            gemini_configured = title_generator.configure_gemini(gemini_key)

        if api_keys.get('openrouter'):
            openrouter_configured = title_generator.configure_openrouter(api_keys['openrouter'])

        if not openai_configured and not gemini_configured and not openrouter_configured:
            return jsonify({
                'success': False,
                'error': 'Nenhuma IA configurada. Configure OpenAI, Gemini ou OpenRouter nas configura√ß√µes.'
            }), 400

        print(f"üé® Gerando t√≠tulos com prompt personalizado baseado em {len(source_titles)} t√≠tulos")
        print(f"üìù Prompt: {custom_prompt[:100]}...")

        # Gerar t√≠tulos com prompt personalizado
        results = title_generator.generate_titles_with_custom_prompt(
            source_titles,
            custom_prompt,
            count,
            ai_provider,
            script_size
        )

        if results.get('success', False):
            return jsonify({
                'success': True,
                'data': {
                    'generated_titles': results['generated_titles'],
                    'total_generated': len(results['generated_titles']),
                    'ai_provider_used': results['ai_provider_used'],
                    'patterns_analysis': results['patterns_analysis'],
                    'source_titles_count': len(source_titles),
                    'custom_prompt_used': results['custom_prompt_used']
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': results.get('error', 'Falha na gera√ß√£o de t√≠tulos com prompt personalizado')
            }), 500

    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o com prompt personalizado: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ================================
# üéµ FUN√á√ïES DE TTS
# ================================

def generate_tts_with_kokoro(text, kokoro_url='http://localhost:8880', voice_name='af_bella', language='en', job_id=None, **kwargs):
    """Gerar √°udio TTS usando API Kokoro FastAPI"""
    try:
        print(f"üéµ Iniciando TTS com Kokoro - Texto: {len(text)} chars, Voz: {voice_name}, Idioma: {language}")
        add_real_time_log(f"üéµ Iniciando TTS com Kokoro - Texto: {len(text)} chars, Voz: {voice_name}, Idioma: {language}", "info", "tts-kokoro")

        # Verificar se job foi cancelado
        if job_id and TTS_JOBS.get(job_id, {}).get('cancelled', False):
            add_real_time_log(f"üõë TTS Kokoro - Job {job_id} cancelado antes do in√≠cio", "warning", "tts-kokoro")
            raise Exception("Gera√ß√£o cancelada pelo usu√°rio")

        # Configurar URL da API Kokoro
        url = f"{kokoro_url}/v1/audio/speech"

        # Preparar payload compat√≠vel com OpenAI
        payload = {
            "model": "kokoro",
            "input": text,
            "voice": voice_name,
            "response_format": "wav",
            "speed": kwargs.get('speed', 1.0),
            "language": language
        }

        headers = {
            'Content-Type': 'application/json'
        }

        print(f"üîç Enviando requisi√ß√£o para Kokoro TTS API...")
        print(f"üîç URL: {url}")
        print(f"üîç Voz: {voice_name}")
        add_real_time_log(f"üîç Enviando requisi√ß√£o para Kokoro TTS: {voice_name}", "info", "tts-kokoro")

        # Fazer requisi√ß√£o com timeout otimizado
        timeout = 60  # Timeout de 60 segundos para Kokoro

        # Verificar cancelamento antes da requisi√ß√£o
        if job_id and TTS_JOBS.get(job_id, {}).get('cancelled', False):
            add_real_time_log(f"üõë TTS Kokoro - Job {job_id} cancelado durante requisi√ß√£o", "warning", "tts-kokoro")
            raise Exception("Gera√ß√£o cancelada pelo usu√°rio")

        response = requests.post(url, json=payload, headers=headers, timeout=timeout)

        print(f"üîç Status da resposta: {response.status_code}")
        add_real_time_log(f"‚úÖ Kokoro TTS - Resposta recebida (status: {response.status_code})", "success", "tts-kokoro")

        if response.status_code != 200:
            error_msg = f"Erro da API Kokoro TTS: {response.status_code} - {response.text}"
            print(f"‚ùå {error_msg}")
            add_real_time_log(f"‚ùå {error_msg}", "error", "tts-kokoro")
            raise Exception(error_msg)

        # Verificar cancelamento ap√≥s resposta
        if job_id and TTS_JOBS.get(job_id, {}).get('cancelled', False):
            add_real_time_log(f"üõë TTS Kokoro - Job {job_id} cancelado ap√≥s resposta", "warning", "tts-kokoro")
            raise Exception("Gera√ß√£o cancelada pelo usu√°rio")

        # Processar resposta JSON da API Kokoro
        try:
            response_data = response.json()
            print(f"üîç Resposta JSON keys: {list(response_data.keys())}")
            
            if 'audio' not in response_data:
                raise Exception("Resposta da API Kokoro n√£o cont√©m dados de √°udio")
            
            # Decodificar √°udio base64
            import base64
            audio_base64 = response_data['audio']
            print(f"üîç Base64 length: {len(audio_base64)}, primeiros 50 chars: {audio_base64[:50]}")
            
            if not audio_base64 or audio_base64.strip() == "":
                raise Exception("Dados de √°udio base64 est√£o vazios")
                
            audio_bytes = base64.b64decode(audio_base64)
            
            print(f"üîç √Åudio decodificado: {len(audio_bytes)} bytes")
            add_real_time_log(f"üîç √Åudio Kokoro decodificado: {len(audio_bytes)} bytes", "info", "tts-kokoro")
            
            # Verificar se o √°udio cont√©m apenas zeros (problema conhecido do Kokoro)
            if len(audio_bytes) > 50 and all(b == 0 for b in audio_bytes[:50]):
                print("‚ö†Ô∏è √Åudio Kokoro cont√©m apenas zeros - usando fallback")
                add_real_time_log("‚ö†Ô∏è √Åudio Kokoro inv√°lido (zeros) - tentando fallback", "warning", "tts-kokoro")
                raise Exception("√Åudio Kokoro cont√©m apenas zeros - fallback necess√°rio")
            
        except Exception as decode_error:
            # Fallback: tentar usar resposta como √°udio bin√°rio direto
            print(f"‚ö†Ô∏è Erro ao decodificar JSON, tentando √°udio bin√°rio direto: {decode_error}")
            audio_bytes = response.content
            
            # Verificar se o √°udio bin√°rio tamb√©m cont√©m apenas zeros
            if len(audio_bytes) > 50 and all(b == 0 for b in audio_bytes[:50]):
                print("‚ö†Ô∏è √Åudio bin√°rio tamb√©m cont√©m apenas zeros - usando fallback")
                add_real_time_log("‚ö†Ô∏è √Åudio Kokoro bin√°rio inv√°lido - tentando fallback", "warning", "tts-kokoro")
                raise Exception("√Åudio Kokoro bin√°rio cont√©m apenas zeros - fallback necess√°rio")

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        os.makedirs(temp_dir, exist_ok=True)

        timestamp = int(time.time())
        filename = f"tts_kokoro_{timestamp}.wav"
        filepath = os.path.join(temp_dir, filename)

        print(f"üîç Salvando √°udio em: {filepath}")
        add_real_time_log(f"üîç Salvando √°udio Kokoro: {filename}", "info", "tts-kokoro")

        with open(filepath, 'wb') as f:
            f.write(audio_bytes)

        print(f"‚úÖ √Åudio TTS Kokoro gerado com sucesso: {filepath}")
        add_real_time_log(f"‚úÖ √Åudio Kokoro salvo com sucesso: {filename} ({len(audio_bytes)} bytes)", "success", "tts-kokoro")

        return {
            'success': True,
            'data': {
                'audio_url': f'/api/automations/audio/{filename}',
                'filename': filename,
                'voice_used': voice_name,
                'language_used': language,
                'text_length': len(text),
                'kokoro_url': kokoro_url,
                'size': len(audio_bytes),
                'duration': 0  # Kokoro n√£o fornece dura√ß√£o, mas adicionamos para compatibilidade
            },
            'message': '√Åudio gerado com sucesso usando Kokoro TTS'
        }

    except Exception as e:
        error_msg = f"Erro no TTS Kokoro: {str(e)}"
        print(f"‚ùå {error_msg}")
        add_real_time_log(f"‚ùå {error_msg}", "error", "tts-kokoro")
        return {
            'success': False,
            'error': error_msg
        }

def generate_tts_with_gemini(text, api_key=None, voice_name='Aoede', model='gemini-2.5-flash-preview-tts', job_id=None, **kwargs):
    """Gerar √°udio TTS usando API Gemini nativa com rota√ß√£o de chaves"""
    try:
        print(f"üéµ Iniciando TTS com Gemini - Texto: {len(text)} chars, Voz: {voice_name}")

        # Usar rota√ß√£o de chaves se n√£o foi fornecida uma chave espec√≠fica
        if not api_key:
            api_key = get_next_gemini_key()
            if not api_key:
                raise Exception("Nenhuma chave Gemini dispon√≠vel")

        import requests
        import json
        import time

        # Limitar o texto para evitar timeouts (Gemini TTS tem limite menor)
        max_chars = 2000  # Limite mais conservador para TTS
        if len(text) > max_chars:
            text = text[:max_chars] + "..."
            print(f"‚ö†Ô∏è Texto truncado para {len(text)} caracteres (limite TTS: {max_chars})")

        # Usar API REST do Gemini para TTS
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"

        headers = {
            "x-goog-api-key": api_key,
            "Content-Type": "application/json"
        }

        payload = {
            "contents": [{
                "parts": [{
                    "text": text
                }]
            }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {
                            "voiceName": voice_name
                        }
                    }
                }
            }
        }

        print(f"üîç Enviando requisi√ß√£o para Gemini TTS API...")
        print(f"üîç URL: {url}")
        print(f"üîç Voz: {voice_name}")

        # Implementar retry com timeout otimizado
        max_retries = 2  # Reduzir para 2 tentativas para ser mais r√°pido
        timeouts = [45, 90]  # Timeouts otimizados

        for attempt in range(max_retries):
            # Verificar se job foi cancelado
            if job_id and TTS_JOBS.get(job_id, {}).get('cancelled', False):
                add_real_time_log(f"üõë TTS Gemini - Job {job_id} cancelado durante retry", "warning", "tts-gemini")
                raise Exception("Gera√ß√£o cancelada pelo usu√°rio")

            try:
                timeout = timeouts[attempt]
                print(f"üîÑ Tentativa {attempt + 1}/{max_retries} - Timeout: {timeout}s")
                add_real_time_log(f"üîÑ TTS Gemini - Tentativa {attempt + 1}/{max_retries} (timeout: {timeout}s)", "info", "tts-gemini")

                response = requests.post(url, json=payload, headers=headers, timeout=timeout)
                add_real_time_log(f"‚úÖ TTS Gemini - Resposta recebida (status: {response.status_code})", "success", "tts-gemini")
                break  # Se chegou aqui, a requisi√ß√£o foi bem-sucedida

            except requests.exceptions.Timeout:
                print(f"‚è∞ Timeout na tentativa {attempt + 1}")
                add_real_time_log(f"‚è∞ TTS Gemini - Timeout na tentativa {attempt + 1}", "warning", "tts-gemini")
                if attempt == max_retries - 1:
                    error_msg = f"Timeout ap√≥s {max_retries} tentativas. Tente novamente ou use ElevenLabs."
                    add_real_time_log(f"‚ùå TTS Gemini - {error_msg}", "error", "tts-gemini")
                    raise Exception(error_msg)
                print(f"üîÑ Tentando novamente em 3 segundos...")
                time.sleep(3)
            except Exception as e:
                print(f"‚ùå Erro na tentativa {attempt + 1}: {str(e)}")
                add_real_time_log(f"‚ùå TTS Gemini - Erro tentativa {attempt + 1}: {str(e)}", "error", "tts-gemini")
                if attempt == max_retries - 1:
                    raise
                print(f"üîÑ Tentando novamente em 3 segundos...")
                time.sleep(3)

        print(f"üîç Status da resposta: {response.status_code}")

        if response.status_code != 200:
            error_msg = f"Erro da API Gemini TTS: {response.status_code} - {response.text}"
            print(f"‚ùå {error_msg}")
            raise Exception(error_msg)

        result = response.json()
        print(f"üîç Resposta recebida: {result.keys() if isinstance(result, dict) else 'n√£o √© dict'}")
        add_real_time_log(f"üîç Processando resposta da API Gemini TTS", "info", "tts-gemini")

        # Extrair dados do √°udio da resposta Gemini
        if 'candidates' not in result or not result['candidates']:
            error_msg = "Resposta n√£o cont√©m candidates"
            add_real_time_log(f"‚ùå {error_msg}", "error", "tts-gemini")
            raise Exception(error_msg)

        candidate = result['candidates'][0]
        if 'content' not in candidate or 'parts' not in candidate['content']:
            error_msg = "Resposta n√£o cont√©m content/parts"
            add_real_time_log(f"‚ùå {error_msg}", "error", "tts-gemini")
            raise Exception(error_msg)

        parts = candidate['content']['parts']
        if not parts or 'inlineData' not in parts[0]:
            error_msg = "Resposta n√£o cont√©m inlineData"
            add_real_time_log(f"‚ùå {error_msg}", "error", "tts-gemini")
            raise Exception(error_msg)

        audio_data = parts[0]['inlineData']['data']
        add_real_time_log(f"‚úÖ Dados de √°udio extra√≠dos com sucesso", "success", "tts-gemini")

        # Salvar arquivo tempor√°rio
        import tempfile
        import os
        import base64

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        os.makedirs(temp_dir, exist_ok=True)

        timestamp = int(time.time())
        filename = f"tts_gemini_{timestamp}.wav"
        filepath = os.path.join(temp_dir, filename)

        print(f"üîç Salvando √°udio em: {filepath}")
        add_real_time_log(f"üîç Salvando √°udio TTS: {filename}", "info", "tts-gemini")

        # Decodificar base64 e salvar
        audio_bytes = base64.b64decode(audio_data)
        with open(filepath, 'wb') as f:
            f.write(audio_bytes)

        print(f"‚úÖ √Åudio TTS gerado com sucesso: {filepath}")
        add_real_time_log(f"‚úÖ √Åudio TTS salvo com sucesso: {filename} ({len(audio_bytes)} bytes)", "success", "tts-gemini")

        # URL para acessar o √°udio
        audio_url = f"/api/automations/audio/{filename}"

        return {
            'success': True,
            'data': {
                'audio_file': filepath,
                'filename': filename,
                'audio_url': audio_url,
                'duration': get_audio_duration(filepath),
                'size': len(audio_bytes),
                'voice_used': voice_name,
                'model_used': model,
                'text_length': len(text)
            }
        }

    except Exception as e:
        print(f"‚ùå Erro no TTS Gemini: {e}")
        return {
            'success': False,
            'error': f'Erro ao gerar √°udio com Gemini: {str(e)}'
        }

@automations_bp.route('/tts/jobs', methods=['GET'])
def get_tts_jobs():
    """Obter lista de jobs TTS ativos"""
    try:
        # Limpar jobs antigos (mais de 1 hora)
        current_time = time.time()
        jobs_to_remove = []
        for job_id, job_data in TTS_JOBS.items():
            if current_time - job_data['start_time'] > 3600:  # 1 hora
                jobs_to_remove.append(job_id)

        for job_id in jobs_to_remove:
            del TTS_JOBS[job_id]

        return jsonify({
            'success': True,
            'jobs': TTS_JOBS
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/tts/jobs/<job_id>/cancel', methods=['POST'])
def cancel_tts_job(job_id):
    """Cancelar job TTS espec√≠fico"""
    try:
        if job_id in TTS_JOBS:
            TTS_JOBS[job_id]['cancelled'] = True
            TTS_JOBS[job_id]['status'] = 'cancelled'
            add_real_time_log(f"üõë TTS Job {job_id} cancelado via API", "warning", "tts-control")
            return jsonify({
                'success': True,
                'message': f'Job {job_id} cancelado'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Job n√£o encontrado'
            }), 404
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@automations_bp.route('/audio/<filename>')
def serve_tts_audio(filename):
    """Servir arquivos de √°udio gerados"""
    try:
        import os
        from flask import send_file

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        filepath = os.path.join(temp_dir, filename)

        print(f"üîç Tentando servir √°udio: {filepath}")
        add_real_time_log(f"üîç Servindo √°udio: {filename}", "info", "audio-server")

        if os.path.exists(filepath):
            print(f"‚úÖ Arquivo encontrado, servindo: {filename}")
            add_real_time_log(f"‚úÖ √Åudio servido com sucesso: {filename}", "success", "audio-server")
            return send_file(filepath, as_attachment=False, mimetype='audio/wav')
        else:
            print(f"‚ùå Arquivo n√£o encontrado: {filepath}")
            add_real_time_log(f"‚ùå Arquivo de √°udio n√£o encontrado: {filename}", "error", "audio-server")
            error_response = format_error_response('validation_error', 'Arquivo de √°udio n√£o encontrado', 'Servidor de √Åudio')
            return jsonify(error_response), 404

    except Exception as e:
        print(f"‚ùå Erro ao servir √°udio: {str(e)}")
        add_real_time_log(f"‚ùå Erro ao servir √°udio: {str(e)}", "error", "audio-server")
        error_response = auto_format_error(str(e), 'Servidor de √Åudio')
        return jsonify(error_response), 500

@automations_bp.route('/video/<filename>')
def serve_video(filename):
    """Servir arquivos de v√≠deo gerados"""
    try:
        import os
        from flask import send_file

        # Verificar em m√∫ltiplos diret√≥rios onde os v√≠deos podem estar
        possible_dirs = [
            os.path.join(os.path.dirname(__file__), '..', 'temp'),
            os.path.join(os.path.dirname(__file__), '..', 'outputs'),
            os.path.join(os.path.dirname(__file__), '..', 'temp', 'videos')
        ]
        
        filepath = None
        for temp_dir in possible_dirs:
            potential_path = os.path.join(temp_dir, filename)
            if os.path.exists(potential_path):
                filepath = potential_path
                break

        print(f"üîç Tentando servir v√≠deo: {filename}")
        add_real_time_log(f"üîç Servindo v√≠deo: {filename}", "info", "video-server")

        if filepath and os.path.exists(filepath):
            print(f"‚úÖ Arquivo encontrado, servindo: {filename}")
            add_real_time_log(f"‚úÖ V√≠deo servido com sucesso: {filename}", "success", "video-server")
            return send_file(filepath, as_attachment=False, mimetype='video/mp4')
        else:
            print(f"‚ùå Arquivo n√£o encontrado: {filename}")
            add_real_time_log(f"‚ùå Arquivo de v√≠deo n√£o encontrado: {filename}", "error", "video-server")
            error_response = format_error_response('validation_error', 'Arquivo de v√≠deo n√£o encontrado', 'Servidor de V√≠deo')
            return jsonify(error_response), 404

    except Exception as e:
        print(f"‚ùå Erro ao servir v√≠deo: {str(e)}")
        add_real_time_log(f"‚ùå Erro ao servir v√≠deo: {str(e)}", "error", "video-server")
        error_response = auto_format_error(str(e), 'Servidor de V√≠deo')
        return jsonify(error_response), 500

def get_audio_duration(filepath):
    """Obter dura√ß√£o do arquivo de √°udio"""
    try:
        # Tentar usar mutagen para MP3
        try:
            from mutagen.mp3 import MP3
            audio = MP3(filepath)
            return round(audio.info.length, 2)
        except ImportError:
            # Fallback: estimar dura√ß√£o baseado no tamanho do arquivo
            import os
            file_size = os.path.getsize(filepath)
            # Estimativa: ~1KB por segundo para MP3 de qualidade m√©dia
            estimated_duration = file_size / 1024
            return round(estimated_duration, 2)
        except:
            # Se for WAV, usar wave
            import wave
            with wave.open(filepath, 'rb') as wav_file:
                frames = wav_file.getnframes()
                sample_rate = wav_file.getframerate()
                duration = frames / float(sample_rate)
                return round(duration, 2)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao obter dura√ß√£o do √°udio: {e}")
        return 0.0

def generate_tts_with_elevenlabs(text, api_key, voice_id='default', model_id='eleven_monolingual_v1', **kwargs):
    """Gerar √°udio TTS usando ElevenLabs"""
    try:
        print(f"üéµ Iniciando TTS com ElevenLabs - Texto: {len(text)} chars, Voz: {voice_id}")

        # Se voice_id for 'default', usar uma voz padr√£o conhecida
        if voice_id == 'default':
            voice_id = '21m00Tcm4TlvDq8ikWAM'  # Rachel (voz feminina em ingl√™s)

        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"

        headers = {
            "xi-api-key": api_key,
            "Content-Type": "application/json"
        }

        # Configura√ß√µes de voz mais avan√ßadas
        voice_settings = {
            "stability": kwargs.get('stability', 0.5),
            "similarity_boost": kwargs.get('similarity_boost', 0.5),
            "style": kwargs.get('style', 0.0),
            "use_speaker_boost": kwargs.get('use_speaker_boost', True)
        }

        payload = {
            "text": text,
            "model_id": model_id,
            "voice_settings": voice_settings
        }

        print(f"üîç DEBUG: Fazendo requisi√ß√£o para ElevenLabs...")
        response = requests.post(url, headers=headers, json=payload, timeout=60)

        if response.status_code != 200:
            error_msg = f"Erro ElevenLabs: {response.status_code}"
            try:
                error_data = response.json()
                error_msg += f" - {error_data.get('detail', response.text)}"
            except:
                error_msg += f" - {response.text}"

            return {
                'success': False,
                'error': error_msg
            }

        # Salvar arquivo de √°udio
        import tempfile
        import os

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')
        os.makedirs(temp_dir, exist_ok=True)

        timestamp = int(time.time())
        filename = f"tts_elevenlabs_{timestamp}.mp3"
        filepath = os.path.join(temp_dir, filename)

        with open(filepath, 'wb') as f:
            f.write(response.content)

        print(f"‚úÖ √Åudio TTS ElevenLabs gerado com sucesso: {filepath}")

        return {
            'success': True,
            'data': {
                'audio_file': filepath,
                'filename': filename,
                'size': len(response.content),
                'voice_used': voice_id,
                'model_used': model_id,
                'text_length': len(text),
                'format': 'mp3'
            }
        }

    except Exception as e:
        print(f"‚ùå Erro no TTS ElevenLabs: {e}")
        return {
            'success': False,
            'error': f'Erro ao gerar √°udio com ElevenLabs: {str(e)}'
        }

def join_audio_files(segments):
    """Juntar m√∫ltiplos arquivos de √°udio em um s√≥"""
    try:
        print(f"üîó Juntando {len(segments)} segmentos de √°udio...")

        import os
        import numpy as np
        import soundfile as sf
        import subprocess
        import tempfile

        temp_dir = os.path.join(os.path.dirname(__file__), '..', 'temp')

        # Verificar se temos segmentos v√°lidos
        valid_files = []
        total_size = 0

        for segment in sorted(segments, key=lambda x: x.get('index', 0)):
            filename = segment.get('filename')
            if not filename:
                continue

            filepath = os.path.join(temp_dir, filename)
            if not os.path.exists(filepath):
                print(f"‚ö†Ô∏è Arquivo n√£o encontrado: {filepath}")
                continue

            valid_files.append(filepath)
            total_size += os.path.getsize(filepath)
            print(f"‚úÖ Arquivo v√°lido encontrado: {filename}")

        if not valid_files:
            return {
                'success': False,
                'error': 'Nenhum segmento de √°udio v√°lido encontrado'
            }

        # Usar ffmpeg para concatenar os arquivos (mais eficiente e compat√≠vel)
        timestamp = int(time.time())
        final_filename = f"audio_final_{timestamp}.mp3"
        final_filepath = os.path.join(temp_dir, final_filename)

        # Criar arquivo de lista para ffmpeg
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for filepath in valid_files:
                # Escapar aspas no caminho do arquivo
                escaped_path = filepath.replace('\\', '/').replace("'", "'\"'\"'")
                f.write(f"file '{escaped_path}'\n")
            list_file = f.name

        try:
            # Comando ffmpeg para concatenar
            cmd = [
                'ffmpeg', '-y',  # -y para sobrescrever arquivo existente
                '-f', 'concat',
                '-safe', '0',
                '-i', list_file,
                '-c', 'copy',  # Copiar streams sem recodificar
                final_filepath
            ]

            print(f"üîó Executando concatena√ß√£o com ffmpeg...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

            if result.returncode != 0:
                # Se falhar com copy, tentar recodificar
                print("‚ö†Ô∏è Falha com copy, tentando recodificar...")
                cmd = [
                    'ffmpeg', '-y',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', list_file,
                    '-acodec', 'mp3',
                    '-ab', '192k',
                    final_filepath
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

            if result.returncode != 0:
                raise Exception(f"Erro do ffmpeg: {result.stderr}")

        finally:
            # Limpar arquivo tempor√°rio
            try:
                os.unlink(list_file)
            except:
                pass

        # Verificar se o arquivo foi criado
        if not os.path.exists(final_filepath):
            raise Exception("Arquivo final n√£o foi criado")

        final_size = os.path.getsize(final_filepath)
        
        # Tentar obter dura√ß√£o usando soundfile
        try:
            with sf.SoundFile(final_filepath) as f:
                final_duration = len(f) / f.samplerate
        except:
            # Fallback: estimar dura√ß√£o baseada no n√∫mero de arquivos
            final_duration = len(valid_files) * 10  # Estimativa de 10s por arquivo

        print(f"‚úÖ √Åudio final criado: {final_filename} ({final_duration:.1f}s, {final_size} bytes)")

        return {
            'success': True,
            'data': {
                'audio_file': final_filepath,
                'filename': final_filename,
                'duration': final_duration,
                'size': final_size,
                'segments_count': len(valid_files),
                'format': 'mp3',
                'bitrate': '192k'
            }
        }

    except ImportError as e:
        return {
            'success': False,
            'error': f'Biblioteca necess√°ria n√£o instalada: {str(e)}. Execute: pip install soundfile'
        }
    except subprocess.TimeoutExpired:
        return {
            'success': False,
            'error': 'Timeout na concatena√ß√£o de √°udio. Arquivos muito grandes.'
        }
    except Exception as e:
        print(f"‚ùå Erro ao juntar √°udios: {e}")
        return {
            'success': False,
            'error': f'Erro ao juntar √°udios: {str(e)}'
        }

@automations_bp.route('/rapidapi-keys/reload', methods=['POST'])
def reload_rapidapi_keys():
    """For√ßar reload das chaves RapidAPI do arquivo de configura√ß√£o"""
    try:
        # For√ßar reload das chaves
        old_count = len(RAPIDAPI_KEYS_ROTATION['keys'])
        load_rapidapi_keys()
        new_count = len(RAPIDAPI_KEYS_ROTATION['keys'])
        
        # Reset das chaves falhadas para dar uma nova chance
        RAPIDAPI_KEYS_ROTATION['failed_keys'] = set()
        RAPIDAPI_KEYS_ROTATION['current_index'] = 0
        
        print(f"üîÑ Reload das chaves RapidAPI: {old_count} -> {new_count} chaves")
        add_real_time_log(f"üîÑ Reload das chaves RapidAPI: {old_count} -> {new_count} chaves", "info", "rapidapi-reload")
        
        return jsonify({
            'success': True,
            'message': f'Chaves RapidAPI recarregadas com sucesso',
            'old_count': old_count,
            'new_count': new_count,
            'keys_loaded': new_count,
            'failed_keys_reset': True
        })
        
    except Exception as e:
        print(f"‚ùå Erro ao recarregar chaves RapidAPI: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro ao recarregar chaves: {str(e)}'
        }), 500

# Fun√ß√£o get_rapidapi_status removida para evitar conflito de rotas
# A fun√ß√£o principal est√° definida na linha 574 com rota '/rapidapi-status'

# Fun√ß√£o clear_rapidapi_cache removida para evitar conflito de rotas
# A fun√ß√£o principal est√° definida na linha 613

# Fun√ß√£o reset_rapidapi_throttle removida para evitar conflito de rotas
# A fun√ß√£o principal est√° definida na linha 639

@automations_bp.route('/debug-video-search', methods=['POST'])
def debug_video_search():
    """Endpoint de debug para testar get_channel_videos_rapidapi isoladamente"""
    try:
        data = request.get_json()
        channel_id = data.get('channel_id', 'UCX6OQ3DkcsbYNE6H8uQQuVA')  # MrBeast por padr√£o
        
        print(f"üîç DEBUG: Testando get_channel_videos_rapidapi com channel_id: {channel_id}")
        
        # Configura√ß√£o de teste
        config = {
            'max_videos': 5,
            'min_views': 1000000,
            'max_days_old': 30
        }
        
        start_time = time.time()
        
        # Testar a fun√ß√£o diretamente
        result = get_channel_videos_rapidapi(channel_id, config)
        
        elapsed_time = time.time() - start_time
        
        print(f"üîç DEBUG: get_channel_videos_rapidapi completou em {elapsed_time:.2f}s")
        
        if result['success']:
            videos = result['data']
            print(f"‚úÖ DEBUG: Encontrados {len(videos)} v√≠deos")
            
            return jsonify({
                'success': True,
                'data': {
                    'channel_id': channel_id,
                    'videos_found': len(videos),
                    'elapsed_time': elapsed_time,
                    'videos': videos[:3],  # Apenas os primeiros 3 para debug
                    'config_used': config
                }
            })
        else:
            print(f"‚ùå DEBUG: Erro na busca de v√≠deos: {result.get('error')}")
            return jsonify({
                'success': False,
                'error': result.get('error'),
                'elapsed_time': elapsed_time,
                'channel_id': channel_id
            }), 500
            
    except Exception as e:
        print(f"‚ùå DEBUG: Erro no endpoint de debug: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro no debug: {str(e)}'
        }), 500

@automations_bp.route('/debug-extract-simple', methods=['POST'])
def debug_extract_simple():
    """Endpoint de debug super simples para testar requisi√ß√£o HTTP direta"""
    try:
        data = request.get_json()
        channel_id = data.get('channel_id', 'UCX6OQ3DkcsbYNE6H8uQQuVA')  # Default MrBeast
        
        print(f"üîç DEBUG SIMPLES: Testando requisi√ß√£o HTTP direta para channel_id: {channel_id}")
        
        # Carregar chaves RapidAPI
        load_rapidapi_keys()
        api_key = get_next_rapidapi_key()
        
        if not api_key:
            return jsonify({
                'success': False,
                'error': 'Nenhuma chave RapidAPI dispon√≠vel'
            }), 500
        
        print(f"üîë DEBUG SIMPLES: Usando chave: {api_key[:20]}...")
        
        # Fazer requisi√ß√£o HTTP direta sem cache ou retry
        url = "https://youtube-v2.p.rapidapi.com/channel/videos"
        headers = {
            "X-RapidAPI-Key": api_key,
            "X-RapidAPI-Host": "youtube-v2.p.rapidapi.com"
        }
        params = {
            "channel_id": channel_id,
            "max_results": 5
        }
        
        print(f"üì° DEBUG SIMPLES: Fazendo requisi√ß√£o para {url}")
        print(f"üìã DEBUG SIMPLES: Par√¢metros: {params}")
        
        import requests
        import time
        
        start_time = time.time()
        response = requests.get(url, headers=headers, params=params, timeout=30)
        elapsed_time = time.time() - start_time
        
        print(f"‚úÖ DEBUG SIMPLES: Resposta recebida em {elapsed_time:.2f}s")
        print(f"üìä DEBUG SIMPLES: Status: {response.status_code}")
        print(f"üìè DEBUG SIMPLES: Tamanho: {len(response.content)} bytes")
        
        if response.status_code == 200:
            data = response.json()
            print(f"üéâ DEBUG SIMPLES: Sucesso! Dados recebidos")
            return jsonify({
                'success': True,
                'status_code': response.status_code,
                'response_time': elapsed_time,
                'data_size': len(response.content),
                'data': data
            })
        else:
            print(f"‚ùå DEBUG SIMPLES: Erro {response.status_code}: {response.text[:200]}")
            return jsonify({
                'success': False,
                'status_code': response.status_code,
                'response_time': elapsed_time,
                'error': response.text[:500]
            })
        
    except Exception as e:
        print(f"‚ùå ERRO no debug_extract_simple: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@automations_bp.route('/debug-rapidapi-keys', methods=['GET'])
def debug_rapidapi_keys():
    """Endpoint de debug para verificar o status das chaves RapidAPI"""
    try:
        # Carregar chaves do arquivo de configura√ß√£o
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
        file_keys = {}
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                file_keys = json.load(f)
        
        # Extrair todas as chaves RapidAPI do arquivo
        file_rapidapi_keys = []
        
        # Chave principal
        if file_keys.get('rapidapi'):
            file_rapidapi_keys.append({
                'name': 'rapidapi',
                'key': file_keys['rapidapi'][:20] + '...',
                'full_key': file_keys['rapidapi']
            })
        
        # Chaves numeradas (rapidapi_1, rapidapi_2, etc.)
        for i in range(1, 11):
            key_name = f'rapidapi_{i}'
            if file_keys.get(key_name):
                file_rapidapi_keys.append({
                    'name': key_name,
                    'key': file_keys[key_name][:20] + '...',
                    'full_key': file_keys[key_name]
                })
        
        # Array de chaves (se existir)
        if file_keys.get('rapidapi_keys') and isinstance(file_keys['rapidapi_keys'], list):
            for i, key in enumerate(file_keys['rapidapi_keys']):
                file_rapidapi_keys.append({
                    'name': f'rapidapi_keys[{i}]',
                    'key': key[:20] + '...',
                    'full_key': key
                })
        
        # Status das chaves no sistema de rota√ß√£o
        rotation_keys = RAPIDAPI_KEYS_ROTATION.get('keys', [])
        failed_keys = RAPIDAPI_KEYS_ROTATION.get('failed_keys', set())
        current_index = RAPIDAPI_KEYS_ROTATION.get('current_index', 0)
        
        # Verificar status de cada chave
        keys_status = []
        for file_key in file_rapidapi_keys:
            full_key = file_key['full_key']
            is_loaded = full_key in rotation_keys
            is_failed = full_key in failed_keys
            is_current = is_loaded and rotation_keys[current_index % len(rotation_keys)] == full_key if rotation_keys else False
            
            keys_status.append({
                'name': file_key['name'],
                'key_preview': file_key['key'],
                'is_loaded_in_rotation': is_loaded,
                'is_failed': is_failed,
                'is_current': is_current,
                'status': 'FAILED' if is_failed else ('CURRENT' if is_current else ('LOADED' if is_loaded else 'NOT_LOADED'))
            })
        
        # Estat√≠sticas
        total_keys_in_file = len(file_rapidapi_keys)
        total_keys_loaded = len(rotation_keys)
        total_keys_failed = len(failed_keys)
        total_keys_available = total_keys_loaded - total_keys_failed
        
        print(f"üîç DEBUG RAPIDAPI KEYS:")
        print(f"   üìÅ Chaves no arquivo: {total_keys_in_file}")
        print(f"   üîÑ Chaves carregadas: {total_keys_loaded}")
        print(f"   ‚ùå Chaves falhadas: {total_keys_failed}")
        print(f"   ‚úÖ Chaves dispon√≠veis: {total_keys_available}")
        print(f"   üìç √çndice atual: {current_index}")
        
        for key_status in keys_status:
            print(f"   üîë {key_status['name']}: {key_status['status']} ({key_status['key_preview']})")
        
        return jsonify({
            'success': True,
            'data': {
                'summary': {
                    'total_keys_in_file': total_keys_in_file,
                    'total_keys_loaded': total_keys_loaded,
                    'total_keys_failed': total_keys_failed,
                    'total_keys_available': total_keys_available,
                    'current_index': current_index
                },
                'keys_status': keys_status,
                'rotation_system': {
                    'keys_count': len(rotation_keys),
                    'failed_keys_count': len(failed_keys),
                    'current_index': current_index,
                    'next_key_preview': rotation_keys[(current_index + 1) % len(rotation_keys)][:20] + '...' if rotation_keys else None
                },
                'file_path': config_path,
                'file_exists': os.path.exists(config_path)
            }
        })
        
    except Exception as e:
        print(f"‚ùå Erro no debug das chaves RapidAPI: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro no debug: {str(e)}'
        }), 500

@automations_bp.route('/reset-rapidapi-failed-keys', methods=['POST'])
def reset_rapidapi_failed_keys():
    """Resetar manualmente as chaves RapidAPI falhadas"""
    try:
        # Backup do estado anterior
        old_failed_count = len(RAPIDAPI_KEYS_ROTATION.get('failed_keys', set()))
        old_failed_keys = list(RAPIDAPI_KEYS_ROTATION.get('failed_keys', set()))
        
        # Resetar chaves falhadas
        RAPIDAPI_KEYS_ROTATION['failed_keys'] = set()
        RAPIDAPI_KEYS_ROTATION['current_index'] = 0
        
        # Recarregar chaves do arquivo
        load_rapidapi_keys()
        
        new_available_count = len(RAPIDAPI_KEYS_ROTATION.get('keys', [])) - len(RAPIDAPI_KEYS_ROTATION.get('failed_keys', set()))
        
        print(f"üîÑ Reset manual das chaves RapidAPI:")
        print(f"   ‚ùå Chaves falhadas removidas: {old_failed_count}")
        print(f"   ‚úÖ Chaves dispon√≠veis agora: {new_available_count}")
        print(f"   üîÑ √çndice resetado para: 0")
        
        add_real_time_log(f"üîÑ Reset manual: {old_failed_count} chaves falhadas removidas, {new_available_count} dispon√≠veis", "info", "rapidapi-reset")
        
        return jsonify({
            'success': True,
            'message': 'Chaves RapidAPI falhadas resetadas com sucesso',
            'data': {
                'old_failed_count': old_failed_count,
                'old_failed_keys_preview': [key[:20] + '...' for key in old_failed_keys],
                'new_available_count': new_available_count,
                'total_keys_loaded': len(RAPIDAPI_KEYS_ROTATION.get('keys', [])),
                'current_index_reset_to': 0
            }
        })
        
    except Exception as e:
        print(f"‚ùå Erro ao resetar chaves RapidAPI falhadas: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro ao resetar chaves: {str(e)}'
        }), 500

# ================================
# üß™ ENDPOINTS DE TESTE PARA EXTRA√á√ÉO
# ================================

@automations_bp.route('/test-rapidapi', methods=['POST'])
def test_rapidapi_extraction():
    """Endpoint de teste para extra√ß√£o via RapidAPI"""
    print("üîç DEBUG: Endpoint /test-rapidapi foi chamado!")
    try:
        data = request.get_json()
        print(f"üîç DEBUG: Dados recebidos: {data}")
        url = data.get('url', '')
        max_titles = data.get('max_titles', 30)
        min_views = data.get('min_views', 0)
        max_views = data.get('max_views', None)
        days = data.get('days', None)
        
        if not url:
            return jsonify({
                'success': False,
                'error': 'URL √© obrigat√≥ria'
            }), 400
        
        print(f"üß™ TESTE RapidAPI: Iniciando extra√ß√£o para {url}")
        
        # Debug: verificar estado do sistema de rota√ß√£o
        print(f"üîç DEBUG: RAPIDAPI_KEYS_ROTATION = {RAPIDAPI_KEYS_ROTATION}")
        
        # Obter chave RapidAPI do sistema de rota√ß√£o
        rapidapi_key = get_next_rapidapi_key()
        print(f"üîç DEBUG: Chave obtida = {rapidapi_key[:20] if rapidapi_key else 'None'}...")
        
        if not rapidapi_key:
            print("‚ùå DEBUG: Nenhuma chave RapidAPI dispon√≠vel")
            return jsonify({
                'success': False,
                'error': 'Chave da API RapidAPI √© obrigat√≥ria'
            }), 400
        
        # Extrair channel_id da URL
        channel_id = extract_channel_id_from_url(url, rapidapi_key)
        if not channel_id:
            return jsonify({
                'success': False,
                'error': 'N√£o foi poss√≠vel extrair o ID do canal da URL'
            }), 400
        
        # Chamar fun√ß√£o RapidAPI
        start_time = time.time()
        result = get_channel_videos_rapidapi(channel_id, rapidapi_key, max_titles)
        end_time = time.time()
        
        if result.get('success'):
            # Aplicar filtros se especificados
            videos = result['data']['videos']
            if min_views or (max_views is not None and max_views > 0) or days:
                config = {
                    'min_views': min_views,
                    'max_views': max_views,
                    'days': days,
                    'max_titles': max_titles
                }
                videos = filter_videos_by_config(videos, config)
            
            return jsonify({
                'success': True,
                'method': 'RapidAPI',
                'response_time': round(end_time - start_time, 2),
                'data': {
                    'videos': videos,
                    'total_videos': len(videos),
                    'message': f'‚úÖ {len(videos)} v√≠deos extra√≠dos via RapidAPI!'
                }
            })
        else:
            return jsonify({
                'success': False,
                'method': 'RapidAPI',
                'response_time': round(end_time - start_time, 2),
                'error': result.get('error', 'Erro desconhecido')
            }), 500
            
    except Exception as e:
        print(f"‚ùå Erro no teste RapidAPI: {e}")
        return jsonify({
            'success': False,
            'method': 'RapidAPI',
            'error': str(e)
        }), 500

@automations_bp.route('/test-youtube-api', methods=['POST'])
def test_youtube_api_extraction():
    """Endpoint de teste para extra√ß√£o via YouTube Data API v3"""
    try:
        data = request.get_json()
        url = data.get('url', '')
        max_titles = data.get('max_titles', 30)
        min_views = data.get('min_views', 0)
        max_views = data.get('max_views', None)
        days = data.get('days', None)
        
        if not url:
            return jsonify({
                'success': False,
                'error': 'URL √© obrigat√≥ria'
            }), 400
        
        print(f"üß™ TESTE YouTube API: Iniciando extra√ß√£o para {url}")
        
        # Carregar chave da API do arquivo de configura√ß√£o
        try:
            config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    api_keys = json.load(f)
                youtube_api_key = api_keys.get('youtube_api')
            else:
                return jsonify({
                    'success': False,
                    'error': 'Arquivo api_keys.json n√£o encontrado'
                }), 400
        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'Erro ao carregar api_keys.json: {str(e)}'
            }), 400
        
        if not youtube_api_key:
            return jsonify({
                'success': False,
                'error': 'Chave da YouTube API n√£o configurada no arquivo api_keys.json'
            }), 400
        
        # Extrair channel_id da URL (agora com suporte a handles)
        channel_id = extract_channel_id_from_url(url, youtube_api_key)
        if not channel_id:
            return jsonify({
                'success': False,
                'error': 'N√£o foi poss√≠vel extrair o ID do canal da URL'
            }), 400
        
        # Chamar fun√ß√£o YouTube API
        start_time = time.time()
        result = get_channel_videos_youtube_api(channel_id, youtube_api_key, max_titles)
        end_time = time.time()
        
        if result.get('success'):
            # Aplicar filtros se especificados
            videos = result['data']['videos']
            if min_views or (max_views is not None and max_views > 0) or days:
                config = {
                    'min_views': min_views,
                    'max_views': max_views,
                    'days': days,
                    'max_titles': max_titles
                }
                videos = filter_videos_by_config(videos, config)
            
            return jsonify({
                'success': True,
                'method': 'YouTube API Official',
                'response_time': round(end_time - start_time, 2),
                'data': {
                    'videos': videos,
                    'total_videos': len(videos),
                    'message': f'‚úÖ {len(videos)} v√≠deos extra√≠dos via YouTube API oficial!'
                }
            })
        else:
            return jsonify({
                'success': False,
                'method': 'YouTube API Official',
                'response_time': round(end_time - start_time, 2),
                'error': result.get('error', 'Erro desconhecido')
            }), 500
            
    except Exception as e:
        print(f"‚ùå Erro no teste YouTube API: {e}")
        return jsonify({
            'success': False,
            'method': 'YouTube API Official',
            'error': str(e)
        }), 500

@automations_bp.route('/extract-youtube-ytdlp', methods=['POST'])
def extract_youtube_ytdlp_endpoint():
    """Endpoint dedicado para extra√ß√£o via yt-dlp"""
    try:
        print("üõ°Ô∏è DEBUG: Iniciando endpoint /extract-youtube-ytdlp")
        data = request.get_json()
        print(f"üõ°Ô∏è DEBUG: Dados recebidos: {data}")
        
        url = data.get('url', '').strip()
        config = data.get('config', {})
        
        print(f"üõ°Ô∏è DEBUG: URL: {url}, Config: {config}")
        
        if not url:
            print("‚ùå DEBUG: URL n√£o fornecida")
            return jsonify({
                'success': False,
                'error': 'URL ou ID do canal √© obrigat√≥rio'
            }), 400
        
        print(f"üõ°Ô∏è EXTRA√á√ÉO yt-dlp: Iniciando extra√ß√£o para {url}")
        
        # Chamar fun√ß√£o yt-dlp
        extraction_start_time = time.time()
        result = get_channel_videos_ytdlp(url, config.get('max_titles', 10))
        
        print(f"üõ°Ô∏è DEBUG: Resultado da fun√ß√£o yt-dlp: {result.get('success', False)}")
        
        if result.get('success'):
            # Aplicar filtros se especificados
            videos = result['data']['videos']
            if config:
                videos = filter_videos_by_config(videos, config)
            
            # Preparar dados de resposta
            result_data = result['data']
            result_data['extraction_method'] = 'yt-dlp'
            result_data['videos'] = videos
            result_data['total_videos'] = len(videos)
            result_data['extraction_time'] = time.time() - extraction_start_time
            
            # Calcular totais
            total_views = sum(video.get('views', 0) for video in videos)
            total_likes = sum(video.get('likes', 0) for video in videos)
            result_data['total_views'] = total_views
            result_data['total_likes'] = total_likes
            
            print(f"‚úÖ yt-dlp: {len(videos)} v√≠deos extra√≠dos com sucesso!")
            
            return jsonify({
                'success': True,
                'data': result_data,
                'message': f'‚úÖ Extra√ß√£o conclu√≠da via yt-dlp. {len(videos)} v√≠deos encontrados.'
            })
        else:
            print(f"‚ùå yt-dlp falhou: {result.get('error', 'Erro desconhecido')}")
            return jsonify({
                'success': False,
                'error': result.get('error', 'Erro na extra√ß√£o via yt-dlp')
            }), 500
            
    except Exception as e:
        print(f"‚ùå Erro no endpoint yt-dlp: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro interno: {str(e)}'
        }), 500

@automations_bp.route('/test-ytdlp', methods=['POST'])
def test_ytdlp_extraction():
    """Endpoint de teste para extra√ß√£o via yt-dlp"""
    try:
        print("üîç DEBUG: Iniciando endpoint /test-ytdlp")
        data = request.get_json()
        print(f"üîç DEBUG: Dados recebidos: {data}")
        
        url = data.get('channel_url', '') or data.get('url', '')
        max_titles = data.get('max_titles', 30)
        min_views = data.get('min_views', 0)
        max_views = data.get('max_views', None)
        days = data.get('max_days', None) or data.get('days', None)
        
        print(f"üîç DEBUG: Par√¢metros processados - URL: {url}, max_titles: {max_titles}, min_views: {min_views}, days: {days}")
        
        if not url:
            print("‚ùå DEBUG: URL n√£o fornecida")
            return jsonify({
                'success': False,
                'error': 'URL √© obrigat√≥ria'
            }), 400
        
        print(f"üß™ TESTE yt-dlp: Iniciando extra√ß√£o para {url}")
        print("üîç DEBUG: Chamando get_channel_videos_ytdlp...")
        
        # Chamar fun√ß√£o yt-dlp
        start_time = time.time()
        result = get_channel_videos_ytdlp(url, max_titles)
        end_time = time.time()
        
        print(f"üîç DEBUG: Resultado da fun√ß√£o yt-dlp: {result}")
        print(f"üîç DEBUG: Tempo de execu√ß√£o: {round(end_time - start_time, 2)}s")
        
        if result.get('success'):
            # Aplicar filtros se especificados
            videos = result['data']['videos']
            if min_views or (max_views is not None and max_views > 0) or days:
                config = {
                    'min_views': min_views,
                    'max_views': max_views,
                    'days': days,
                    'max_titles': max_titles
                }
                videos = filter_videos_by_config(videos, config)
            
            return jsonify({
                'success': True,
                'method': 'yt-dlp',
                'response_time': round(end_time - start_time, 2),
                'data': {
                    'videos': videos,
                    'total_videos': len(videos),
                    'message': f'‚úÖ {len(videos)} v√≠deos extra√≠dos via yt-dlp!'
                }
            })
        else:
            return jsonify({
                'success': False,
                'method': 'yt-dlp',
                'response_time': round(end_time - start_time, 2),
                'error': result.get('error', 'Erro desconhecido')
            }), 500
            
    except Exception as e:
        print(f"‚ùå Erro no teste yt-dlp: {e}")
        return jsonify({
            'success': False,
            'method': 'yt-dlp',
            'error': str(e)
        }), 500

# ================================
# üöÄ INICIALIZA√á√ÉO DO SISTEMA
# ================================

# Fun√ß√£o debug_extract_simple removida (duplicata) - mantida apenas a primeira defini√ß√£o na linha 737

# Carregar cache persistente na inicializa√ß√£o
try:
    load_persistent_cache()
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao carregar cache persistente na inicializa√ß√£o: {e}")



# Carregar chaves RapidAPI na inicializa√ß√£o
try:
    load_rapidapi_keys()
    print(f"‚úÖ Chaves RapidAPI carregadas na inicializa√ß√£o: {len(RAPIDAPI_KEYS_ROTATION.get('keys', []))} chaves")
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao carregar chaves RapidAPI na inicializa√ß√£o: {e}")

# Carregar chaves Gemini na inicializa√ß√£o
try:
    load_gemini_keys()
    print(f"‚úÖ Chaves Gemini carregadas na inicializa√ß√£o: {len(GEMINI_KEYS_ROTATION.get('keys', []))} chaves")
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao carregar chaves Gemini na inicializa√ß√£o: {e}")

# ================================
# üîÑ SISTEMA DE RETRY AUTOM√ÅTICO GEMINI
# ================================

def generate_content_with_gemini_retry(prompt, max_retries=None):
    """Gerar conte√∫do usando Gemini com retry autom√°tico entre m√∫ltiplas chaves"""
    import google.generativeai as genai
    
    # Se max_retries n√£o for especificado, usar a quantidade real de chaves dispon√≠veis
    if max_retries is None:
        max_retries = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
    
    last_error = None
    
    for attempt in range(max_retries):
        try:
            # Obter chave Gemini
            api_key = get_next_gemini_key()
            if not api_key:
                raise Exception('Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.')
            
            print(f"üîÑ Tentativa {attempt + 1}/{max_retries}: Usando chave Gemini")
            
            # Configurar Gemini diretamente
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            print(f"üîç DEBUG: Enviando prompt para Gemini ({len(prompt)} chars) - Tentativa {attempt + 1}/{max_retries}")
            response = model.generate_content(prompt)
            print(f"‚úÖ Gemini respondeu com sucesso na tentativa {attempt + 1}")
            return response.text
            
        except Exception as e:
            error_str = str(e)
            last_error = error_str
            print(f"‚ùå Tentativa {attempt + 1}/{max_retries} falhou: {error_str}")
            
            # Se √© erro 429 (quota exceeded) e n√£o √© a √∫ltima tentativa, tentar pr√≥xima chave
            if ("429" in error_str or "quota" in error_str.lower() or "exceeded" in error_str.lower()) and attempt < max_retries - 1:
                print(f"üîÑ Erro de cota detectado, tentando pr√≥xima chave...")
                # Passamos a chave atual que falhou para registrar corretamente
                handle_gemini_429_error(error_str, api_key)
                continue
            else:
                # Outros erros ou √∫ltima tentativa, parar
                if attempt == max_retries - 1:
                    print(f"üõë √öltima tentativa falhou, parando retries")
                else:
                    print(f"üõë Erro n√£o relacionado √† cota, parando tentativas")
                break
    
    # Se chegou aqui, todas as tentativas falharam
    final_error = f'Todas as {max_retries} tentativas Gemini falharam. √öltimo erro: {last_error}'
    print(f"‚ùå DEBUG: {final_error}")
    raise Exception(f'Erro Gemini: {final_error}')
