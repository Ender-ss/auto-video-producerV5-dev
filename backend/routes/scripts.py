"""
üìù Script Generation Routes
Rotas para gera√ß√£o de roteiros com pipeline de 3 prompts
"""

from flask import Blueprint, request, jsonify
import requests
import json
import time
from services.title_generator import TitleGenerator

scripts_bp = Blueprint('scripts', __name__)

@scripts_bp.route('/generate', methods=['POST'])
def generate_long_script(update_callback=None):
    """Gerar roteiros usando Storyteller Unlimited (100% integra√ß√£o)"""
    try:
        from services.storyteller_service import StorytellerService
        
        data = request.get_json()
        title = data.get('title', '')
        premise = data.get('premise', '')
        number_of_chapters = data.get('number_of_chapters', 8)
        api_keys = data.get('api_keys', {})
        
        # Par√¢metros do Storyteller
        agent = data.get('storyteller_agent', 'millionaire_stories')
        target_words = data.get('target_words', 2500)
        
        if not title or not premise:
            return jsonify({
                'success': False,
                'error': 'T√≠tulo e premissa s√£o obrigat√≥rios'
            }), 400

        # Inicializar Storyteller Service
        storyteller_service = StorytellerService()
        
        print("üé¨ Iniciando Storyteller Unlimited...")
        
        # Preparar premissa aprimorada para o Storyteller
        enhanced_premise = f"""
        T√≠tulo: {title}
        
        Contexto: {premise}
        
        Objetivo: Criar um roteiro envolvente dividido em {number_of_chapters} cap√≠tulos com aproximadamente {target_words} palavras no total.
        
        Requisitos:
        - Cada cap√≠tulo deve ter entre 300-500 palavras
        - Manter continuidade narrativa entre cap√≠tulos
        - Usar estrutura de storytelling envolvente
        - Finalizar com gancho para pr√≥ximo cap√≠tulo (exceto o √∫ltimo)
        - Adaptar linguagem para p√∫blico brasileiro
        """

        # Gerar roteiro com Storyteller Unlimited
        result = storyteller_service.generate_storyteller_script(
            title=title,
            premise=enhanced_premise,
            agent_type=agent if agent else 'millionaire_stories',
            num_chapters=number_of_chapters,
            provider='gemini'
        )

        if not result:
            raise Exception("Falha na gera√ß√£o com Storyteller Unlimited")

        # Processar cap√≠tulos retornados pelo Storyteller
        chapters_data = result.get('chapters') or []
        chapters = []
        if chapters_data:
            for idx, ch in enumerate(chapters_data, 1):
                chapters.append({
                    'chapter_number': idx,
                    'title': ch.get('title', f'Cap√≠tulo {idx}'),
                    'content': ch.get('content', '')
                })
            script_content = result.get('full_script', "\n\n".join(ch.get('content', '') for ch in chapters_data))
        else:
            script_content = result.get('full_script', '')
            if script_content:
                # Tentar dividir por marcadores comuns de cap√≠tulos
                chapter_parts = script_content.split('\n\n## Cap√≠tulo ')
                for i, part in enumerate(chapter_parts):
                    if i == 0 and not part.strip().startswith('Cap√≠tulo'):
                        # pode ser uma introdu√ß√£o fora do padr√£o; pular
                        continue
                    if part.strip():
                        chapter_num = i + 1
                        chapter_text = part.strip()
                        if not chapter_text.startswith('Cap√≠tulo'):
                            chapter_text = f"Cap√≠tulo {chapter_num}\n\n{chapter_text}"
                        chapters.append({
                            'chapter_number': chapter_num,
                            'title': f'Cap√≠tulo {chapter_num}',
                            'content': chapter_text
                        })

        # Formatar resultado no padr√£o esperado
        script_result = {
            'title': title,
            'premise': premise,
            'context': enhanced_premise,
            'narrative_structure': result.get('narrative_summary', ''),
            'chapters': chapters,
            'total_chapters': len(chapters),
            'total_words': sum(len(ch['content'].split()) for ch in chapters if ch.get('content')),
            'system_used': 'storyteller_unlimited',
            'agent': agent
        }

        return jsonify({
            'success': True,
            'scripts': script_result,
            'provider_used': 'storyteller_unlimited',
            'chapters_generated': len(result['chapters']),
            'system': 'storyteller'
        })

    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o com Storyteller Unlimited: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'system': 'storyteller_unlimited'
        }), 500

def execute_prompt_1(title, premise, ai_provider, openrouter_model, api_keys, title_generator):
    """Prompt 1: Tradu√ß√£o e Contexto"""
    prompt = f"""Por favor, forne√ßa o texto acima em Portugu√™s, utilizando nomes e express√µes comuns entre os falantes de Portugu√™s em diferentes pa√≠ses, adaptado de forma a refletir a cultura compartilhada pelos diversos povos que falam a l√≠ngua. Adapte nomes, locais e refer√™ncias culturais de forma a serem naturais e reconhec√≠veis no idioma Portugu√™s, garantindo que mantenham relev√¢ncia e ressoem com o p√∫blico.

A sa√≠da deve ter o seguinte formato:

{{
    "Contexto": "{premise}"
}}

Certifique-se de que a chave gerada siga o padr√£o exigido."""

    try:
        if ai_provider == 'auto':
            providers = ['openrouter', 'gemini', 'openai']
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
                    elif provider == 'gemini' and title_generator.gemini_model:
                        return call_gemini(prompt, title_generator)
                    elif provider == 'openai' and title_generator.openai_client:
                        return call_openai(prompt, title_generator)
                except Exception as e:
                    print(f"‚ùå Erro com {provider}: {e}")
                    continue
        elif ai_provider == 'openrouter':
            return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
        elif ai_provider == 'gemini':
            return call_gemini(prompt, title_generator)
        elif ai_provider == 'openai':
            return call_openai(prompt, title_generator)
            
        return None
    except Exception as e:
        print(f"‚ùå Erro no Prompt 1: {e}")
        return None

def execute_prompt_2(title, context, ai_provider, openrouter_model, api_keys, title_generator):
    """Prompt 2: Estrutura Narrativa"""
    prompt = f"""# Objetivo Principal: 

Transformar qualquer tema em um √∫nico prompt narrativo para o primeiro cap√≠tulo, sem finalizar a hist√≥ria. O resultado ser√° um array JSON chamado `Prompts`, que conter√° exatamente 1 objeto, com o campo `prompt`.

## Tema: "{title}"
### Contexto: "{context}"

## Estrutura Base do Prompt  
Cada prompt deve come√ßar com: "Escreva uma hist√≥ria de aproximadamente 500 palavras sobre..."  

## Especifica√ß√µes T√©cnicas do JSON

```json
{{
  "Prompts": [
    {{
      "prompt": "Escreva uma hist√≥ria de aproximadamente 500 palavras sobre..."
    }}
  ]
}}
```

## Requisitos T√©cnicos 

- Apenas um objeto no array `Prompts`  
- Cadeia com aspas duplas  
- Indenta√ß√£o: 2 espa√ßos  
- Sem quebras de linha no conte√∫do de `prompt`  
- JSON v√°lido e com caracteres especiais escapados  

## Estrutura Narrativa Detalhada (Apenas Primeiro Cap√≠tulo)

1. **Apresenta√ß√£o do Protagonista**  
   - Nome e caracter√≠sticas principais  
   - Contexto social/profissional  
   - Estado emocional inicial  

2. **Cen√°rio Principal**  
   - Localiza√ß√£o temporal e espacial  
   - Atmosfera e ambiente  
   - Elementos √∫nicos do mundo da hist√≥ria  

3. **Ativador da Hist√≥ria**  
   - Evento catalisador que rompa a normalidade  
   - Inicie o conflito inicial ou dilema principal  

4. **Gancho Narrativo**  
   - Elemento de mist√©rio ou tens√£o que deixe clara a continua√ß√£o  
   - Pergunta n√£o resolvida  
   - Termine sem concluir o conflito, mantendo a hist√≥ria incompleta 

## Checklist de Valida√ß√£o

1. **JSON**  
   - [ ] Apenas 1 objeto dentro de "Prompts"  
   - [ ] Campo "prompt" sem quebras de linha  
   - [ ] Cadeias com aspas duplas, sem caracteres especiais 

2. **Narrativa**  
   - [ ] Hist√≥ria N√ÉO finalizada (o cap√≠tulo fica em aberto)    
   - [ ] Inclui ganchos, sem resolver o conflito  
   - [ ] N√£o conclua a trama nem resolva o conflito principal. Em vez disso, crie um problema a partir de cada solu√ß√£o, fazendo o leitor sentir que a hist√≥ria ainda precisa continuar. A sensa√ß√£o final deve ser de que h√° mais por vir, nunca uma conclus√£o definitiva.  
   - [ ] Certifique-se de que o cap√≠tulo termine com um gancho intrigante, criando um mist√©rio ou uma d√∫vida que deixe o leitor ansioso pelo pr√≥ximo cap√≠tulo, sem conseguir parar de ler.  
   - [ ] Mantenha um equil√≠brio entre a√ß√£o e reflex√£o, permitindo que o personagem evolua, mas sem dar respostas definitivas ou conclus√µes que resolvam os dilemas abertos.

## Observa√ß√£o Final

- N√£o conclua a trama nem resolva o conflito principal. Em vez disso, crie um problema a partir de cada solu√ß√£o, fazendo o leitor sentir que a hist√≥ria ainda precisa continuar. A sensa√ß√£o final deve ser que h√° mais por vir, nunca uma conclus√£o definitiva.  
- Certifique-se de que o cap√≠tulo termine com um gancho intrigante, criando um mist√©rio ou uma d√∫vida que deixe o leitor ansioso pelo pr√≥ximo cap√≠tulo, sem conseguir parar de ler.  
- Mantenha um equil√≠brio entre a√ß√£o e reflex√£o, permitindo que o personagem evolua, mas sem dar respostas definitivas ou conclus√µes que resolvam os dilemas abertos."""

    try:
        if ai_provider == 'auto':
            providers = ['openrouter', 'gemini', 'openai']
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
                    elif provider == 'gemini' and title_generator.gemini_model:
                        return call_gemini(prompt, title_generator)
                    elif provider == 'openai' and title_generator.openai_client:
                        return call_openai(prompt, title_generator)
                except Exception as e:
                    print(f"‚ùå Erro com {provider}: {e}")
                    continue
        elif ai_provider == 'openrouter':
            return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
        elif ai_provider == 'gemini':
            return call_gemini(prompt, title_generator)
        elif ai_provider == 'openai':
            return call_openai(prompt, title_generator)
            
        return None
    except Exception as e:
        print(f"‚ùå Erro no Prompt 2: {e}")
        return None

def execute_prompt_3(title, context, narrative_result, number_of_chapters, ai_provider, openrouter_model, api_keys, title_generator, update_callback=None, custom_inicio='', custom_meio='', custom_fim='', detailed_prompt_text=''):
    """Prompt 3: Gera√ß√£o dos Cap√≠tulos"""
    chapters = []

    try:
        print(f"üîç DEBUG: Iniciando gera√ß√£o de {number_of_chapters} cap√≠tulos")
        print(f"üîç DEBUG: AI Provider: {ai_provider}")
        print(f"üîç DEBUG: APIs dispon√≠veis: {list(api_keys.keys())}")
        print(f"üîç DEBUG: Usando prompt detalhado: {'‚úÖ' if detailed_prompt_text else '‚ùå'}")

        # Verificar se h√° pelo menos uma API configurada
        has_openrouter = api_keys.get('openrouter') is not None and title_generator.openrouter_api_key is not None
        has_gemini = title_generator.gemini_model is not None
        has_openai = title_generator.openai_client is not None

        print(f"üîç DEBUG: OpenRouter configurado: {'‚úÖ' if has_openrouter else '‚ùå'}")
        print(f"üîç DEBUG: Gemini configurado: {'‚úÖ' if has_gemini else '‚ùå'}")
        print(f"üîç DEBUG: OpenAI configurado: {'‚úÖ' if has_openai else '‚ùå'}")

        if not (has_openrouter or has_gemini or has_openai):
            print("‚ùå ERRO: Nenhuma API de IA configurada para gera√ß√£o de roteiros")
            return []

        # Extrair o prompt base da estrutura narrativa
        base_prompt = extract_base_prompt(narrative_result)
        print(f"üîç DEBUG: Base prompt extra√≠do: {base_prompt[:100]}...")
        
        # Importar fun√ß√µes auxiliares para prompts de roteiro
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from routes.premise import create_inicio_prompt, create_capitulo_prompt, create_final_prompt
        
        # Se tiver prompt detalhado, usar a fun√ß√£o de gera√ß√£o de roteiro longo
        if detailed_prompt_text:
            print("üìù Usando prompt detalhado para gera√ß√£o de roteiro longo")
            return generate_script_with_detailed_prompt(title, context, base_prompt, detailed_prompt_text, number_of_chapters, ai_provider, openrouter_model, api_keys, title_generator, update_callback)
        
        for i in range(number_of_chapters):
            print(f"üìñ Gerando Cap√≠tulo {i + 1}/{number_of_chapters}")
            
            # Determinar qual prompt usar baseado na posi√ß√£o do cap√≠tulo
            if i == 0:
                # Primeiro cap√≠tulo - usar prompt de in√≠cio
                if custom_inicio:
                    chapter_prompt = custom_inicio
                else:
                    chapter_prompt = create_inicio_prompt(title, context, base_prompt, 'medio')
            elif i == number_of_chapters - 1:
                # √öltimo cap√≠tulo - usar prompt de fim
                if custom_fim:
                    chapter_prompt = custom_fim
                else:
                    chapter_prompt = create_final_prompt(title, context, base_prompt, 'medio')
            else:
                # Cap√≠tulos do meio - usar prompt de meio
                if custom_meio:
                    chapter_prompt = custom_meio
                else:
                    chapter_prompt = create_capitulo_prompt(title, context, base_prompt, i, number_of_chapters, 'medio')

            # Gerar o cap√≠tulo
            chapter_content = None
            print(f"üîç DEBUG: Gerando cap√≠tulo {i+1} com prompt de {len(chapter_prompt)} caracteres")

            if ai_provider == 'auto':
                providers = ['openrouter', 'gemini', 'openai']
                for provider in providers:
                    try:
                        print(f"üîç DEBUG: Tentando provider {provider}")
                        if provider == 'openrouter' and api_keys.get('openrouter'):
                            print(f"üîç DEBUG: Chamando OpenRouter...")
                            chapter_content = call_openrouter(chapter_prompt, openrouter_model, api_keys['openrouter'])
                            print(f"‚úÖ DEBUG: OpenRouter retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        elif provider == 'gemini' and title_generator.gemini_model:
                            print(f"üîç DEBUG: Chamando Gemini...")
                            chapter_content = call_gemini(chapter_prompt, title_generator)
                            print(f"‚úÖ DEBUG: Gemini retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        elif provider == 'openai' and title_generator.openai_client:
                            print(f"üîç DEBUG: Chamando OpenAI...")
                            chapter_content = call_openai(chapter_prompt, title_generator)
                            print(f"‚úÖ DEBUG: OpenAI retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        else:
                            print(f"‚ö†Ô∏è DEBUG: Provider {provider} n√£o dispon√≠vel")
                    except Exception as e:
                        print(f"‚ùå Erro com {provider}: {e}")
                        continue
            elif ai_provider == 'openrouter':
                chapter_content = call_openrouter(chapter_prompt, openrouter_model, api_keys['openrouter'])
            elif ai_provider == 'gemini':
                chapter_content = call_gemini(chapter_prompt, title_generator)
            elif ai_provider == 'openai':
                chapter_content = call_openai(chapter_prompt, title_generator)
            
            if chapter_content:
                # Gerar t√≠tulo do cap√≠tulo baseado no conte√∫do
                chapter_title = f"Cap√≠tulo {i + 1}"
                if len(chapter_content) > 50:
                    # Tentar extrair uma frase inicial como t√≠tulo
                    first_sentence = chapter_content.split('.')[0][:50]
                    if len(first_sentence) > 10:
                        chapter_title = f"Cap√≠tulo {i + 1}: {first_sentence}..."

                chapters.append({
                    'chapter_number': i + 1,
                    'title': chapter_title,
                    'content': chapter_content,
                    'word_count': len(chapter_content.split())
                })
                if update_callback:
                    update_callback(chapters)
            else:
                print(f"‚ùå Falha ao gerar cap√≠tulo {i + 1}")
                # Se √© o primeiro cap√≠tulo e falhou, retornar erro
                if i == 0:
                    print(f"‚ùå ERRO CR√çTICO: Falha ao gerar o primeiro cap√≠tulo")
                    return []
                # Se n√£o √© o primeiro, continuar com os cap√≠tulos j√° gerados
                break

            # Pequena pausa entre cap√≠tulos para evitar rate limiting
            time.sleep(1)

        print(f"‚úÖ DEBUG: Gerados {len(chapters)} cap√≠tulos com sucesso")
        return chapters
        
    except Exception as e:
        print(f"‚ùå Erro no Prompt 3: {e}")
        return []

def extract_base_prompt(narrative_structure):
    """Extrair o prompt base da estrutura narrativa"""
    try:
        if isinstance(narrative_structure, str):
            # Tentar parsear como JSON
            import json
            data = json.loads(narrative_structure)
            if 'Prompts' in data and len(data['Prompts']) > 0:
                return data['Prompts'][0].get('prompt', narrative_structure)
        return narrative_structure
    except:
        return narrative_structure

def call_openrouter(prompt, model, api_key):
    """Chamar OpenRouter API"""
    try:
        print(f"üîç DEBUG: Enviando prompt para OpenRouter ({len(prompt)} chars)")
        if model == 'auto':
            model = 'anthropic/claude-3.5-sonnet'
        print(f"üîç DEBUG: Usando modelo: {model}")
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:5173',
            'X-Title': 'Auto Video Producer'
        }
        
        response = requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers,
            json={
                'model': model,
                'messages': [
                    {'role': 'system', 'content': 'Voc√™ √© um especialista em cria√ß√£o de roteiros e storytelling.'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 2000,
                'temperature': 0.8
            },
            timeout=60
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            print(f"üîç DEBUG: OpenRouter respondeu com {len(content)} caracteres")
            return content
        else:
            print(f"‚ùå DEBUG: OpenRouter erro {response.status_code}: {response.text}")
            raise Exception(f'OpenRouter API error: {response.status_code}')

    except Exception as e:
        print(f"‚ùå DEBUG: Erro detalhado no OpenRouter: {str(e)}")
        raise Exception(f'Erro OpenRouter: {str(e)}')

def call_gemini(prompt, title_generator=None):
    """Chamada para API Gemini usando rota√ß√£o autom√°tica"""
    try:
        # Importar sistema de rota√ß√£o de chaves
        try:
            from routes.automations import get_next_gemini_key, handle_gemini_429_error, get_gemini_keys_count
            import google.generativeai as genai
            
            # Usar a quantidade real de chaves dispon√≠veis
            max_retries = get_gemini_keys_count() if get_gemini_keys_count() > 0 else 1
            print(f"üîë Usando {max_retries} chaves Gemini para scripts")
            last_error = None
            
            for attempt in range(max_retries):
                try:
                    # Obter pr√≥xima chave Gemini
                    api_key = get_next_gemini_key()
                    if not api_key:
                        raise Exception('Nenhuma chave Gemini dispon√≠vel. Configure pelo menos uma chave nas Configura√ß√µes.')
                    
                    print(f"üîç DEBUG: Tentativa {attempt + 1}/{max_retries}: Enviando prompt para Gemini ({len(prompt)} chars)")
                    
                    # Configurar Gemini diretamente
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel('gemini-1.5-flash')
                    
                    # Gerar conte√∫do
                    response = model.generate_content(prompt)
                    content = response.text.strip()
                    
                    print(f"üîç DEBUG: Gemini respondeu com {len(content)} caracteres na tentativa {attempt + 1}")
                    return content
                    
                except Exception as e:
                    error_str = str(e)
                    last_error = error_str
                    print(f"‚ùå DEBUG: Erro na tentativa {attempt + 1}: {error_str}")
                    
                    # Check if it's a quota error (429)
                    if "429" in error_str or "quota" in error_str.lower() or "rate limit" in error_str.lower():
                        if attempt < max_retries - 1:  # Not the last attempt
                            print(f"üîÑ Erro de quota detectado, tentando pr√≥xima chave Gemini...")
                            handle_gemini_429_error(error_str, api_key)
                            continue
                        else:
                            print("‚ùå Todas as tentativas de retry falharam")
                            handle_gemini_429_error(error_str, api_key)
                    else:
                        # For non-quota errors, don't retry
                        print(f"‚ùå Erro n√£o relacionado √† quota, parando tentativas: {error_str}")
                        break
            
            # Se chegou aqui, todas as tentativas falharam
            final_error = f'Falha na gera√ß√£o com Gemini ap√≥s todas as {max_retries} tentativas. √öltimo erro: {last_error}'
            raise Exception(final_error)
            
        except ImportError:
            # Fallback para m√©todo antigo se rota√ß√£o n√£o estiver dispon√≠vel
            if title_generator and title_generator.gemini_model:
                response = title_generator.gemini_model.generate_content(prompt)
                return response.text
            else:
                raise Exception("Gemini n√£o configurado ou chave n√£o dispon√≠vel")
    except Exception as e:
        print(f"‚ùå Erro na chamada Gemini: {e}")
        raise

def call_openai(prompt, title_generator):
    """Chamar OpenAI API"""
    try:
        print(f"üîç DEBUG: Enviando prompt para OpenAI ({len(prompt)} chars)")
        response = title_generator.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de roteiros e storytelling."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.8
        )
        content = response.choices[0].message.content
        print(f"üîç DEBUG: OpenAI respondeu com {len(content)} caracteres")
        return content
    except Exception as e:
        print(f"‚ùå DEBUG: Erro detalhado no OpenAI: {str(e)}")
        raise Exception(f'Erro OpenAI: {str(e)}')

def generate_long_script(script_data, update_callback=None):
    """Fun√ß√£o principal para gera√ß√£o de roteiros longos - compat√≠vel com pipeline_service.py"""
    try:
        print("üé¨ Iniciando gera√ß√£o de roteiro longo...")
        
        # Extrair dados do script_data
        title = script_data.get('title', '')
        premise = script_data.get('premise', '')
        chapters = script_data.get('chapters', 8)
        style = script_data.get('style', 'inicio')
        duration_target = script_data.get('duration_target', 300)
        include_hooks = script_data.get('include_hooks', True)
        custom_inicio = script_data.get('custom_inicio', '')
        custom_meio = script_data.get('custom_meio', '')
        custom_fim = script_data.get('custom_fim', '')
        detailed_prompt = script_data.get('detailed_prompt', False)
        detailed_prompt_text = script_data.get('detailed_prompt_text', '') if detailed_prompt else ''
        
        if not title or not premise:
            return {
                'success': False,
                'error': 'T√≠tulo e premissa s√£o obrigat√≥rios para gera√ß√£o de roteiro'
            }
        
        # Usar diretamente as fun√ß√µes de gera√ß√£o sem Flask request
        print(f"üìù Gerando roteiro: {title}")
        print(f"üìñ Premissa: {premise}")
        print(f"üìä Cap√≠tulos: {chapters}")
        
        # Inicializar o gerador de t√≠tulos para ter acesso √†s APIs
        title_generator = TitleGenerator()
        
        # Configurar APIs automaticamente
        def load_api_keys_from_file():
            """Carrega chaves de API do arquivo JSON"""
            import os
            import json
            try:
                config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'api_keys.json')
                print(f"üîç DEBUG: Caminho do config: {config_path}")
                if os.path.exists(config_path):
                    print("üîç DEBUG: Arquivo de config encontrado")
                    with open(config_path, 'r') as f:
                        keys = json.load(f)
                        print(f"üîç DEBUG: Chaves carregadas: {list(keys.keys())}")
                        return keys
                print("‚ùå DEBUG: Arquivo de config n√£o encontrado")
                return {}
            except Exception as e:
                print(f"‚ùå Erro ao carregar chaves de API: {e}")
                return {}
        
        api_keys = load_api_keys_from_file()
        
        if api_keys.get('openai'):
            print("üîç DEBUG: Configurando OpenAI")
            title_generator.configure_openai(api_keys['openai'])
        else:
            print("‚ùå DEBUG: Chave OpenAI n√£o encontrada")

        gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
        if gemini_key:
            print("üîç DEBUG: Configurando Gemini com chave: {gemini_key[:5]}...")
            title_generator.configure_gemini(gemini_key)
        else:
            print("‚ùå DEBUG: Chave Gemini n√£o encontrada")

        if api_keys.get('openrouter'):
            print("üîç DEBUG: Configurando OpenRouter")
            title_generator.configure_openrouter(api_keys['openrouter'])
        else:
            print("‚ùå DEBUG: Chave OpenRouter n√£o encontrada")
        
        # Pipeline de 3 prompts
        print("üé¨ Iniciando pipeline de gera√ß√£o de roteiros...")
        
        # PROMPT 1: Tradu√ß√£o e Contexto
        print("üìù Executando Prompt 1: Tradu√ß√£o e Contexto")
        context_result = execute_prompt_1(title, premise, 'auto', 'auto', api_keys, title_generator)
        
        if not context_result:
            raise Exception("Falha no Prompt 1: Tradu√ß√£o e Contexto")
        
        # PROMPT 2: Estrutura Narrativa
        print("üìñ Executando Prompt 2: Estrutura Narrativa")
        narrative_result = execute_prompt_2(title, context_result, 'auto', 'auto', api_keys, title_generator)
        
        if not narrative_result:
            raise Exception("Falha no Prompt 2: Estrutura Narrativa")
        
        # PROMPT 3: Gera√ß√£o dos Cap√≠tulos
        print(f"‚úçÔ∏è Executando Prompt 3: Gera√ß√£o de {chapters} Cap√≠tulos")
        if detailed_prompt and detailed_prompt_text:
            print(f"üìù Usando prompt detalhado para gera√ß√£o de roteiro")
        chapters_list = execute_prompt_3(title, context_result, narrative_result, chapters, 'auto', 'auto', api_keys, title_generator, update_callback, custom_inicio, custom_meio, custom_fim, detailed_prompt_text)
        
        if not chapters_list:
            raise Exception("Falha no Prompt 3: Gera√ß√£o dos Cap√≠tulos")
        
        # Combinar todos os cap√≠tulos em um roteiro √∫nico
        full_script = ""
        for chapter in chapters_list:
            full_script += f"\n\n{chapter.get('title', '')}\n\n"
            full_script += chapter.get('content', '')
        
        # Calcular dura√ß√£o estimada (aproximadamente 150 palavras por minuto)
        word_count = len(full_script.split())
        # Garantir que duration_target seja um n√∫mero - extrair apenas n√∫meros
        if isinstance(duration_target, str):
            # Extrair n√∫meros da string (ex: "5-7 minutes" -> 5)
            import re
            numbers = re.findall(r'\d+', duration_target)
            duration_target_num = int(numbers[0]) if numbers else 5
        else:
            duration_target_num = duration_target
        estimated_duration = max(word_count / 150, duration_target_num / 60)  # em minutos
        
        print(f"‚úÖ Roteiro gerado com sucesso: {len(chapters_list)} cap√≠tulos, {word_count} palavras")
        
        return {
            'success': True,
            'data': {
                'script': full_script.strip(),
                'chapters': chapters_list,
                'estimated_duration': estimated_duration,
                'word_count': word_count,
                'style': style,
                'provider_used': 'auto',
                'context': context_result,
                'narrative_structure': narrative_result
            }
        }
                
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de roteiro longo: {e}")
        return {
            'success': False,
            'error': str(e)
        }

def generate_script_with_detailed_prompt(title, context, base_prompt, detailed_prompt_text, number_of_chapters, ai_provider, openrouter_model, api_keys, title_generator, update_callback=None):
    """Gera roteiros usando prompt detalhado para roteiros longos"""
    chapters = []
    
    try:
        print(f"üìù Gerando roteiro com prompt detalhado: {title}")
        print(f"üìñ N√∫mero de cap√≠tulos: {number_of_chapters}")
        
        # Criar o prompt detalhado combinando todas as informa√ß√µes
        detailed_full_prompt = f"""
# T√≠tulo: {title}

# Contexto: {context}

# Base Narrativa: {base_prompt}

# Instru√ß√µes Detalhadas do Usu√°rio:
{detailed_prompt_text}

# Requisitos T√©cnicos:
- Gere exatamente {number_of_chapters} cap√≠tulos
- Cada cap√≠tulo deve ter conte√∫do substancial e rico em detalhes
- Mantenha a continuidade narrativa entre os cap√≠tulos
- Crie ganchos interessantes entre os cap√≠tulos
- Desenvolva personagens de forma consistente
- Construa uma narrativa coesa com in√≠cio, meio e fim bem definidos
- O tom e estilo devem ser consistentes com as instru√ß√µes detalhadas fornecidas

# Formato de Sa√≠da:
Gere cada cap√≠tulo separadamente, come√ßando com "CAP√çTULO X: [T√≠tulo do Cap√≠tulo]" seguido pelo conte√∫do do cap√≠tulo.
"""
        
        # Gerar o roteiro completo de uma vez
        full_script_content = None
        
        if ai_provider == 'auto':
            providers = ['openrouter', 'gemini', 'openai']
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        print(f"üîç DEBUG: Chamando OpenRouter com prompt detalhado...")
                        full_script_content = call_openrouter(detailed_full_prompt, openrouter_model, api_keys['openrouter'])
                        print(f"‚úÖ DEBUG: OpenRouter retornou {len(full_script_content) if full_script_content else 0} caracteres")
                        break
                    elif provider == 'gemini' and title_generator.gemini_model:
                        print(f"üîç DEBUG: Chamando Gemini com prompt detalhado...")
                        full_script_content = call_gemini(detailed_full_prompt, title_generator)
                        print(f"‚úÖ DEBUG: Gemini retornou {len(full_script_content) if full_script_content else 0} caracteres")
                        break
                    elif provider == 'openai' and title_generator.openai_client:
                        print(f"üîç DEBUG: Chamando OpenAI com prompt detalhado...")
                        full_script_content = call_openai(detailed_full_prompt, title_generator)
                        print(f"‚úÖ DEBUG: OpenAI retornou {len(full_script_content) if full_script_content else 0} caracteres")
                        break
                except Exception as e:
                    print(f"‚ùå Erro com {provider}: {e}")
                    continue
        elif ai_provider == 'openrouter':
            full_script_content = call_openrouter(detailed_full_prompt, openrouter_model, api_keys['openrouter'])
        elif ai_provider == 'gemini':
            full_script_content = call_gemini(detailed_full_prompt, title_generator)
        elif ai_provider == 'openai':
            full_script_content = call_openai(detailed_full_prompt, title_generator)
        
        if not full_script_content:
            print("‚ùå Falha ao gerar roteiro com prompt detalhado")
            return []
        
        # Processar o conte√∫do gerado para extrair os cap√≠tulos
        import re
        
        # Dividir o conte√∫do em cap√≠tulos usando o padr√£o "CAP√çTULO X:"
        chapter_pattern = r'CAP√çTULO (\d+):([^\n]*)\n([^]*?)(?=CAP√çTULO \d+:|$)'
        chapter_matches = re.findall(chapter_pattern, full_script_content, re.DOTALL)
        
        if not chapter_matches:
            # Se n√£o encontrou o padr√£o, tentar dividir o conte√∫do em partes iguais
            print("‚ö†Ô∏è Padr√£o de cap√≠tulos n√£o encontrado, dividindo conte√∫do em partes iguais")
            words = full_script_content.split()
            words_per_chapter = len(words) // number_of_chapters
            
            for i in range(number_of_chapters):
                start_idx = i * words_per_chapter
                end_idx = (i + 1) * words_per_chapter if i < number_of_chapters - 1 else len(words)
                chapter_words = words[start_idx:end_idx]
                chapter_content = ' '.join(chapter_words)
                
                chapters.append({
                    'chapter_number': i + 1,
                    'title': f"Cap√≠tulo {i + 1}",
                    'content': chapter_content,
                    'word_count': len(chapter_words)
                })
                
                if update_callback:
                    update_callback(chapters)
        else:
            # Processar os cap√≠tulos encontrados
            for match in chapter_matches:
                chapter_num = int(match[0])
                chapter_title = match[1].strip()
                chapter_content = match[2].strip()
                
                chapters.append({
                    'chapter_number': chapter_num,
                    'title': chapter_title if chapter_title else f"Cap√≠tulo {chapter_num}",
                    'content': chapter_content,
                    'word_count': len(chapter_content.split())
                })
                
                if update_callback:
                    update_callback(chapters)
        
        # Garantir que temos o n√∫mero correto de cap√≠tulos
        if len(chapters) != number_of_chapters:
            print(f"‚ö†Ô∏è N√∫mero de cap√≠tulos gerados ({len(chapters)}) diferente do solicitado ({number_of_chapters})")
            
            # Se temos menos cap√≠tulos que o solicitado, adicionar cap√≠tulos vazios
            while len(chapters) < number_of_chapters:
                chapters.append({
                    'chapter_number': len(chapters) + 1,
                    'title': f"Cap√≠tulo {len(chapters) + 1}",
                    'content': "Conte√∫do n√£o gerado",
                    'word_count': 0
                })
            
            # Se temos mais cap√≠tulos que o solicitado, remover os excedentes
            if len(chapters) > number_of_chapters:
                chapters = chapters[:number_of_chapters]
        
        print(f"‚úÖ Roteiro com prompt detalhado gerado com sucesso: {len(chapters)} cap√≠tulos")
        return chapters
        
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de roteiro com prompt detalhado: {e}")
        return []
