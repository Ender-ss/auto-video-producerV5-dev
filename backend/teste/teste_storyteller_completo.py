#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste Completo do Sistema Storyteller Unlimited
Gera roteiro de 10 cap√≠tulos usando o sistema implementado
Analisa fluidez narrativa e performance
"""

import os
import sys
import json
import time
import logging
from datetime import datetime
from pathlib import Path

# Adiciona o diret√≥rio backend ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.storyteller_service import storyteller_service
import services.ai_services as ai_services

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('teste_storyteller.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class StorytellerTester:
    """Classe para testar o sistema Storyteller completo"""
    
    def __init__(self):
        self.storyteller = storyteller_service
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'test_config': {},
            'execution_results': {},
            'narrative_analysis': {},
            'performance_metrics': {},
            'errors': [],
            'success': False
        }
        
    def setup_test_config(self):
        """Configura par√¢metros do teste"""
        self.test_config = {
            'title': 'A Faxineira e o Segredo do Milion√°rio',
            'premise': '''Uma faxineira humilde precisa levar seu filho doente ao trabalho na mans√£o de um milion√°rio. 
            Quando o patr√£o descobre a crian√ßa, fica em choque ao reconhecer uma marca de nascen√ßa id√™ntica √† de sua ex-namorada. 
            Ele percebe que pode ser o pai da crian√ßa e decide ajudar, mas descobre segredos familiares que mudar√£o suas vidas para sempre. 
            Uma hist√≥ria de supera√ß√£o, amor perdido, responsabilidade paterna e a descoberta de que o dinheiro n√£o compra a felicidade, 
            mas pode ser usado para fazer o bem.''',
            'agent_type': 'millionaire_stories',
            'num_chapters': 10,
            'provider': 'gemini',
            'target_narrative_style': 'fluido_emocional_detalhado'
        }
        
        self.test_results['test_config'] = self.test_config
        logger.info(f"Configura√ß√£o do teste: {self.test_config}")
        
    def load_api_keys(self):
        """Carrega chaves da API do arquivo de configura√ß√£o"""
        try:
            config_path = Path('../config/api_keys.json')
            if not config_path.exists():
                # Tenta caminho alternativo
                config_path = Path('config/api_keys.json')
                
            with open(config_path, 'r', encoding='utf-8') as f:
                api_config = json.load(f)
                
            # Extrai chaves Gemini do formato atual
            gemini_keys = []
            for key, value in api_config.items():
                if key.startswith('gemini_') and value:
                    gemini_keys.append(value)
            
            if not gemini_keys:
                raise ValueError("Nenhuma chave Gemini encontrada")
                
            logger.info(f"Carregadas {len(gemini_keys)} chaves Gemini")
            return gemini_keys
            
        except Exception as e:
            error_msg = f"Erro ao carregar chaves da API: {e}"
            logger.error(error_msg)
            self.test_results['errors'].append(error_msg)
            return []
    
    def execute_storyteller_generation(self):
        """Executa a gera√ß√£o do roteiro usando o Storyteller"""
        logger.info("üöÄ Iniciando gera√ß√£o do roteiro com Storyteller...")
        
        start_time = time.time()
        
        try:
            # Carrega chaves da API
            api_keys = self.load_api_keys()
            if not api_keys:
                raise ValueError("Nenhuma chave API dispon√≠vel")
            
            # Usa primeira chave dispon√≠vel
            api_key = api_keys[0]
            
            # Gera o roteiro usando o storyteller service
            result = self.storyteller.generate_storyteller_script(
                title=self.test_config['title'],
                premise=self.test_config['premise'],
                agent_type=self.test_config['agent_type'],
                num_chapters=self.test_config['num_chapters'],
                api_key=api_key,
                provider=self.test_config['provider']
            )
            
            execution_time = time.time() - start_time
            
            # Salva resultados
            self.test_results['execution_results'] = {
                'success': True,
                'execution_time': execution_time,
                'total_chapters': len(result.get('chapters', [])),
                'total_characters': len(result.get('full_script', '')),
                'script_data': result
            }
            
            logger.info(f"‚úÖ Roteiro gerado com sucesso em {execution_time:.2f}s")
            logger.info(f"üìä {len(result.get('chapters', []))} cap√≠tulos, {len(result.get('full_script', ''))} caracteres")
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"Erro na gera√ß√£o do roteiro: {str(e)}"
            logger.error(error_msg)
            
            self.test_results['execution_results'] = {
                'success': False,
                'execution_time': execution_time,
                'error': error_msg
            }
            self.test_results['errors'].append(error_msg)
            
            return None
    
    def analyze_narrative_quality(self, script_result):
        """Analisa a qualidade narrativa do roteiro gerado"""
        logger.info("üìù Analisando qualidade narrativa...")
        
        if not script_result:
            self.test_results['narrative_analysis'] = {
                'success': False,
                'error': 'Nenhum roteiro para analisar'
            }
            return
        
        try:
            full_script = script_result.get('full_script', '')
            chapters = script_result.get('chapters', [])
            
            # An√°lise b√°sica de estrutura
            analysis = {
                'total_words': len(full_script.split()),
                'total_characters': len(full_script),
                'chapter_count': len(chapters),
                'average_chapter_length': 0,
                'narrative_flow_indicators': {},
                'dialogue_presence': False,
                'emotional_depth_indicators': {},
                'structural_quality': {}
            }
            
            if chapters:
                chapter_lengths = [len(ch.get('content', '')) for ch in chapters]
                analysis['average_chapter_length'] = sum(chapter_lengths) / len(chapter_lengths)
                analysis['chapter_length_variance'] = max(chapter_lengths) - min(chapter_lengths)
            
            # Verifica fluidez narrativa
            narrative_indicators = {
                'dialogue_count': full_script.count('"'),
                'paragraph_breaks': full_script.count('\n\n'),
                'emotional_words': sum(1 for word in ['cora√ß√£o', 'l√°grimas', 'emo√ß√£o', 'sentimento', 'amor', 'medo', 'alegria'] 
                                     if word.lower() in full_script.lower()),
                'transition_words': sum(1 for word in ['ent√£o', 'depois', 'enquanto', 'quando', 'mas', 'por√©m', 'entretanto'] 
                                      if word.lower() in full_script.lower())
            }
            
            analysis['narrative_flow_indicators'] = narrative_indicators
            analysis['dialogue_presence'] = narrative_indicators['dialogue_count'] > 20
            
            # An√°lise de profundidade emocional
            emotional_indicators = {
                'descriptive_passages': full_script.count('.') - full_script.count('...'),
                'internal_thoughts': full_script.lower().count('pensou') + full_script.lower().count('refletiu'),
                'sensory_descriptions': sum(1 for word in ['viu', 'ouviu', 'sentiu', 'tocou', 'cheiro'] 
                                          if word.lower() in full_script.lower())
            }
            
            analysis['emotional_depth_indicators'] = emotional_indicators
            
            # Avalia√ß√£o estrutural
            structural_quality = {
                'has_introduction': len(chapters) > 0 and len(chapters[0].get('content', '')) > 500,
                'has_development': len(chapters) > 5,
                'has_climax': len(chapters) > 7,
                'has_resolution': len(chapters) == self.test_config['num_chapters']
            }
            
            analysis['structural_quality'] = structural_quality
            
            # Calcula score geral
            quality_score = 0
            if analysis['dialogue_presence']: quality_score += 20
            if narrative_indicators['emotional_words'] > 10: quality_score += 20
            if narrative_indicators['transition_words'] > 15: quality_score += 20
            if all(structural_quality.values()): quality_score += 25
            if analysis['average_chapter_length'] > 1500: quality_score += 15
            
            analysis['overall_quality_score'] = quality_score
            analysis['quality_rating'] = (
                'Excelente' if quality_score >= 80 else
                'Bom' if quality_score >= 60 else
                'Regular' if quality_score >= 40 else
                'Precisa Melhorar'
            )
            
            self.test_results['narrative_analysis'] = analysis
            
            logger.info(f"üìä An√°lise conclu√≠da - Score: {quality_score}/100 ({analysis['quality_rating']})")
            
        except Exception as e:
            error_msg = f"Erro na an√°lise narrativa: {str(e)}"
            logger.error(error_msg)
            self.test_results['narrative_analysis'] = {
                'success': False,
                'error': error_msg
            }
            self.test_results['errors'].append(error_msg)
    
    def save_generated_script(self, script_result):
        """Salva o roteiro gerado em arquivo"""
        if not script_result:
            return None
            
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'roteiro_storyteller_{timestamp}.txt'
            filepath = Path(filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"# {script_result.get('title', 'Roteiro Gerado')}\n\n")
                f.write(f"**Premissa:** {script_result.get('premise', '')}\n\n")
                f.write(f"**Gerado em:** {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}\n")
                f.write(f"**Sistema:** Storyteller Unlimited\n\n")
                f.write("=" * 80 + "\n\n")
                
                # Escreve roteiro completo
                full_script = script_result.get('full_script', '')
                if full_script:
                    f.write(full_script)
                else:
                    # Se n√£o tiver script completo, monta dos cap√≠tulos
                    chapters = script_result.get('chapters', [])
                    for i, chapter in enumerate(chapters, 1):
                        f.write(f"\n\n## CAP√çTULO {i}\n\n")
                        f.write(chapter.get('content', ''))
                
                f.write("\n\n" + "=" * 80)
                f.write(f"\n\n**Estat√≠sticas:**\n")
                f.write(f"- Total de cap√≠tulos: {len(script_result.get('chapters', []))}\n")
                f.write(f"- Total de caracteres: {len(full_script)}\n")
                f.write(f"- Palavras aproximadas: {len(full_script.split())}\n")
            
            logger.info(f"üíæ Roteiro salvo em: {filepath.absolute()}")
            return str(filepath.absolute())
            
        except Exception as e:
            error_msg = f"Erro ao salvar roteiro: {str(e)}"
            logger.error(error_msg)
            self.test_results['errors'].append(error_msg)
            return None
    
    def generate_test_report(self):
        """Gera relat√≥rio completo do teste"""
        logger.info("üìã Gerando relat√≥rio do teste...")
        
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_filename = f'relatorio_teste_storyteller_{timestamp}.json'
            
            # Determina sucesso geral
            execution_success = self.test_results['execution_results'].get('success', False)
            narrative_quality = self.test_results.get('narrative_analysis', {}).get('overall_quality_score', 0)
            
            self.test_results['success'] = execution_success and narrative_quality >= 60
            
            # Adiciona resumo executivo
            self.test_results['executive_summary'] = {
                'test_passed': self.test_results['success'],
                'execution_successful': execution_success,
                'narrative_quality_score': narrative_quality,
                'total_errors': len(self.test_results['errors']),
                'recommendations': self._generate_recommendations()
            }
            
            # Salva relat√≥rio JSON
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, indent=2, ensure_ascii=False)
            
            # Gera relat√≥rio em texto leg√≠vel
            text_report = self._generate_text_report()
            text_filename = f'relatorio_teste_storyteller_{timestamp}.txt'
            
            with open(text_filename, 'w', encoding='utf-8') as f:
                f.write(text_report)
            
            logger.info(f"üìä Relat√≥rio salvo em: {report_filename} e {text_filename}")
            
            return {
                'json_report': report_filename,
                'text_report': text_filename,
                'success': self.test_results['success']
            }
            
        except Exception as e:
            error_msg = f"Erro ao gerar relat√≥rio: {str(e)}"
            logger.error(error_msg)
            return {'error': error_msg}
    
    def _generate_recommendations(self):
        """Gera recomenda√ß√µes baseadas nos resultados"""
        recommendations = []
        
        execution_results = self.test_results.get('execution_results', {})
        narrative_analysis = self.test_results.get('narrative_analysis', {})
        
        if not execution_results.get('success', False):
            recommendations.append("Verificar configura√ß√£o das chaves API do Gemini")
            recommendations.append("Validar conectividade com servi√ßos de IA")
            recommendations.append("Revisar logs de erro para problemas espec√≠ficos")
        
        quality_score = narrative_analysis.get('overall_quality_score', 0)
        if quality_score < 60:
            recommendations.append("Melhorar prompts para maior profundidade narrativa")
            recommendations.append("Ajustar configura√ß√µes de cap√≠tulos por agente")
            
        if narrative_analysis.get('average_chapter_length', 0) < 1500:
            recommendations.append("Aumentar tamanho m√≠nimo de cap√≠tulos")
            
        if not narrative_analysis.get('dialogue_presence', False):
            recommendations.append("Incluir mais di√°logos nos prompts de gera√ß√£o")
        
        if len(self.test_results.get('errors', [])) > 0:
            recommendations.append("Implementar tratamento de erro mais robusto")
        
        return recommendations
    
    def _generate_text_report(self):
        """Gera relat√≥rio em formato texto leg√≠vel"""
        report = []
        report.append("=" * 80)
        report.append("RELAT√ìRIO DE TESTE - STORYTELLER UNLIMITED")
        report.append("=" * 80)
        report.append(f"Data/Hora: {self.test_results['timestamp']}")
        report.append(f"Status Geral: {'‚úÖ SUCESSO' if self.test_results['success'] else '‚ùå FALHA'}")
        report.append("")
        
        # Configura√ß√£o do teste
        report.append("üìã CONFIGURA√á√ÉO DO TESTE")
        report.append("-" * 40)
        config = self.test_results['test_config']
        report.append(f"T√≠tulo: {config.get('title', 'N/A')}")
        report.append(f"Agente: {config.get('agent_type', 'N/A')}")
        report.append(f"Cap√≠tulos: {config.get('num_chapters', 'N/A')}")
        report.append(f"Provedor: {config.get('provider', 'N/A')}")
        report.append("")
        
        # Resultados da execu√ß√£o
        report.append("üöÄ RESULTADOS DA EXECU√á√ÉO")
        report.append("-" * 40)
        exec_results = self.test_results.get('execution_results', {})
        report.append(f"Sucesso: {'Sim' if exec_results.get('success') else 'N√£o'}")
        report.append(f"Tempo de execu√ß√£o: {exec_results.get('execution_time', 0):.2f}s")
        report.append(f"Cap√≠tulos gerados: {exec_results.get('total_chapters', 0)}")
        report.append(f"Caracteres totais: {exec_results.get('total_characters', 0)}")
        report.append("")
        
        # An√°lise narrativa
        report.append("üìù AN√ÅLISE NARRATIVA")
        report.append("-" * 40)
        narrative = self.test_results.get('narrative_analysis', {})
        report.append(f"Score de qualidade: {narrative.get('overall_quality_score', 0)}/100")
        report.append(f"Avalia√ß√£o: {narrative.get('quality_rating', 'N/A')}")
        report.append(f"Palavras totais: {narrative.get('total_words', 0)}")
        report.append(f"Tamanho m√©dio por cap√≠tulo: {narrative.get('average_chapter_length', 0):.0f} chars")
        report.append(f"Presen√ßa de di√°logos: {'Sim' if narrative.get('dialogue_presence') else 'N√£o'}")
        report.append("")
        
        # Erros
        if self.test_results.get('errors'):
            report.append("‚ùå ERROS ENCONTRADOS")
            report.append("-" * 40)
            for i, error in enumerate(self.test_results['errors'], 1):
                report.append(f"{i}. {error}")
            report.append("")
        
        # Recomenda√ß√µes
        recommendations = self.test_results.get('executive_summary', {}).get('recommendations', [])
        if recommendations:
            report.append("üí° RECOMENDA√á√ïES")
            report.append("-" * 40)
            for i, rec in enumerate(recommendations, 1):
                report.append(f"{i}. {rec}")
            report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def run_complete_test(self):
        """Executa o teste completo do Storyteller"""
        logger.info("üé¨ Iniciando teste completo do Storyteller Unlimited")
        
        try:
            # 1. Configura√ß√£o
            self.setup_test_config()
            
            # 2. Execu√ß√£o
            script_result = self.execute_storyteller_generation()
            
            # 3. An√°lise
            self.analyze_narrative_quality(script_result)
            
            # 4. Salvamento
            script_file = self.save_generated_script(script_result)
            
            # 5. Relat√≥rio
            report_info = self.generate_test_report()
            
            # Log final
            if self.test_results['success']:
                logger.info("üéâ Teste conclu√≠do com SUCESSO!")
            else:
                logger.warning("‚ö†Ô∏è Teste conclu√≠do com PROBLEMAS")
            
            return {
                'success': self.test_results['success'],
                'script_file': script_file,
                'report_files': report_info,
                'test_results': self.test_results
            }
            
        except Exception as e:
            error_msg = f"Erro cr√≠tico no teste: {str(e)}"
            logger.error(error_msg)
            self.test_results['errors'].append(error_msg)
            self.test_results['success'] = False
            
            return {
                'success': False,
                'error': error_msg,
                'test_results': self.test_results
            }

def main():
    """Fun√ß√£o principal"""
    print("üé¨ TESTE STORYTELLER UNLIMITED")
    print("=" * 50)
    
    tester = StorytellerTester()
    results = tester.run_complete_test()
    
    print("\n" + "=" * 50)
    if results['success']:
        print("‚úÖ TESTE CONCLU√çDO COM SUCESSO!")
        print(f"üìÑ Roteiro salvo: {results.get('script_file', 'N/A')}")
    else:
        print("‚ùå TESTE FALHOU!")
        print(f"üîç Erro: {results.get('error', 'Verifique os logs')}")
    
    print(f"üìä Relat√≥rios: {results.get('report_files', {})}")
    print("=" * 50)
    
    return results

if __name__ == "__main__":
    main()